[ { "title": "如何优雅的编写Dockerfile", "url": "/posts/how-to-write-a-dockerfile-elegantly/", "categories": "Software Development", "tags": "Docker", "date": "2022-09-16 20:07:00 +0800", "snippet": "容器需要从Dockerfile开始，本文将介绍如何写出一个优雅的Dockerfile文件。Docker容器容器的特点我们都知道容器就是一个标准的软件单元，它有以下特点： 随处运行：容器可以将代码与配置文件和相关依赖库进行打包，从而确保在任何环境下的运行都是一致的。 高资源利用率：容器提供进程级的隔离，因此可以更加精细地设置CPU和内存的使用率，进而更好地利用服务器的计算资源。 快速扩展：每个容器都可作为单独的进程予以运行，并且可以共享底层操作系统的系统资源，这样一来可以加快容器的启动和停止效率。 轻量：容器是进程级的资源隔离，而虚拟机是操作系统级的资源隔离，所以Docker容器相对于虚拟机来说可以节省更多的资源开销，因为Docker容器不再需要GuestOS这一层操作系统了。 快速：容器的启动和创建无需启动GuestOS，可以实现秒级甚至毫秒级的启动。 可移植性：Docker容器技术是将应用及所依赖的库和运行时的环境技术改造包成容器镜像，可以在不同的平台运行。 自动化：容器生态中的容器编排工作（如：Kubernetes）可帮助我们实现容器的自动化管理。Docker容器目前市面上的主流容器引擎有Docker、Rocket/rkt、OpenVZ/Odin等等，而独霸一方的容器引擎就是使用最多的Docker容器引擎。Docker容器是与系统其他部分隔离开的一系列进程，运行这些进程所需的所有文件都由另一个镜像提供，从开发到测试再到生产的整个过程中，Linux 容器都具有可移植性和一致性。相对于依赖重复传统测试环境的开发渠道，容器的运行速度要快得多，并且支持在多种主流云平台（PaaS）和本地系统上部署。Docker容器很好地解决了“开发环境能正常跑，一上线就各种崩”的尴尬。DockerfileDockerfile是用来描述文件的构成的文本文档，其中包含了用户可以在使用行调用以组合Image的所有命令，用户还可以使用Docker build实现连续执行多个命令指今行的自动构建。通过编写Dockerfile生磁镜像，可以为开发、测试团队提供基本一致的环境，从而提升开发、测试团队的效率，不用再为环境不统一而发愁，同时运维也能更加方便地管理我们的镜像。Dockerfile语法Dockerfile格式# CommentINSTRUCTION arguments虽然Dockerfile并不区分大小写，但还是约定指令使用大写。Docker按顺序运行Dockerfile中的指令。一个Dockerfile必须以FROM指令开始。这可能是在解析器指令、注释和全局范围的ARG之后。FROM指令指定了你要构建的父镜像。FROM前面只能有一个或多个ARG指令，这些指令声明了Dockerfile中FROM行使用的参数。Docker将以#开头的行视为注释，除非该行是一个有效的解析指令(parser directives)。一行中其他地方的#标记被视为一个参数。这允许像这样的语句。# directive=value1FROM ImageName解析指令是可选的，虽然不区分大小写，但还是约定使用小写。解析指令会影响到Dockerfile的解析逻辑，并且不会生成图层，也不会在构建时显示。解析指令只能出现在Dockerfile头部，并且一条解析指令只能出现一次。如果碰到注释、Dockerfile指令或空行，接下来出现的解析指令都无效，被当做注释处理。不支持续行。目前仅支持 syntax escape 两个解析器指令 syntax 语法格式： # syntax = &amp;lt;builder&amp;gt; 该指令可以用于选择不同的构建器（Builder），以及切换到不同的语法版本。例如，如果您想要使用BuildKit作为构建器，则可以在Dockerfile中添加以下语句： # syntax = docker/dockerfile:experimental 且此功能仅在使用BuildKit 后端时可用，在使用经典构建器后端时将被忽略。 Custom Dockerfile syntax escape 该escape指令设置用于转义字符的字符 Dockerfile。如果未指定，则默认转义字符为\\ 将转义字符设置为 在上特别有用 Windows，其中\\是目录路径分隔符。与Windows PowerShell一致 # escape=` 上面的例子将转义字符设置为反引号（`），并且后续的反斜杠将被视为普通字符而不是转义字符。 Dockerfile解析指令可以用于修改Dockerfile的解析方式，从而增强其灵活性和可扩展性解析指令详细文档参考Docker文档Dockerfile命令集 命令 说明 FROM 基于哪个镜像来实现 MAINTAINER 为构建的镜像设置作者信息(已被弃用) LABEL 给构建的镜像打标签 ENV 声明环境变量 ARG 指定了用户在 docker build --build-arg 时可以使用的参数 RUN 执行的命令添加宿主机文件到容器里，有需要解压的文 CMD run后面跟启动命令会被覆盖掉 ENTRYPOINT 与CMD功能相同，但需docker run 不会覆盖，如果需要覆盖可增加参数-entrypoint来覆盖 ADD 件会自动解压 COPY 添加宿主机文件到容器里 WORKDIR 工作目录 EXPOSE 容器内应用可使用的端口容器启动后所执行的程序，如果执行docker VOLUME 将宿主机的目录挂载到容器里 USER 为接下来的Dockerfile指令指定用户 ONBUILD 向镜像中添加一个触发器，当以该镜像为base image再次构建新的镜像时，会触发执行其中的指令 STOPSIGNAL 容器结束时触发系统信号 HEALTHCHECK 增加自定义的心跳检测功能 SHELL 更改后续的Dockerfile指令中所使用的shell FROM构建的镜像继承自某个base image。格式:FROM [--platform=&amp;lt;platform&amp;gt;] &amp;lt;image&amp;gt; [AS &amp;lt;name&amp;gt;]FROM [--platform=&amp;lt;platform&amp;gt;] &amp;lt;image&amp;gt;[:&amp;lt;tag&amp;gt;] [AS &amp;lt;name&amp;gt;]FROM [--platform=&amp;lt;platform&amp;gt;] &amp;lt;image&amp;gt;[@&amp;lt;digest&amp;gt;] [AS &amp;lt;name&amp;gt;]FROM指令必须是Dockerfile的第一个指令，可以使用多次来构建多个镜像，以最后一个镜像的ID为输出值。tag和digest是可选的，如果不提供则使用latest。该FROM指令初始化一个新的构建阶段并为后续指令设置 基础映像。因此，有效Dockerfile必须以指令开始FROM。该图像可以是任何有效图像——从公共存储库中拉取图像开始特别容易。ARG FROM是. 中可能先于的唯一指令Dockerfile。FROM可以在单个中出现多次Dockerfile以创建多个图像或使用一个构建阶段作为另一个构建阶段的依赖项。只需记下每条新指令之前提交输出的最后一个图像 ID FROM。每条FROM指令都会清除之前指令创建的任何状态。AS name 可选，可以通过添加到 指令来为新构建阶段指定名称FROM。FROM该名称可以在后续和 说明中使用COPY --from=&amp;lt;name&amp;gt;，以引用此阶段构建的镜像。或值是可选tag的digest。如果您省略其中任何一个，构建器将latest默认采用一个标记。如果构建器找不到该tag值，则会返回错误。可选--platform标志可用于指定图像的平台，以防FROM引用多平台图像。例如，linux/amd64、 linux/arm64或windows/amd64。默认情况下，使用构建请求的目标平台。可以在此标志的值中使用全局构建参数，例如自动平台 ARG 允许您将阶段强制为本机构建平台 (--platform=$BUILDPLATFORM)，并使用它交叉编译到阶段内的目标平台。通常情况下，在编写 Dockerfile 时，需要基于一个已经存在的镜像构建。因此，你需要在 FROM 指令中指定你要基于哪个镜像进行构建。如果你想从零开始创建一个全新的 Docker 镜像，则可以考虑使用一个最小化的基础镜像，例如 scratch。这个镜像并不包含任何操作系统组件或应用程序，它只提供了一个空白的文件系统。因此，你可以根据需要添加自己的应用程序和依赖项。以下是一个简单的例子：FROM scratch# 添加应用程序二进制文件COPY myapp /myapp# 设置容器启动命令CMD [&quot;/myapp&quot;]在这个例子中，我们首先指定了 FROM scratch，表示我们要从空白镜像开始构建。接着，我们将 myapp 应用程序复制到容器中，并设置容器启动命令为 /myapp。注意，从零开始构建 Docker 镜像可能需要一些额外的工作和配置，因为你需要自己设置运行环境和依赖项。因此，如果你可以使用现有的基础镜像来构建你的应用程序，那么通常会更加容易和高效。ARG 和 FROM 是如何交互的FROMinstructions 支持由ARG 在第一条指令之前发生的任何指令声明的变量FROM。ARG CODE_VERSION=latestFROM base:${CODE_VERSION}CMD /code/run-appFROM extras:${CODE_VERSION}CMD /code/run-extras在FROM之前声明的ARG位于构建阶段之外，因此无法在FROM之后的任何指令中使用。要使用在第一个FROM之前声明的ARG的默认值，请在构建阶段内使用不带值的ARG指令：ARGARG VERSION=latestFROM busybox:$VERSIONARG VERSIONRUN echo $VERSION &amp;gt; image_versionMAINTAINER (deprecated)MAINTAINER &amp;lt;name&amp;gt;该MAINTAINER指令设置生成图像的作者字段。该LABEL指令是一个更灵活的版本，您应该改用它，因为它可以设置您需要的任何元数据，并且可以轻松查看，例如使用docker inspect. 要设置与您可以使用的字段相对应的标签 MAINTAINER：LABEL org.opencontainers.image.authors=&quot;SvenDowideit@home.org.au&quot;这将从docker inspect其他标签中可见。LABELLABEL = = = ...该LABEL指令将元数据添加到图像中。ALABEL是键值对。要在值中包含空格LABEL，请像在命令行解析中一样使用引号和反斜杠。几个使用示例：LABEL “com.example.vendor”=”ACME Incorporated”LABEL com.example.label-with-value=”foo”LABEL version=”1.0”LABEL description=”This text illustrates that label-values can span multiple lines.”一张图片可以有多个标签。您可以在一行中指定多个标签。在 Docker 1.10 之前，这会减小最终映像的大小，但现在已不再如此。您仍然可以选择通过以下两种方式之一在一条指令中指定多个标签：LABEL multi.label1=”value1” multi.label2=”value2” other=”value3”LABEL multi.label1=”value1” multi.label2=”value2” other=”value3” 请务必使用双引号而不是单引号。特别是当您使用字符串插值时（例如LABEL example=”foo-$ENV_VAR”），单引号将按原样使用字符串而不解包变量的值。 基础图像或父图像（行中的图像FROM）中包含的标签由您的图像继承。如果标签已存在但具有不同的值，则最近应用的值会覆盖任何先前设置的值。ENV在构建的镜像中设置环境变量，在后续的Dockerfile指令中可以直接使用，也可以固化在镜像里，在容器运行时仍然有效。格式：ENV &amp;lt;key&amp;gt; &amp;lt;value&amp;gt;：把第一个空格之后的所有值都当做&amp;lt;key&amp;gt;的值，无法在一行内设定多个环境变量。ENV &amp;lt;key&amp;gt;=&amp;lt;value&amp;gt; ...：可以设置多个环境变量，如果&amp;lt;value&amp;gt;中存在空格，需要转义或用引号”括起来。docker推荐使用第二种，因为可以在一行中写多个环境变量，减少图层。如下：ENV MY_NAME=&quot;John Doe&quot; MY_DOG=Rex\\ The\\ Dog \\ MY_CAT=fluffy 注意 可以在容器运行时指定环境变量，替换镜像中的已有变量，docker run –env &amp;lt;key&amp;gt;=&amp;lt;value&amp;gt;。 使用ENV可能会对后续的Dockerfile指令造成影响，如果只需要对一条指令设置环境变量，可以使用这种方式：RUN &amp;lt;key&amp;gt;=&amp;lt;value&amp;gt; &amp;lt;command&amp;gt; ENV当容器从生成的图像运行时，使用的环境变量设置将持续存在。您可以使用 查看值docker inspect，并使用 更改它们docker run –env &amp;lt;key&amp;gt;=&amp;lt;value&amp;gt;。如果环境变量只在构建期间需要，而不是在最终图像中，请考虑为单个命令设置一个值：RUN DEBIAN_FRONTEND=noninteractive apt-get update &amp;amp;&amp;amp; apt-get install -y ...或者使用ARG，它不会保留在最终图像中：ARG DEBIAN_FRONTEND=noninteractiveRUN apt-get update &amp;amp;&amp;amp; apt-get install -y ...ARG指定了用户在 docker build --build-arg &amp;lt;varname&amp;gt;=&amp;lt;value&amp;gt; 时可以使用的参数ARG &amp;lt;name&amp;gt;[=&amp;lt;default value&amp;gt;]构建参数在定义的时候生效而不是在使用的时候。如下面第三行开始的user才是用户构建参数传递过来的user：FROM busyboxUSER ${user:-some_user}ARG userUSER $user后续的ENV指令会覆盖同名的构建参数，正常用法如下：FROM ubuntuARG CONT_IMG_VERENV CONT_IMG_VER ${CONT_IMG_VER:-v1.0.0}RUN echo $CONT_IMG_VERdocker内置了一批构建参数，可以不用在Dockerfile中声明：HTTP_PROXY、http_proxy、HTTPS_PROXY、https_proxy、FTP_PROXY、ftp_proxy、NO_PROXY、no_proxy注意在使用构建参数(而不是在构建参数定义的时候)的指令中，如果构建参数的值发生了变化，会导致该指令发生变化，会重新寻找缓存。在Dockerfile中，ENV和ARG指令都被用来设置环境变量，但它们之间有一些区别。 ARG指令是在构建过程中定义一个变量，可以通过–build-arg选项覆盖默认值。这样可以将构建参数传递给Dockerfile，并在构建期间使用它们。ARG变量在构建后不会存在于容器中。 ENV指令用于在容器中设置环境变量。与ARG不同，ENV指令在运行容器时创建环境变量，并将其持久化到容器中。这意味着在容器运行时可以使用这些环境变量。 总之，ARG指令用于在构建期间定义变量，而ENV指令用于在容器运行时设置环境变量。RUN在镜像的构建过程中执行特定的命令，并生成一个中间镜像。格式:RUN &amp;lt;command&amp;gt;：shell格式RUN [&quot;executable&quot;, &quot;param1&quot;, &quot;param2&quot;]：exec格式RUN指令将在当前镜像的新层中执行任何命令并提交结果。生成的提交镜像将用于Dockerfile中下一步骤。分层RUN指令和生成提交符合Docker的核心概念，其中提交是廉价的，容器可以从镜像历史记录的任何点创建，就像源代码控制一样。使用exec形式可以避免shell字符串处理，并使用不包含指定shell可执行文件的基础映像运行命令。默认情况下，使用shell形式的shell可以使用SHELL命令更改。在shell形式中，您可以使用\\（反斜杠）将单个RUN指令延续到下一行。例如，请考虑以下两行：RUN /bin/bash -c &#39;source $HOME/.bashrc &amp;amp;&amp;amp; \\echo $HOME&#39;它们一起相当于这一行：RUN /bin/bash -c &#39;source $HOME/.bashrc &amp;amp;&amp;amp; echo $HOME&#39;要使用除“/bin/sh”之外的其他 shell，请使用传入所需 shell 的exec形式。例如：RUN [&quot;/bin/bash&quot;, &quot;-c&quot;, &quot;echo hello&quot;] exec形式被解析为 JSON 数组，这意味着您必须在单词周围使用双引号 (“) 而不是单引号 (‘) 。与shell形式不同，exec形式不调用命令 shell。这意味着正常的 shell 处理不会发生。例如， RUN [ &quot;echo&quot;, &quot;$HOME&quot; ]不会对 进行变量替换$HOME。如果您想要 shell 处理，那么要么使用shell形式，要么直接执行 shell，例如：RUN [ &quot;sh&quot;, &quot;-c&quot;, &quot;echo $HOME&quot; ]. 当使用exec形式直接执行shell时，如shell形式，是shell在做环境变量扩展，而不是docker。 在JSON形式中，需要对反斜杠进行转义。这在反斜杠是路径分隔符的 Windows 上尤为重要。由于不是有效的 JSON，以下行将被视为shell形式，并以意外的方式失败： RUN [&quot;c:\\windows\\system32\\tasklist.exe&quot;] 此示例的正确语法是： RUN [&quot;c:\\\\windows\\\\system32\\\\tasklist.exe&quot;] 指令缓存RUN不会在下一次构建期间自动失效。类似指令的缓存 RUN apt-get dist-upgrade -y将在下一次构建期间重复使用。可以使用标志使指令RUN缓存失效–no-cache ，例如docker build –no-cache。有关详细信息，请参阅Dockerfile最佳实践指南。指令的缓存RUN可以由指令ADD和COPY指令使之失效。CMD该CMD指令具有三种形式：CMD [&quot;executable&quot;,&quot;param1&quot;,&quot;param2&quot;]（exec形式，这是首选形式）CMD [&quot;param1&quot;,&quot;param2&quot;]（作为ENTRYPOINT 的默认参数）CMD command param1 param2（外壳形式）CMD一个文件中只能有一条指令Dockerfile。如果您列出多个，CMD 则只有最后一个CMD会生效。CMD的主要目的是为正在执行的容器提供默认值。这些默认值可以包含可执行文件，也可以省略可执行文件，在这种情况下，您还必须指定一条ENTRYPOINT 指令。 如果CMD用于为ENTRYPOINT指令提供默认参数，则CMD和ENTRYPOINT指令都应使用 JSON 数组格式指定。 与RUN指令的区别：RUN在构建的时候执行，并生成一个新的镜像，CMD在容器运行的时候执行，在构建时不进行任何操作。ENTRYPOINTENTRYPOINT 有两种形式：exec形式，这是首选形式：ENTRYPOINT [&quot;executable&quot;, &quot;param1&quot;, &quot;param2&quot;]外壳形式：ENTRYPOINT command param1 param2将ENTRYPOINT您配置将作为可执行文件运行的容器。CMD 和 ENTRYPOINT 是如何交互的CMD和指令都ENTRYPOINT定义了运行容器时执行的命令。很少有规则描述他们的合作。 Dockerfile 应指定至少一个CMD或ENTRYPOINT命令。 ENTRYPOINT应该在将容器用作可执行文件时定义。 CMD应该用作为命令定义默认参数ENTRYPOINT或在容器中执行临时命令的一种方式。 CMD在使用替代参数运行容器时将被覆盖。 下表显示了针对不同ENTRYPOINT/CMD组合执行的命令： Company 没有ENTRYPOINT 没有ENTRYPOINT exec_entry p1_entry ENTRYPOINT [“exec_entry”,”p1_entry”] 没有CMD 错误，不允许 /bin/sh -c exec_entry p1_entry exec_entry p1_entry CMD [“exec_cmd”, “p1_cmd “] exec_cmd p1_cmd /bin/sh -c exec_entry p1_entry exec_entry p1_entry exec_cmd p1_cmd CMD exec_cmd p1_cmd /bin/sh -c exec_cmd p1_cmd /bin/sh -c exec_entry p1_entry exec_entry p1_entry /bin/sh -c exec_cmd p1_cmd 如果CMD是从基本图像定义的，则设置ENTRYPOINT将重置CMD为空值。在这种情况下，CMD必须在当前图像中定义一个值。ADD在构建镜像时，复制上下文中的文件到镜像内，格式：ADD [--chown=&amp;lt;user&amp;gt;:&amp;lt;group&amp;gt;] [--checksum=&amp;lt;checksum&amp;gt;] &amp;lt;src&amp;gt;... &amp;lt;dest&amp;gt;ADD [--chown=&amp;lt;user&amp;gt;:&amp;lt;group&amp;gt;] [&quot;&amp;lt;src&amp;gt;&quot;,... &quot;&amp;lt;dest&amp;gt;&quot;]包含空格的路径需要后一种形式。 该–chown功能仅在用于构建 Linux 容器的 Dockerfile 上受支持，不适用于 Windows 容器。由于用户和组所有权概念不会在 Linux 和 Windows 之间转换，因此使用和将/&amp;gt;etc/passwd用户/etc/group和组名转换为 ID 限制了此功能仅适用于基于 Linux 操作系统的容器。该ADD指令从中复制新文件、目录或远程文件 URL &amp;lt;src&amp;gt; ，并将它们添加到路径中图像的文件系统中&amp;lt;dest&amp;gt;。可以指定多个&amp;lt;src&amp;gt;资源，但如果它们是文件或目录，则它们的路径被解释为相对于构建上下文的源。每个都可能包含通配符，匹配将使用 Go 的filepath.Match&amp;lt;src&amp;gt;规则完成 。例如：添加以“hom”开头的所有文件：ADD hom* /mydir/在下面的示例中，?被替换为任何单个字符，例如“home.txt”。ADD hom?.txt /mydir/是&amp;lt;dest&amp;gt;绝对路径，或相对于 的路径WORKDIR，源将被复制到目标容器内。下面的示例使用相对路径，并将“test.txt”添加到&amp;lt;WORKDIR&amp;gt;/relativeDir/：ADD test.txt relativeDir/而此示例使用绝对路径，并将“test.txt”添加到/absoluteDir/ADD test.txt /absoluteDir/当添加包含特殊字符（例如[ and ]）的文件或目录时，您需要按照 Golang 规则对这些路径进行转义，以防止它们被视为匹配模式。例如，要添加名为 的文件arr[0].txt，请使用以下命令；ADD arr[[]0].txt /mydir/所有新文件和目录都使用 0 的 UID 和 GID 创建，除非可选标志–chown指定给定的用户名、组名或 UID/GID 组合以请求所添加内容的特定所有权。标志的格式–chown允许用户名和组名字符串或直接整数 UID 和 GID 的任意组合。提供不带组名的用户名或不带 GID 的 UID 将使用与 GID 相同的数字 UID。如果提供了用户名或组名，容器的根文件系统 /etc/passwd和/etc/group文件将分别用于执行从名称到整数 UID 或 GID 的转换。以下示例显示了标志的有效定义–chown：ADD --chown=55:mygroup files* /somedir/ADD --chown=bin files* /somedir/ADD --chown=1 files* /somedir/ADD --chown=10:11 files* /somedir/如果容器根文件系统不包含/etc/passwd或 /etc/group文件，并且标志中使用了用户名或组名–chown ，则构建操作将失败ADD。使用数字 ID 不需要查找，也不会依赖于容器根文件系统内容。ADD遵守以下规则： 该&amp;lt;src&amp;gt;路径必须在构建的上下文中；你不能ADD ../something /something，因为 a 的第一步 docker build是将上下文目录（和子目录）发送到 docker 守护进程。 如果&amp;lt;src&amp;gt;是一个 URL 并且&amp;lt;dest&amp;gt;不以尾部斜杠结尾，则会从该 URL 下载一个文件并将其复制到&amp;lt;dest&amp;gt;. 如果&amp;lt;src&amp;gt;是一个 URL 并且&amp;lt;dest&amp;gt;确实以尾部斜杠结尾，那么文件名是从 URL 推断出来的，文件被下载到 &amp;lt;dest&amp;gt;/&amp;lt;filename&amp;gt;. 例如，ADD http://example.com/foobar /将创建文件/foobar. URL 必须有一个重要的路径，以便在这种情况下可以发现适当的文件名（http://example.com 将不起作用）。 如果&amp;lt;src&amp;gt;是目录，则复制目录的全部内容，包括文件系统元数据。 不复制目录本身，只复制其内容。 如果&amp;lt;src&amp;gt;是采用可识别压缩格式（身份、gzip、bzip2 或 xz）的本地tar 存档，则将其解压缩为目录。来自远程URL 的资源不会被解压缩。复制或解压缩目录时，它具有与 相同的行为tar -x，结果是以下的并集： 目标路径上存在的任何内容和源代码树的内容，冲突解决后支持“2”。在逐个文件的基础上。 文件是否被识别为可识别的压缩格式完全基于文件的内容，而不是文件的名称。例如，如果一个空文件恰好以此结尾，.tar.gz将不会被识别为压缩文件，也不会生成任何类型的解压缩错误消息，而只是将文件复制到目标位置。 如果&amp;lt;src&amp;gt;是任何其他类型的文件，它将连同其元数据一起单独复制。在这种情况下，如果&amp;lt;dest&amp;gt;以尾部斜杠 结尾/，它将被视为一个目录，其内容&amp;lt;src&amp;gt;将写入&amp;lt;dest&amp;gt;/base(&amp;lt;src&amp;gt;). 如果&amp;lt;src&amp;gt;直接或由于使用通配符指定了多个资源，则&amp;lt;dest&amp;gt;必须是目录，并且必须以斜杠结尾/。 如果&amp;lt;dest&amp;gt;不以尾部斜杠结尾，它将被视为常规文件，其内容&amp;lt;src&amp;gt;将写入&amp;lt;dest&amp;gt;. 如果&amp;lt;dest&amp;gt;不存在，则会创建它及其路径中所有缺失的目录。COPY与ADD类似，只不过ADD是将上下文内的文件复制到镜像内，COPY是在镜像内的复制。格式与ADD一致。COPY有两种形式：COPY [--chown=&amp;lt;user&amp;gt;:&amp;lt;group&amp;gt;] &amp;lt;src&amp;gt;... &amp;lt;dest&amp;gt;COPY [--chown=&amp;lt;user&amp;gt;:&amp;lt;group&amp;gt;] [&quot;&amp;lt;src&amp;gt;&quot;,... &quot;&amp;lt;dest&amp;gt;&quot;]注意如果&amp;lt;dest&amp;gt;不存在，COPY指令会自动创建所有目录，包括子目录在 Dockerfile 中，COPY 和 ADD 都用于将文件或目录复制到容器中，但它们有一些区别： COPY 只能复制文件或目录到容器中，而 ADD 还支持自动解压缩 URL 和 tar 文件。 ADD 支持将远程 URL 作为源文件。如果您使用 COPY 命令并指定了 URL，则会出现错误。 如果您使用 ADD 命令并且源文件是 tar 文件，它将在复制之前自动解压缩。 COPY 更加透明，因为它只是简单地将本地文件复制到容器中，而 ADD 具有额外的功能（如自动解压缩），可能会导致意外行为。总之，如果您只需要复制本地文件到容器中，最好使用 COPY 命令。如果您需要支持更高级的复制功能（如自动解压缩和 URL 支持），则可以使用 ADD 命令。WORKDIR为接下来的Dockerfile指令指定当前工作目录，可多次使用，如果使用的是相对路径，则相对的是上一个工作目录，类似shell中的cd命令。格式：WORKDIR /path/to/workdir受影响的指令有：RUN、CMD、ENTRYPOINT、COPY和ADD。该WORKDIR指令可以解析先前使用设置的环境变量 ENV。您只能使用在Dockerfile. 例如：ENV DIRPATH=/pathWORKDIR $DIRPATH/$DIRNAMERUN pwdpwd最终命令的输出Dockerfile将是 /path/$DIRNAME如果未指定，则默认工作目录为/. 实际上，如果您不是从头开始构建 Dockerfile ( FROM scratch)，则WORKDIR可能由您使用的基础映像设置。因此，为避免在未知目录中进行意外操作，最好WORKDIR明确设置您的。EXPOSE为构建的镜像设置监听端口，使容器在运行时监听。格式：EXPOSE &amp;lt;port&amp;gt; [&amp;lt;port&amp;gt;...]EXPOSE指令并不会让容器监听host的端口，如果需要，需要在docker run时使用-p、-P参数来发布容器端口到host的某个端口上。默认情况下，EXPOSE采用 TCP。您还可以指定 UDP：EXPOSE 80/udp要在 TCP 和 UDP 上公开，请包括两行：EXPOSE 80/tcpEXPOSE 80/udp在这种情况下，如果您使用docker run -P ，端口将为 TCP 公开一次，为 UDP 公开一次。请记住，-P在主机上使用临时高阶主机端口，因此 TCP 和 UDP 的端口不会相同。无论设置如何EXPOSE，您都可以在运行时使用-p标志覆盖它们。例如 docker run -p 80:80/tcp -p 80:80/udp ...VOLUME指定镜像内的目录为数据卷。格式：VOLUME [&quot;/var/log&quot;]VOLUME /var/log /var/db在容器运行的时候，docker会把镜像中的数据卷的内容复制到容器的数据卷中去。如果在接下来的Dockerfile指令中，修改了数据卷中的内容，则修改无效。 请记住以下有关Dockerfile. 基于 Windows 的容器上的卷：使用基于 Windows 的容器时，容器内卷的目的地必须是以下之一： 一个不存在的或空的目录 驱动器以外的C: 从 Dockerfile 中更改卷：如果任何构建步骤在声明卷后更改卷中的数据，这些更改将被丢弃。 JSON 格式：列表被解析为 JSON 数组。”您必须用双引号 ( ) 而不是单引号 ( )将单词括起来’。 主机目录在容器运行时声明：主机目录（挂载点）本质上是依赖于主机的。这是为了保持图像的可移植性，因为不能保证给定的主机目录在所有主机上都可用。因此，您无法从 Dockerfile 中挂载主机目录。该VOLUME指令不支持指定host-dir 参数。您必须在创建或运行容器时指定挂载点。 USERUSER &amp;lt;user&amp;gt;[:&amp;lt;group&amp;gt;]或者USER &amp;lt;UID&amp;gt;[:&amp;lt;GID&amp;gt;]该USER指令设置用户名（或 UID）和可选的用户组（或 GID）以用作当前阶段剩余部分的默认用户和组。指定的用户用于RUN指令，并在运行时运行相关ENTRYPOINT和CMD命令。请注意，为用户指定组时，用户将只有指定的组成员资格。任何其他已配置的组成员身份都将被忽略。当用户没有主要组时，图像（或下一条指令）将与该root组一起运行。在 Windows 上，如果用户不是内置帐户，则必须先创建它。net user这可以通过作为 Dockerfile 的一部分调用的命令来完成。FROM microsoft/windowsservercore# Create Windows user in the containerRUN net user /add patrick# Set it for subsequent commandsUSER patrickONBUILD向镜像中添加一个触发器，当以该镜像为base image再次构建新的镜像时，会触发执行其中的指令。格式：ONBUILD [INSTRUCTION]比如我们生成的镜像是用来部署Python代码的，但是因为有多个项目可能会复用该镜像。所以一个合适的方式是：[...]# 在下一次以此镜像为base image的构建中，执行ADD . /app/src，将项目代目添加到新镜像中去ONBUILD ADD . /app/src# 并且build Python代码ONBUILD RUN /usr/local/bin/python-build --dir /app/src[...] ONBUILD只会继承给子节点的镜像，不会再继承给孙子节点。ONBUILD ONBUILD或者ONBUILD FROM或者ONBUILD MAINTAINER是不允许的。STOPSIGNALSTOPSIGNAL signal该STOPSIGNAL指令设置将发送到容器退出的系统调用信号。该信号可以是格式为 的信号名称SIG&amp;lt;NAME&amp;gt;，例如SIGKILL，或者与内核系统调用表中的位置匹配的无符号数字，例如9。SIGTERM如果未定义则为默认值。--stop-signal可以使用标志在docker run和覆盖每个容器的图像默认停止信号 docker create。HEALTHCHECK增加自定义的心跳检测功能，多次使用只有最后一次有效。格式：HEALTHCHECK [OPTION] CMD &amp;lt;command&amp;gt;：通过在容器内运行command来检查心跳HEALTHCHECK NONE：取消从base image继承来的心跳检测可选的OPTION：--interval=DURATION：检测间隔，默认30秒--timeout=DURATION：命令超时时间，默认30秒--retries=N：连续N次失败后标记为不健康，默认3次&amp;lt;command&amp;gt;可以是shell脚本，也可以是exec格式的json数组。docker以&amp;lt;command&amp;gt;的退出状态码来区分容器是否健康，这一点同shell一致：0：命令返回成功，容器健康1：命令返回失败，容器不健康2：保留状态码，不要使用举例：每5分钟检测本地网页是否可访问，超时设为3秒：HEALTHCHECK --interval=5m --timeout=3s \\ CMD curl -f http://localhost/ || exit 1可以使用docker inspect命令来查看健康状态。SHELLSHELL [&quot;executable&quot;, &quot;parameters&quot;]SHELL指令允许覆盖用于命令shell形式的默认shell。在Linux上，默认的shell是[&quot;/bin/sh&quot;, &quot;-c&quot;]，在Windows上是[&quot;cmd&quot;, &quot;/S&quot;, &quot;/C&quot;]。在Dockerfile中，SHELL指令必须以JSON格式编写。在Windows上，SHELL指令特别有用，因为有两个常用且非常不同的本地shell：cmd和powershell，还有其他可用的shell，例如sh。SHELL指令可以出现多次。每个SHELL指令都会覆盖所有先前的SHELL指令，并影响所有后续指令。例如：FROM microsoft/windowsservercore# Executed as cmd /S /C echo defaultRUN echo default# Executed as cmd /S /C powershell -command Write-Host defaultRUN powershell -command Write-Host default# Executed as powershell -command Write-Host helloSHELL [&quot;powershell&quot;, &quot;-command&quot;]RUN Write-Host hello# Executed as cmd /S /C echo helloSHELL [&quot;cmd&quot;, &quot;/S&quot;, &quot;/C&quot;]RUN echo hello当在Dockerfile中使用它们的shell形式时，以下指令可能会受到SHELL指令的影响：RUN、CMD和ENTRYPOINT。以下示例是在Windows上常见的模式，可以通过使用SHELL指令来简化：RUN powershell -command Execute-MyCmdlet -param1 &quot;c:\\foo.txt&quot;docker 调用的命令将是：cmd /S /C powershell -command Execute-MyCmdlet -param1 &quot;c:\\foo.txt&quot;这是低效的，原因有二。首先，调用了一个不必要的 cmd.exe 命令处理器（又名 shell）。其次，shellRUN形式中的每条指令都 需要一个额外的命令前缀。powershell -command为了提高效率，可以采用两种机制中的一种。一种是使用 RUN 命令的 JSON 形式，例如：RUN [&quot;powershell&quot;, &quot;-command&quot;, &quot;Execute-MyCmdlet&quot;, &quot;-param1 \\&quot;c:\\\\foo.txt\\&quot;&quot;]虽然 JSON 形式是明确的并且不使用不必要的 cmd.exe，但它确实需要通过双引号和转义来更加冗长。替代机制是使用SHELL指令和shell形式，为 Windows 用户提供更自然的语法，尤其是与escape解析器指令结合使用时：# escape=`FROM microsoft/nanoserverSHELL [&quot;powershell&quot;,&quot;-command&quot;]RUN New-Item -ItemType Directory C:\\ExampleADD Execute-MyCmdlet.ps1 c:\\example\\RUN c:\\example\\Execute-MyCmdlet -sample &#39;hello world&#39;优雅的Dockerfile原则编写优雅的Dockerfile主要需要注意以下几点： Dockerfile文件不宜过长，层级越多最终制作出来的镜像也就越大。 构建出来的镜像不要包含不需要的内容，如日志、安装临时文件等。 尽量使用运行时的基础镜像，不需要将构建时的过程也放到运行时的Dockerfile里。以下两个Dockerfile实例进行简单的对比FROM ubuntu:16.04RUN apt-get updateRUN apt-get install -y apt-utils libjpeg-dev \\ python-pipRUN pip install --upgrade pipRUN easy_install -U setuptoolsRUN apt-get cleanFROM ubuntu:16.04RUN apt-get update &amp;amp;&amp;amp; apt-get install -y apt-utils \\ libjpeg-dev python-pip \\ &amp;amp;&amp;amp; pip install --upgrade pip \\ &amp;amp;&amp;amp; easy_install -U setuptools \\ &amp;amp;&amp;amp; apt-get clean第一个Dockerfile，乍一看条理清晰，结构合理，似乎还不错。再看第二个Dockerfile，紧凑，不易阅读，为什么要这么写？第一个Dockerfile的好处是：当正在执行的过程某一层出错，对其进行修正后再次Build，前面已经执行完成的层不会再次执行。这样能大大减少下次Build的时间，而它的问题就是会因层级变多了而使镜像占用的空间也变大。第二个Dockerfile把所有的组件全部在一层解决，这样做能一定程度上减少镜像的占用空间，但在制作基础镜像的时候若其中某个组编译出错，修正后再次Build就相当于重头再来了，前面编译好的组件在一个层里，得全部都重新编译一遍，比较消耗时间。从下表可以看出两个Dockerfile所编译出来的镜像大小：$ docker images | grep ubuntu REPOSITORY TAG IMAGE ID CREATED SIZE ubuntu 16.04 93623e635431 1 days ago 422MB ubuntu 16.04-1 3g5b329df1a9 1 days ago 412MB 仅从镜像大小来看好像并没有特别的效果，但若Dockerfile非常长的话可以考虑减少层次，因为Dockerfile最高只能有127层。Dockerfile案例 使用Java jar包打包镜像# FROM ibm-semeru-runtimes:open-11-jre# 需减少容器内存占用使用ibm-semeru-runtimesFROM openjdk:11WORKDIR /home COPY *.jar app.jar COPY application.yml application.yml EXPOSE 8080ENTRYPOINT [&quot;java&quot;,&quot;-jar&quot;,&quot;app.jar&quot;,&quot;--spring.config.location=application.yml&quot;] 使用Maven基础镜像完成SpringBoot编译打包镜像FROM maven:3.3.3ADD pom.xml /tmp/build/RUN cd /tmp/build &amp;amp;&amp;amp; mvn -q dependency:resolveADD src /tmp/build/src #构建应用RUN cd /tmp/build &amp;amp;&amp;amp; mvn -q -DskipTests=true package \\ #拷贝编译结果到指定目录 &amp;amp;&amp;amp; mv target/*.jar /app.jar \\ #清理编译痕迹 &amp;amp;&amp;amp; cd / &amp;amp;&amp;amp; rm -rf /tmp/buildVOLUME /tmpEXPOSE 8080ENTRYPOINT [&quot;java&quot;,&quot;-Djava.security.egd=file:/dev/./urandom&quot;,&quot;-jar&quot;,&quot;/app.jar&quot;]使用多阶构Docker在升级到Docker 17.05之后就能支持多阶构建了，为了使镜像更加小巧，我们采用多阶构建的方式来打包镜像。在多阶构建出现之前我们通常使用一个Dockerfile或多个Dockerfile来构建镜像。单文件构建在多阶构建出来之前使用单个文件进行构建，单文件就是将所有的构建过程（包括项目的依赖、编译、测试、打包过程）全部包含在一个Dockerfile中之下：FROM golang:1.11.4-alpine3.8 AS build-envENV GO111MODULE=offENV GO15VENDOREXPERIMENT=1ENV BUILDPATH=github.com/lattecake/helloRUN mkdir -p /go/src/${BUILDPATH}COPY ./ /go/src/${BUILDPATH}RUN cd /go/src/${BUILDPATH} &amp;amp;&amp;amp; CGO_ENABLED=0 GOOS=linux GOARCH=amd64 go install –vCMD [/go/bin/hello]这种的做法会带来一些问题： Dockerfile文件会特别长，当需要的东西越来越多的时候可维护性指数级将会下降； 镜像层次过多，镜像的体积会逐步增大，部署也会变得越来越慢； 代码存在泄漏风险。以Golang为例，它运行时不依赖任何环境，只需要有一个编译环境，那这个编译环境在实际运行时是没有任务作用的，编译完成后，那些源码和编译器已经没有任务用处了也就没必要留在镜像里。 REPOSITORY TAG IMAGE ID CREATED SIZE Hello 16.04 23g3gff98442 1 min ago 312MB 单文件构建最终占用了312MB的空间多文件构建在多阶构建出来之前有没有好的解决方案呢？有，比如采用多文件构建或在构建服务器上安装编译器，不过在构建服务器上安装编译器这种方法我们就不推荐了，因为在构建服务器上安装编译器会导致构建服务器变得非常臃肿，需要适配各个语言多个版本、依赖，容易出错，维护成本高。所以这里只介绍多文件构建的方式。多文件构建，其实就是使用多个Dockerfile，然后通过脚本将它们进行组合。假设有三个文件分别是：Dockerfile.run、Dockerfile.build、build.sh。 Dockerfile.run就是运行时程序所必须需要的一些组件的Dockerfile，它包含了最精简的库； Dockerfile.build只是用来构建，构建完就没用了； build.sh的功能就是将Dockerfile.run和Dockerfile.build进行组成，把Dockerfile.build构建好的东西拿出来，然后再执行Dockerfile.run，算是一个调度的角色。FROM golang:1.11.4-alpine3.8 AS build-envENV GO111MODULE=offENV GO15VENDOREXPERIMENT=1ENV BUILDPATH=github.com/lattecake/helloRUN mkdir -p /go/src/${BUILDPATH}COPY ./ /go/src/${BUILDPATH}RUN cd /go/src/${BUILDPATH} &amp;amp;&amp;amp; CGO_ENABLED=0 GOOS=linux GOARCH=amd64 go install –vFROM alpine:latestRUN apk –no-cache add ca-certificatesWORKDIR /rootADD hello .CMD [&quot;./hello&quot;]#!/bin/shdocker build -t –rm hello:build . -f Dockerfile.builddocker create –name extract hello:builddocker cp extract:/go/bin/hello ./hellodocker rm -f extractdocker build –no-cache -t –rm hello:run . -f Dockerfile.runrm -rf ./hello执行build.sh完成项目的构建。 REPOSITORY TAG IMAGE ID CREATED SIZE Hello2 - 453je92fo212 1 min ago 7.33MB Hello - sf39f4i30itf 1 min ago 312MB 从上表可以看到，多文件构建大大减小了镜像的占用空间，但它有三个文件需要管理，维护成本也更高一些。多阶构建最后我们来看看万众期待的多阶构建。完成多阶段构建我们只需要在Dockerfile中多次使用FORM声明，每次FROM指令可以使用不同的基础镜像，并且每次FROM指令都会开始新的构建，我们可以选择将一个阶段的构建结果复制到另一个阶段，在最终的镜像中只会留下最后一次构建的结果，这样就可以很容易地解决前面提到的问题，并且只需要编写一个Dockerfile文件。这里值得注意的是：需要确保Docker的版本在17.05及以上。下面我们来说说具体操作。在Dockerfile里可以使用as来为某一阶段取一个别名”build-env”：FROM golang:1.11.2-alpine3.8 AS build-env然后从上一阶段的镜像中复制文件，也可以复制任意镜像中的文件：COPY –from=build-env /go/bin/hello /usr/bin/hello看一个简单的例子：FROM golang:1.11.4-alpine3.8 AS build-env ENV GO111MODULE=offENV GO15VENDOREXPERIMENT=1ENV GITPATH=github.com/lattecake/helloRUN mkdir -p /go/src/${GITPATH}COPY ./ /go/src/${GITPATH}RUN cd /go/src/${GITPATH} &amp;amp;&amp;amp; CGO_ENABLED=0 GOOS=linux GOARCH=amd64 go install -v FROM alpine:latestENV apk –no-cache add ca-certificatesCOPY --from=build-env /go/bin/hello /root/helloWORKDIR /rootCMD [&quot;/root/hello&quot;]执行docker build -t –rm hello3 .后再执行docker images ，然后我们来看镜像的大小： REPOSITORY TAG IMAGE ID CREATED SIZE Hello3 - 21ae345mi453 1 min ago 7.2MB Hello2 - 32mk4sap0ml4 1 min ago 7.23MB Hello - a32sd23j0154 1 min ago 312MB 多阶构建给我们带来很多便利，最大的优势是在保证运行镜像足够小的情况下还减轻了Dockerfile的维护负担，因此极力推荐使用多阶构建来将你的代码打包成Docker 镜像。参考 Dockerfile reference 如何编写优雅的Dockerfile 深入Dockerfile（一）: 语法指南 Dockerfile: ENTRYPOINT和CMD的区别" }, { "title": "Portainer 在 VPS 的部署流程", "url": "/posts/deploy-portainer-in-vps/", "categories": "Tech Projects", "tags": "Docker, GeekDairy, 安装流程, Nginx", "date": "2022-07-23 21:07:00 +0800", "snippet": "介绍Portainer 是一个轻量级的管理 UI ，可让你轻松管理不同的 Docker 环境（Docker 主机或 Swarm 群集）。它由可在任何 Docker 引擎上运行的单个容器组成Portainer 由两个元素组成，Portainer Server和Portainer Agent 。这两个元素在 Docker 引擎上作为轻量级 Docker 容器运行。本文档将帮助您在 Linux 环境中安装 Portainer Server 容器。部署Portainer部署前置条件最新版本的 Docker 已安装并运行在要安装 Portainer 的服务器实上启用 sudo 权限默认情况下，Portainer Server 将通过 port 公开 UI，9443并通过 port 公开 TCP 隧道服务器8000。后者是可选的，仅在计划将边缘计算功能与边缘代理一起使用时才需要。部署流程首先，创建 Portainer Server 将用于存储其数据库的Docker volume ：docker volume create portainer_data然后，拉取并安装 Portainer Server 容器、docker run -d -p 8000:8000 -p 9443:9443 --name portainer --restart=always -v /var/run/docker.sock:/var/run/docker.sock -v portainer_data:/data portainer/portainer-ce:2.11.1 默认情况下，Portainer 会生成并使用自签名 SSL 证书来保护 port 9443。或者，您可以在安装期间或在安装完成后通过 Portainer UI提供您自己的 SSL 证书。 If you require HTTP port 9000 open for legacy reasons, add the following to your docker run command: -p 9000:9000Portainer 服务器现已安装完毕。可以通过运行检查 Portainer Server 容器是否已启动 docker ps：root@server:~# docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES de5b28eb2fa9 portainer/portainer-ce:2.11.1 &quot;/portainer&quot; 2 weeks ago Up 9 days 0.0.0.0:8000-&amp;gt;8000/tcp, :::8000-&amp;gt;8000/tcp, 0.0.0.0:9443-&amp;gt;9443/tcp, :::9443-&amp;gt;9443/tcp portainer配置Nginx的反向代理在VPS上部署为了保证服务器安全会选择开放尽可能少的端口到公网，这时通常我们会使用Nginx来做一个服务器托管服务的统一反向代理。由于我使用了宝塔面板进行服务器管理，所以使用宝塔面板提供的UI建立一个反向代理站点来代理Portainer控制面板，步骤如下 在Cloudflare或者其他DNS服务商注册一共供Portainer面板使用的域名并解析到部署服务器后 在宝塔面板新建一个站点绑定刚刚解析的域名，可以直接打开查看站点是否搭建成功 在宝塔面板-&amp;gt;站点选项-&amp;gt;反向代理选项卡中选择新建反向代理，目标URL填写 https://127.0.0.1:9443 ，然后点击确定完成反向代理配置 最后在宝塔面板-&amp;gt;站点选项-&amp;gt;SSL选项卡对此站点使用Let’s Encrypt加密开启HTTPS这时候就完成了部署的全过程，现在安装已完成，可以通过打开 Web 浏览器并转到解析的域名登录您的 Portainer 服务器实例。" }, { "title": "Proxmox VE直通硬盘", "url": "/posts/passthrough-hard-drive-in-proxmox-ve/", "categories": "Tech Projects", "tags": "PVE, GeekDairy", "date": "2022-06-14 14:37:00 +0800", "snippet": "使用PVE有时为了方便，需要将硬盘直通, PVE系统直通硬盘有两种方式，方法一命令操作，直通单块硬盘；方法二添加 PCI设备，直通 SATA Controller(SATA 控制器)。全盘映射查找磁盘ID进入Proxmox VE(PVE)系统的SSH，或直接进入PVE管理网页Shell输入命令：ls -l /dev/disk/by-id/lrwxrwxrwx 1 root root 9 Jun 12 09:36 ata-GALAX_TA1D0240A_305D0********0279966 -&amp;gt; ../../sdalrwxrwxrwx 1 root root 10 Jun 12 09:36 ata-GALAX_TA1D0240A_305D0********0279966-part1 -&amp;gt; ../../sda1lrwxrwxrwx 1 root root 10 Jun 12 09:36 ata-GALAX_TA1D0240A_305D0********0279966-part2 -&amp;gt; ../../sda2lrwxrwxrwx 1 root root 10 Jun 12 09:36 ata-GALAX_TA1D0240A_305D0********0279966-part3 -&amp;gt; ../../sda3lrwxrwxrwx 1 root root 9 Jun 12 09:58 ata-ST1000DM003-1****2_W********7 -&amp;gt; ../../sdblrwxrwxrwx 1 root root 10 Jun 12 09:36 dm-name-pve-root -&amp;gt; ../../dm-1lrwxrwxrwx 1 root root 10 Jun 12 09:36 dm-name-pve-swap -&amp;gt; ../../dm-0lrwxrwxrwx 1 root root 10 Jun 12 09:36 dm-name-pve-vm--100--disk--0 -&amp;gt; ../../dm-8lrwxrwxrwx 1 root root 10 Jun 12 09:36 dm-name-pve-vm--101--disk--0 -&amp;gt; ../../dm-7lrwxrwxrwx 1 root root 10 Jun 12 09:36 dm-name-pve-vm--105--disk--0 -&amp;gt; ../../dm-6lrwxrwxrwx 1 root root 10 Jun 12 09:36 dm-name-pve-vm--200--disk--0 -&amp;gt; ../../dm-9lrwxrwxrwx 1 root root 10 Jun 12 09:36 dm-uuid-LVM-ezreio8tLBAyf5iIBYW5HS*********ZgzGBJxLqknLHZ05EUcCM0h3lWV -&amp;gt; ../../dm-1lrwxrwxrwx 1 root root 10 Jun 12 09:36 dm-uuid-LVM-ezreio8tLBAyf5iIBYW5HS*********nbQKEmdsTHkKIe8j2Ou0mfRwXNL -&amp;gt; ../../dm-7lrwxrwxrwx 1 root root 10 Jun 12 09:36 dm-uuid-LVM-ezreio8tLBAyf5iIBYW5HS*********OS0i5zs3870PzzgRxluMPy9qALl -&amp;gt; ../../dm-8lrwxrwxrwx 1 root root 10 Jun 12 09:36 dm-uuid-LVM-ezreio8tLBAyf5iIBYW5HS*********SUJ1HHzTaROYIrVWHsoN9fZ4XiM -&amp;gt; ../../dm-9lrwxrwxrwx 1 root root 10 Jun 12 09:36 dm-uuid-LVM-ezreio8tLBAyf5iIBYW5HS*********FE8hXy66BHq4Hf0HjxNMkUgqXnb -&amp;gt; ../../dm-0lrwxrwxrwx 1 root root 10 Jun 12 09:36 dm-uuid-LVM-ezreio8tLBAyf5iIBYW5HS*********4PcYIkPqUFwmS91bfMSRwlA9vxR -&amp;gt; ../../dm-6lrwxrwxrwx 1 root root 10 Jun 12 09:36 lvm-pv-uuid-2oucQP-****-****-****-****-****-gm99Po -&amp;gt; ../../sda3lrwxrwxrwx 1 root root 9 Jun 12 09:58 wwn-0x500********f289 -&amp;gt; ../../sdb这里必需选择的是整个硬盘(物理硬盘)而不是分区，比如sda、sdb、sdc对应的id，而不是(sda1、sda2…) 注：ata、mmc等…表示接口方式，通常有ATA、SATA、SCS、NVME、eMMC和SASI等类型。IDE和SATA接口一般为“ata”，SCSI及SAS接口一般为”scsi“。硬盘映射将物理磁盘直通给PVE系统下虚拟机中需要在shell下通过CLI的方式来添加，使用的工具为qm(Qemu/KVM虚拟机管理器)，通过命令 set 来设置物理磁盘到虚拟机中。qm set &amp;lt;vm_id&amp;gt; –&amp;lt;disk_type&amp;gt;[n] /dev/disk/by-id/&amp;lt;type&amp;gt;-$brand-$model_$serial_number注释： m_id : 为创建虚拟机时指定的VM ID。 &amp;lt;disk_type&amp;gt;[n]： 磁盘的总线类型及其编号，总线类型可以选择IDE、SATA、VirtIO Block和SCSI类型，编号从0开始，最大值根据总线接口类型有所不同，IDE为3，SATA为5，VirTIO Block为15，SCSI为13。 “/dev/disk/by-id/-brand-brand−model_$serial_number” ： 为磁盘ID的具体路径和名称。 按照我硬盘的参数举例：如上方的硬盘数据 ata-ST1000DM003-1****2_W****7 为例，将此硬盘直通给VM ID编号为200的虚拟机下，总线类型接口为sata0（请根据PVE虚拟机下的总线编号设置）挂载命令如下：qm set 200 -sata0 /dev/disk/by-id/ata-ST1000DM003-1****2_W********7，硬盘直通完成后，返回update VM 200: -sata0 /dev/disk/by-id/ata-ST1000DM003-1****2_W********7为直通成功。检查然后进入PVE虚拟机管理网页,查看是否真的挂载成功。如果看到PVE 200 虚拟机下的硬件设备里有直通的硬盘,就说明成功。如上图中所示，如果有橘黄色字体显示该设置并未生效，请从PVE控制台的重启虚拟机后生效。直通 SATA Controller/PCI-E 阵列卡Proxmox VE(PVE)系统直通SATA Controller(SATA 控制器)，会把整个sata总线全部直通过去，就是直接将南桥或者直接把北桥连接的sata总线直通，那么有些主板sata接口就会全部被直通。 注意：如果您的PVE系统是安装在SATA的硬盘中，会导致PVE系统无法启动，所以在直通 SATA Controller(SATA 控制器)，之前请先确认自己的PVE系统安装位置，或者直接将系统安装在 NVMe 硬盘中。 在开始之前开启IOMMU硬件直通功能(需要CPU支持VT-D)，执行下一步添加 SATA Controller（SATA 控制器）/PCI-E 阵列卡操作。选择需要设置的PVE系统，点击 硬件 &amp;gt; 添加 &amp;gt; PCI设备 &amp;gt; 选择 SATA Controller（SATA 控制器），最后点击“添加”把 SATA Controller（SATA 控制器）添加给相应的系统后，完成重启，PVE硬件直通的设置就生效了。" }, { "title": "4种强化域名安全的协议", "url": "/posts/4-protocols-for-enhanced-domain-name-security/", "categories": "Bottom Layer Knowledge", "tags": "协议解析, Internet Security, Network", "date": "2022-05-22 20:47:00 +0800", "snippet": "传统的 DNS 有啥问题传统的 DNS 是一个【比较古老】的协议。最早的草案可以追溯到1983年。1987年定稿之后，基本上没啥变化。设计 DNS 的时候，互联网基本上还是个玩具。那年头的互联网协议，压根儿都没考虑安全性，DNS 当然也不例外。所以 DNS 的交互过程全都是【明文】滴，既无法做到“保密性”，也无法实现“完整性”。缺乏“保密性”就意味着——任何一个能【监视】你上网流量的人，都可以【看到】你查询了哪些域名。直接引发的问题就是隐私风险。缺乏“完整性”就意味着——任何一个能【修改】你上网流量的人，都可以【篡改】你的查询结果。直接引发的问题就是“DNS 欺骗”（也叫“DNS 污染”或“DNS 缓存投毒”）为了解决传统 DNS 的这些弊端，后来诞生了好几个网络协议，以强化域名系统的安全性DNSSEC历史这玩意儿是“Domain Name System Security Extensions”的缩写。在今天介绍的4个协议中，DNSSEC 是最早诞生的（1997）。从最先的 RFC 2065 进化为 RFC 2535，再到 RFC 4033、RFC 4034、RFC 4035。在今天介绍的4个协议中，DNSSEC 也是最早大规模部署的。在2010年的时候，所有根域名服务器都已经部署了 DNSSEC。到了2011年，若干顶级域名（.org 和 .com 和 .net 和 .edu）也部署了 DNSSEC。协议栈-------- DNSSEC-------- UDP-------- IP--------安全性的原理当初设计 DNSSEC 的一个考虑是“尽可能兼容 DNS 协议”。所以 DNSSEC 只是在 DNS 协议的基础上增加了一个【数字签名机制】。有了数字签名，如果域名查询的结果被人篡改了，DNSSEC 客户端就可以通过【校验签名】，判断查询结果是假的。套用信息安全的行话——DNSSEC 实现了【完整性】（也叫“不可篡改性”）。由于 DNSSEC 引入了【数字签名】，就需要有【公私钥对】。私钥是保密的，用来生成签名；公钥是公开的，用来验证签名。DNSSEC 客户端可以向 DNSSEC 服务器发出请求，获得一个 DNSKEY 记录，里面含公钥；然后用这个公钥校验每次的查询结果。信任链的实现有些聪明的老哥会问了：DESSEC 客户端在向服务器请求公钥的过程中，如果被攻击者篡改了，得到一个假的公钥，那该如何是好？为了解决此问题，DNSSEC 体系要求【上级域】来担保。比如想要证明 optiomus-xs.github.io 这个域名的公钥是否可信，就依靠 github.io 这个域名的公钥来验证。通过层层追溯，最后达到【根域名服务器】。而“根域名服务器的公钥”是事先就部署在客户端的——这玩意儿就是整个信任链的根源，称之为“信任锚”（Trust Anchor）。优点 这4个协议中，DNSSEC 应该是最成熟的。除了前面提到的广泛部署，大多数公共的域名服务器也都支持它。在这4个协议中，支持 DNSSEC 的最多。缺点 虽然 DNSSEC 最成熟，但它有个天生的缺陷——【没有】考虑到【保密性】。 DNSSEC 虽然对传输的数据做了数字签名，但是【没有】进行加密。这就意味着——任何能监视你网络流量的人，也可以看到你通过 DNSSEC 查询了哪些域名。 Chrome 曾经在 14 版本支持过 DNSSEC，后来又【移除】了；而 Firefox 官方从未支持过 DNSSEC 协议。DNSCrypt历史第2个出场的是 DNSCrypt。这个协议是由 Frank Denis 和 Yecheng Fu两人设计的。这个协议从来【没有】提交过 RFC（征求意见稿），要想看它的协议实现，只能去它的官网历史上有过两个版本，分别称：Version 1 和 Version 2。如今主要使用“版本2”协议栈---------------- DNSCrypt---------------- TCP or UDP---------------- IP----------------安全性的原理前面提到 DNSSEC 协议强调兼容性。而 DNSCrypt 则完全是另起炉灶搞出来的协议。在这个协议中，域名的“查询请求”与“响应结果”都是加密的。这就是它比 DNSSEC 高级的地方。换句话说，DNSCrypt 既能做到【完整性】，也能做到【保密性】；相比之下，DNSSEC 只能做到【完整性】。信任链的实现DNSCrypt 的信任链比较简单——客户端要想使用哪个 DNSCrypt 服务器，就需要预先部署该服务器的公钥。另外，DNSCrypt 还支持客户端认证（作为可选项）。如果需要的话，可以在服务器上部署客户端的公钥。此时，服务器只接受可信的客户端的查询请求。优点 如前所述，DNSCrypt 同时支持【完整性】与【保密性】。在隐私方面完胜 DNSSEC。 在下层协议方面，DNSCrypt 同时支持 TCP 和 UDP，显然比 DNSSEC 灵活（DNSSEC 只支持 UDP）。 顺便提醒一下：虽然 DNSCrypt 协议默认使用 443 这个端口号，但该协议与 HTTPS 毫无关系。缺点 DNSCrypt 最大的缺点就是前面提到的：【从未】提交过 RFC。没有 RFC 也就无法通过 IETF（互联网工程任务组）进行标准化。一个无法标准化的协议，其生命力要打很大的折扣。 另一个比较小的缺点是——虽然 DNSCrypt 协议是加密的，但可以被识别出来。换句话说：如果有人监控你的流量，可以识别出哪些流量属于 DNSCrypt 协议。 Google 和 Cloudflare 的公共域名系统【尚未】支持 DNSCryptDNS over TLS“DNS over TLS”有时也被简称为【DoT】。为了打字省力，本文以下部分用 DoT 来称呼之历史DoT 已经正式发布了 RFC（参见 RFC 7858 和 RFC 8310）。从时间上看，RFC7858 是2016年发布的，RFC8310 是今年（2018）发布的；显然，这个协议出现得比较晚（相比前面提到的 DNSSEC 和 DNSCrypt）。协议栈-------- DoT-------- TLS-------- TCP-------- IP--------安全性的原理顾名思义，DNS over TLS 就是基于 TLS 隧道之上的域名协议。由于 TLS 本身已经实现了【保密性】与【完整性】，因此 DoT 自然也就具有这两项特性。信任链的实现DoT 的信任链依赖于 TLS，而 TLS 的信任链靠的是 CA 证书体系优点 相比 DNSSEC，DoT 具备了【保密性】； 相比 DNSCrypt，DoT 已经标准化。 另外，由于 DoT 协议是完全包裹在 TLS 里面，即使有人监视你的上网流量，也无法判断——哪些 TLS 流量是用于域名查询，哪些 TLS 用于网页传输。换句话说，DoT 协议的流量无法被【单独识别】出来。缺点支持 DoT 的客户端还不够多。尤其是主流的浏览器还没有计划增加 DoT 的支持DNS over HTTPS“DNS over HTTPS”有时也被简称为【DoH】。为了打字省力，本文以下部分用 DoH 来称呼历史在今天介绍的4个协议中，DoH 是最新的（最晚出现的）。RFC 方面，它已经有了相应的草案，但还【没有】正式发布。截至写本文时，DoH 的草案已经发了 15 个版本（从 00 到 14），最新版很多人把 DoH 与 DoT 混为一谈，实际上这是两种不同的协议。你可以对比这两者的协议栈，（只要没有星际玩家）就可看出其中的差别。协议栈-------- DoH-------- HTTP-------- TLS-------- TCP-------- IP--------安全性的原理顾名思义，DNS over HTTPS 就是基于 HTTPS 隧道之上的域名协议。而 HTTPS 又是“HTTP over TLS”。所以 DoH 相当于是【双重隧道】的协议。与 DoT 类似，DoH 最终也是依靠 TLS 来实现了【保密性】与【完整性】信任链的实现DoH 类似于 DoT，最终是靠 TLS 所使用的“CA 证书体系”来实现信任链优点 基本上，DoT 具备的优点，DoH 也具备。 相比 DoT，DoH 还多了一个优点： 由于 DoH 是基于 HTTP 之上。而主流的编程语言都有成熟的 HTTP 协议封装库；再加上 HTTP 协议的使用本身很简单。因此，要想用各种主流编程语言开发一个 DoH 的客户端，是非常容易滴缺点 如前所述，DoH 目前还只有 RFC 的草案，尚未正式发布。这算是一个缺点。 相比 DoT，DoH 还有一个小缺点——由于 DoH 比 DoT 多了一层（请对比两者的协议栈），所以在性能方面，DoH 会比 DoT 略差。为啥说这是个【小】缺点捏？因为域名的查询并【不】频繁，而且客户端软件可以很容易地对域名的查询结果进行【缓存】（以降低查询次数）。所以 DoH 比 DoT 性能略差，无伤大雅。" }, { "title": "Gin 中的 BasicAuth授权认证中间件使用", "url": "/posts/the-basicauth-authorization-middleware-in-gin/", "categories": "Software Development", "tags": "Go, DevDairy", "date": "2022-05-14 20:35:00 +0800", "snippet": "什么是BasicAuth是一种开放平台认证方式，简单的说就是需要你输入用户名和密码才能继续访问。在单路由中使用如果需要针对单个路由使用，在要在单路由中注册BasicAuth中间件即可。// 使用BasicAuth中间件func main(){ engine := gin.Default() // 设置账号和密码，key:代表账号,value:代表密码 ginAccounts := gin.Accounts{ &quot;user&quot;:&quot;password&quot;, &quot;abc&quot;:&quot;123&quot;, } // 注册路由和中间件 engine.GET(&quot;/test&quot;,gin.BasicAuth(ginAccounts), func(context *gin.Context) { // 获取中间件BasicAuth user := context.MustGet(gin.AuthUserKey).(string) fmt.Println(user) context.JSON(200,gin.H{&quot;msg&quot;:&quot;success&quot;}) }) _ = engine.Run()}在路由组中使用绝大部分情况下,我们都是在路由组中使用BasicAuth中间件。func RunUseBasicAuthWithGroup() { engine := gin.Default() // 注册路由组和中间件 userGroup := engine.Group(&quot;/user&quot;, gin.BasicAuth(gin.Accounts{ &quot;abc&quot;: &quot;123&quot;, })) userGroup.GET(&quot;info&quot;, func(context *gin.Context) { context.JSON(200, gin.H{&quot;msg&quot;: &quot;user.info&quot;}) })}" }, { "title": "海量积分数据实时排名处理方式", "url": "/posts/real-time-ranking-processing-of-huge-amount-of-points-data/", "categories": "Bottom Layer Knowledge", "tags": "Architecture Design", "date": "2022-05-12 20:08:00 +0800", "snippet": "需求概述积分排名在很多项目都会出现，大家都不会陌生，需求也很简单，积分排名主要满足以下需求： 查询用户名次。 查询TopN(即查询前N名的用户) 实时排名（很多项目是可选的）当排序的数据量不大的时候，这个需求很容易满足，但是如果数据量很大的时候比如百万级、千万级甚至上亿的时候，或者有实时排名需求；这个时候要满足性能、低成本等需求，在设计上就变得复杂起来了常规积分排名处理这里列举下日常对于排名的常规做法和缺陷。数据库解决方案这是最简单的做法，数据存储在数据库里面，然后利用数据库做排序处理。这里分两种情况：单库/单表参与排名的数据量小的时候的做法，所有数据存储在一张表上。查询操作示例：查询用户名次:SELECT count(*) as rank FROM 积分表 WHERE 积分 &amp;gt; (SELECT 积分 FROM 积分表 WHERE uid=’用户ID’)查询前N名：SELECT uid, 积分 FROM 积分表 ORDER BY 积分 DESC LIMIT 0,N分库/分表对于这种情况数据不在一块，在查询操作上跟上面单表情况的区别就是，分库/分表需要做，查询任务切割和查询结果合并处理。查询排名效率低，会造成扫描大量的记录，甚至全表扫描，性能低，在数据量大、高并发的情况下这种方案是不可用的。采用常规排序算法思路上就是把积分排序处理从数据库转移出来，自己实现排序和查询处理。实际排名业务的特点： 每次用户的积分更新都会在一个小的积分范围内波动。 已有的积分数据都是已排序的。常见的几种排序算法大家都熟知这里就不列举了。缺陷：对于海量数据排序处理，简单的使用常规排序算法并不合适，要么就是排序造成大量的数据移动、要么就是对已排序的数据查询名次效率不高。高效的排名算法前面的排名算法都是针对积分进行排序，然后通过统计积分高于自己的人数获得排名。要想知道某个用户的名次，只需要知道比这个用户高分的人数，不一定需要对积分做排序。在这里换个思路不对积分进行排序，仅仅是统计每个积分区间的人数，用积分区间的形式去统计相应的人数，下面是算法描述。根据积分范围创建平衡二叉树设[0, N]为积分范围， 构造的平衡二叉树如下图。每个节点包含两个数据字段（除了指针）： Range: 表示积分范围。 Counts： 表示当前积分区间包含多少人。积分的区间的划分是根据平分的方式，把当前积分范围一分为二生成两个子节点，然后递归的重复该步骤，直到积分区间无法划分为止（即区间[x, y]， x == y）例子：假设积分范围为: [0, 5], 构造的平衡二叉树如下图：节点内的数据表示当前积分区间的人数。从上图可以看出来，所有积分都在叶子节点，叶子节点即最小粒度的积分区间。统计相应积分区间的人数这里主要有两种操作：假设积分为i添加积分添加积分的过程就是查找积分i， 同时累加查找过程经过的节点计数。下面给出操作例子，注意观察操作路径。例： 需要添加积分3， 结果如下图接着在添加积分4，结果如下图接着再添加积分4，结果如下图接着添加积分2，结果如下图删除积分删除积分的过程也是查找积分i， 区别是查找过程经过的节点计数全部减1。 只有积分是存在的情况下，才能做删除操作，另外用一组标记，标识积分是否存在，这里就不列举了。例子： 删除积分4， 结果如下图查询名次操作查询某个积分的排名的过程也是查找积分i的过程，下面是查找过程统计节点计数的算法：对于查找路径上的任意节点，如果积分在左节点区间，则累加右节点区间的计数。最终累加计数的结果加1即是积分的名次例子： 查找积分3的名次蓝色节点是查找积分3经过的路径，红色节点是需要累加的计数值。最终结果是：0 + 1 + 1， 积分3的名次是第2名从上面的算法可以看出，对平衡二叉树的操作，算法复杂度是O(log N), N是最大积分。在积分范围不变的情况下，算法复杂度是稳定的，跟用户量无关，因此可以实现海量用户积分排名、实时排名算法需要。对于海量积分数据实时排名、这里给出的是核心算法，实际业务的时候还需要增加一些额外的处理，比如uid于积分的映射表用于记录用户历史积分、积分与uid的映射表用于TopN这种查询前N名的需求、数据持久化、高可用等需求。" }, { "title": "堆的原理和实现", "url": "/posts/principle-and-implementation-of-heaps/", "categories": "Bottom Layer Knowledge", "tags": "Data Structure", "date": "2022-05-03 19:43:00 +0800", "snippet": "堆堆这种数据结构，有很多的实现，比如：最大堆，最小堆，斐波那锲堆，左派堆，斜堆等。从孩子节点的个数上还可以分为二叉堆，N叉堆等。本文我们从最大二叉堆堆入手看看堆究竟是什么什么是堆我们先看看它的定义 堆是一种完全二叉树（不是平衡二叉树，也不是二分搜索树哦） 堆要求孩子节点要小于等于父亲节点（如果是最小堆则大于等于其父亲节点）满足以上两点性质即可成为一棵合格的堆数据结构。我们解读一下上面的两点性质 堆是一种完全二叉树，要注意堆是一种建立在二叉树上的数据结构，不同于AVL或者红黑树是建立在二分搜索树上的数据结构。 堆要求孩子节点要大于等于父亲节点，该定义是针对的最大堆。对于最小堆，孩子节点小于或者等于其父亲节点。如上所示，只有图1是合格的最大堆，图2不满足父节点大于或者等于孩子节点的性质。图3不满足完全二叉树的性质。堆的存储结构前面我们说堆是一个完全二叉树，其中一种在合适不过的存储方式就是数组。首先从下图看一下用数组表示堆的可行性。看了上图，说明数组确实是可以表示一个二叉堆的。使用数组来存储堆的节点信息，有一种天然的优势那就是节省内存空间。因为数组占用的是连续的内存空间，相对来说对于散列存储的结构来说，数组可以节省连续的内存空间，不会将内存打乱。接下来看看数组到二叉堆的下标表示。将数组的索引设为 i。则： 左孩子找父节点：parent（i）= （i - 1）/2。比如2元素的索引为5，其父亲节点4的下标parent（2）= （5 - 1）/2 = 2； 右孩子找父节点：parent（i）= （i-2）/ 2。比如0元素找父节点 （6-2）/2= 2； 其实可以将上面的两种方法合并成一个，即 parent（i）= （i - 1）/2 ；从java语法出发大家可以发现，整数相除得到的就是省略了小数位的。所以。。。你懂得。 同理 父节点找左孩子：leftChild(i)= parent(i)* 2 + 1。 父节点找右孩子：rightChild(i) = parent(i)*2 + 2。 最大二叉堆的实现构建基础代码上面分析了数组作为堆存储结构的可行性分析。接下来我们通过数组构建一下堆的基础结构/** * 描述：最大堆 **/ public class MaxHeap&amp;lt;E extends Comparable&amp;lt;E&amp;gt;&amp;gt; { //使用数组存储 private Array&amp;lt;E&amp;gt; data; public MaxHeap(){ data = new Array&amp;lt;&amp;gt;(); } public MaxHeap(int capacity){ data = new Array&amp;lt;&amp;gt;(capacity); } public int size(){ return this.data.getSize(); } public boolean isEmpty(){ return this.data.isEmpty(); } /** * 根据当前节点索引 index 计算其父节点的 索引 * @param index * @return */ private int parent(int index) { if(index ==0){ throw new IllegalArgumentException(&quot;该节点为根节点&quot;); } return (index - 1) / 2;//这里为什么不分左右？因为java中 / 运算符只保留整数位。 } /** * 返回索引为 index 节点的左孩子节点的索引 * @param index * @return */ private int leftChild(int index){ return index*2 + 1; } /** * 返回索引为 index 节点的右孩子节点的索引 * @param index * @return */ private int rightChild(int index){ return index*2 + 2; }}插入和上浮 sift up堆中插入元素意味着该堆的性质可能遭到破坏，所以这是如同向AVL中插入元素后需要再平衡是一个道理，需要调整堆中元素的位置，使之重新满足堆的性质。在最大二叉堆中，要堆化一个元素，需要向上查找，找到它的父节点，大于父节点则交换两个元素，重复该过程直到每个节点都满足堆的性质为止。这个过程我们称之为上浮操作。下面我们用图例描述一下这个过程：如上图5所示，我们向该堆中插入一个元素15。在数组中位于数组尾部。如图6所示，向上查找，发现15大于它的父节点，所以进行交换。如图7所示，继续向上查找，发现仍大于其父节点14。继续交换。然后还会继续向上查找，发现小于其父节点19，停止上浮操作。整个二叉堆通过上浮操作维持了其性质。上浮操作的时间复杂度为O(logn)插入和上浮操作的代码实现很简单，如下所示。/*** 向堆中添加元素* @param e*/public void add(E e){ // 向数组尾部添加元素 this.data.addLast(e); siftUp(data.getSize() - 1);}/*** 上浮操作* @param k*/private void siftUp(int k) { // 上浮，如果大于父节点，进行交换 while(k &amp;gt; 0 &amp;amp;&amp;amp; get(k).compareTo(get(parent(k))) &amp;gt; 0){ data.swap(k, parent(k)); k = parent(k); }}取出堆顶元素和下沉 sift down上面我们介绍了插入和上浮操作，那删除和下沉操作将不再是什么难题。一般的如果我们取出堆顶元素，我们选择将该数组中的最后一个元素替换堆顶元素，返回堆顶元素，删除最后一个元素。然后再对该元素做下沉操作 sift down。接下来我们通过图示看看一下过程。如上图8所示，将堆顶元素取出，然后让最后一个元素移动到堆顶位置。删除最后一个元素，这时得到图9的结果。如图10，堆顶的9元素会分别和其左右孩子节点进行比较，选出较大的孩子节点和其进行交换。很明显右孩子17大于左孩子15。即和右孩子进行交换。如图11，9节点继续下沉最终和其左孩子12交换后，再没有孩子节点。此次过程的下沉操作完成。下沉操作的时间复杂度为O(logn)代码实现仍然是非常简单/*** 取出堆中最大元素* 时间复杂度 O（logn）* @return*/public E extractMax(){ E ret = findMax(); this.data.swap(0, (data.getSize() - 1)); data.removeLast(); siftDown(0); return ret;}13 /*** 下沉操作* 时间复杂度 O（logn）* @param k*/public void siftDown(int k){ while(leftChild(k) &amp;lt; data.getSize()){// 从左节点开始，如果左节点小于数组长度，就没有右节点了 int j = leftChild(k); if(j + 1 &amp;lt; data.getSize() &amp;amp;&amp;amp; get(j + 1).compareTo(get(j)) &amp;gt; 0){// 选举出左右节点最大的那个 j ++; } if(get(k).compareTo(get(j)) &amp;gt;= 0){// 如果当前节点大于左右子节点，循环结束 break; } data.swap(k, j); k = j; }}Replace和HeapifyReplace操作呢其实就是取出堆顶元素然后新插入一个元素。根据我们上面的总结，大家很容易想到。返回堆顶元素后，直接将该元素置于堆顶，然后再进行下沉操作即可。/** * 取出最大的元素，并替换成元素 e * 时间复杂度 O（logn） * @param e * @return */public E replace(E e){ E ret = findMax(); data.set(0, e); siftDown(0); return ret;}Heapify操作就比较有意思了。Heapify本身的意思为“堆化”，那我们将什么进行堆化呢？根据其存储结构，我们可以将任意一个数组进行堆化。将一个数组堆化？what？一个个向最大二叉堆中插入不就行了？呃，如果这样的话，需要对每一个元素进行一次上浮时间复杂度为O(nlogn)。显然这样做的话，时间复杂度控制的不够理想。有没有更好的方法呢。既然这样说了，肯定是有的。思路就是将一个数组当成一个完全二叉树，然后从最后一个非叶子节点开始逐个对飞叶子节点进行下沉操作。如何找到最后一个非叶子节点呢？这也是二叉堆常问的一个问题。相信大家还记得前面我们说过parent(i) = (child(i)-1)/2。这个公式是不分左右节点的哦，自己可以用代码验证一下，在前面的parent()方法中也有注释解释了。那么最后一个非叶子节点其实就是 （(arr.size())/2 - 1）即可。 /** * Heapify * @param arr */ public MaxHeap(E[] arr){ data = new Array&amp;lt;&amp;gt;(arr); for(int i = parent(arr.length - 1); i &amp;gt;= 0; i --){ siftDown(i); }1}" }, { "title": "DNS 协议解析流程", "url": "/posts/dns-workflow/", "categories": "Bottom Layer Knowledge", "tags": "Network, 协议解析", "date": "2022-04-19 13:42:00 +0800", "snippet": "报文分析例子：名称服务器 (nameserver) 地址为 192.168.18.135。该名称服务器管理了一个区域 (zone)，区域的名称为 example.com.。环境中有一台用户终端，地址为 192.168.18.136，其在名称服务器中添加了一条解析记录，记录为 user.example.com，该记录的值为本机的地址。+----------------+ query +--------------------+| Nameserver |&amp;lt;-----------| User || 192.168.18.135 | | 192.168.18.136 || (example.com.) |-----------&amp;gt;| (user.example.com) |+----------------+ answer +--------------------+当用户在终端上将解析服务 (reslover) 的地址指向名称服务器 (192.168.18.135) 时，他就可以通过 user.example.com 这条域名来访问他的终端 (192.168.18.136)用户可以通过 dig、host、ping 等命令来发送 dns 报文，如：[root@user ~]# host user.example.comuser.example.com has address 192.168.18.136在名称服务器上抓包，第一条为 dns 的请求，其报文如下：0000 00 0c 29 8f da 54 00 0c 29 75 2e c5 08 00 45 00 ..).ÚT..)u.Å..E.0010 00 3e 33 fd 00 00 40 11 a0 51 c0 a8 12 89 c0 a8 .&amp;gt;3ý..@. QÀ¨..À¨0020 12 87 eb 5b 00 35 00 2a 6b 67 aa 96 01 00 00 01 ..ë[.5.*kgª.....0030 00 00 00 00 00 00 04 75 73 65 72 07 65 78 61 6d .......user.exam0040 70 6c 65 03 63 6f 6d 00 00 01 00 01 ple.com.....其中”aa 96 01 00 00 01 00 00 00 00 00 00 04 75 73 65 72 07 65 78 61 6d 70 6c 65 03 63 6f 6d 00 00 01 00 01” 为 dns 的报文信息。DNS 查询响应报文的格式如下：|&amp;lt;-- 16 --&amp;gt;|&amp;lt;-- 16 --&amp;gt;|(bit)+----------------+----------------+---| ID | FLAG | ^+----------------+----------------+ || QDCOUNT | ANCOUNT | |+----------------+----------------+| NSCOUNT | ARCOUNT |+----------------+----------------+| QUESTIONs | 12bytes+---------------------------------+| ANSWERs |+---------------------------------+| AUTHORITYs | |+---------------------------------+ || ADDITIONALs | v+---------------------------------+---根据上述格式分析 dns 的请求报文信息： 标识 (ID) 为”aa 96” 标志 (FLAG) 为随后的”01 00”，转化为 bit 为”00000001 00000000”，其格式如下： +-----+---------+-----+-----+-----+-----+-------+--------+ |QR(1)|opcode(4)|AA(1)|TC(1)|RD(1)|RA(1)|zero(3)|rcode(4)| +-----+---------+-----+-----+-----+-----+-------+--------+ 根据下述格式及含义，本条报文的标志部分的含义为：本报文为查询报文，非授权回答，不可截断，期望递归查询，返回码为没有差错。 QR：0 表示查询报文，1 表示响应报文。 opcode：0 表示标准查询，1 为反向查询，2 为服务器状态请求，3 暂无定义，4 为通知 (Notify)，5 为更新 (Update)，6-15 暂无定义 AA：表示 “授权回答 (authoritative answer)”。该名字服务器是授权于该域的。 TC：表示 “可截断的 (truncated)”。使用 UDP 时，它表示当应答的总长度超过 512 字节时，只返回前 512 字节。 RD：表示 “期望递归 (recursion desired)”。该比特能在一个查询中设置，并在响应中返回。这个标志告诉名字服务器必须处理这个查询，也称为一个递归查询。如果该位为 0，且被请求的名字服务器没有一个 授权回答，它就返回一个能解答该查询的其他名字服务器列表，这称为迭代查询。在后面的例子中，我们将看到这两种类型查询的例子。 RA：表示 “可用递归”。如果名字服务器支持递归查询，则在响应中将该比特设置为 1。在后面的例子中可看到大多数名字服务器都提供递归查询，除了某些根服务器。 zero：必须设置为 0，预留给将来的需求 rcode：表示返回码，0 为没有差错，1 为格式错误，2 为服务端失败，3 为不存在的域名，4 为无法执行，5 为请求拒绝，6 为域名异常存在 (不应存在)，7 为解析记录异常存在 (不应存在)，8 为解析记录异 常不存在 (应存在)，9 为名字服务器不能认证该请求区域，10 为请求的域不在区域文件中 问题数 (QDCOUNT)”00 01”，为 16bit 整数，表示请求 (requestiong section) 中包含的查询实体，即有几条查询，默认为 1 条。本条报文问题数部分的含义为：包含了一条查询实体，即 user.example.com。 资源记录数 (ANCOUNT)”00 00”，为 16bit 整数，表示回答 (answer section) 中包含的资源记录数。本条报文资源记录数部分的含义为：并未包含任何资源记录 (因为是查询报文)。 授权资源记录数 (NSCOUNT)”00 00”，为 16bit 整数，表示授权记录 (authority records section) 中包含的名字服务数量。本条报文授权资源记录数部分的含义为：未包含任何授权资源记录数 (因为是查询报文)。 额外资源记录数 (ARCOUNT)”00 00”，为 16bit 整数，表示额外记录 (additional records section) 中资源记录的数量。本条报文额外资源记录数部分的含义为：未包含任意额外记录数 (因为是查询报文)。 查询问题 (QUESTIONs)”04 75 73 65 72 07 65 78 61 6d 70 6c 65 03 63 6f 6d 00 00 01 00 01”，其格式如下： |&amp;lt;----- 32 -----&amp;gt;| +----------------------------------+ | QNAME | +-----------------+----------------+ | QTYPE | QCLASS | +----------------------------------+ |&amp;lt;-- 16 --&amp;gt;|&amp;lt;-- 16 --&amp;gt;| 其中”04 75 73 65 72 07 65 78 61 6d 70 6c 65 03 63 6f 6d 00” 即表示查询名 (QNAME)，其格式如下： +--------+-+-+-+-+--------+-+-+-+-+-+-+-+--------+-+-+-+--------+ |4(count)|u|s|e|r|7(count)|e|x|a|m|p|l|e|3(count)|c|o|m|0(count)| +--------+-+-+-+-+--------+-+-+-+-+-+-+-+--------+-+-+-+--------+ 每个标识符首部为计数，表示了该标识符的长度，末尾的 0 表示根标识符。标识符最长为 63 字节，所以计数应在 0-63 之间。 查询类型 (QTYPE)”00 01”，即 1，表示 A 记录 (域名 =&amp;gt; 主机号)； 查询类 (QCLASS)”00 01”，即 1，表示 IN 类型； 第二条为 dns 名字服务器应答的报文信息，其报文如下：0000 00 0c 29 75 2e c5 00 0c 29 8f da 54 08 00 45 00 ..)u.Å..).ÚT..E.0010 00 71 be 20 00 00 40 11 15 fb c0 a8 12 87 c0 a8 .q¾ ..@..ûÀ¨..À¨0020 12 89 00 35 dc 20 00 5d a6 cf aa 96 85 80 00 01 ...5Ü .]¦Ï.¥....0030 00 01 00 01 00 01 04 75 73 65 72 07 65 78 61 6d .......user.exam0040 70 6c 65 03 63 6f 6d 00 00 01 00 01 c0 0c 00 01 ple.com.....À...0050 00 01 00 00 02 58 00 04 c0 a8 12 88 c0 11 00 02 .....X..À¨..À...0060 00 01 00 00 02 58 00 07 04 6e 73 30 31 c0 11 c0 .....X...ns01À.À0070 3e 00 01 00 01 00 00 02 58 00 04 c0 a8 12 87 &amp;gt;.......X..À¨..其中”aa 96 85 80 00 01 00 01 00 01 00 01 04 75 73 65 72 07 65 78 61 6d 70 6c 65 03 63 6f 6d 00 00 01 00 01 c0 0c 00 01 00 01 00 00 02 58 00 04 c0 a8 12 88 c0 11 00 02 00 01 00 00 02 58 00 07 04 6e 73 30 31 c0 11 c0 3e 00 01 00 01 00 00 02 58 00 04 c0 a8 12 87” 为 dns 的报文信息根据 DNS 查询响应报文格式，其中： 标识为 (ID)”aa 96”。 标志为 (FLAG)”85 80”，转化为 bit 为”10000101 10000000”，按照标志部分的格式分析： +-----+---------+-----+-----+-----+-----+-------+--------+ |QR(1)|opcode(4)|AA(1)|TC(1)|RD(1)|RA(1)|zero(3)|rcode(4)| +-----+---------+-----+-----+-----+-----+-------+--------+ 本条报文的含义为：该报文为响应报文，属于标准查询，查询的名字服务器授权该域，本条报文不可截断，具有递归期望的并且是可递归的，返回码没有错误。 问题数 (QDCOUNT)”00 01”，表示包含 1 条查询实体。 资源记录数 (ANCOUNT)”00 01”，表示包含了 1 条资源记录。 授权资源记录数 (NSCOUNT)”00 01”，表示包含了 1 条授权资源记录。 额外资源记录数 (ARCOUNT)”00 01”，表示包含了 1 条额外资源记录。 查询问题 (QUESTIONs)”04 75 73 65 72 07 65 78 61 6d 70 6c 65 03 63 6f 6d 00 00 01 00 01”，与上一条查询报文中的查询问题含义一致 以下为资源记录部分，资源记录的格式为： |&amp;lt;-- 16 --&amp;gt;|&amp;lt;-- 16 --&amp;gt;|(bit) +----------------+ | RNAME | +----------------+----------------+ | RTYPE | RCLASS | +----------------+----------------+ | RTTL | +----------------+----------------+ | RDLENGTH | | +----------------+ | | RDATA | +---------------------------------+ 回答 (ANSWERs)”c0 0c 00 01 00 01 00 00 02 58 00 04 c0 a8 13 88”，表示回答中的资源记录，其中域名 (RNAME)”c0 0c” 表示 user.example.com；类型 (RTYPE)”00 01” 值为 1，代表 A 类即主机号；类 (RCLASS)”00 01” 值为 1，代表 IN 互联网；生存时间 (RTTL)”00 00 02 58”，32bit 整数，数值为”00000000 00000000 00000010 01011000”，转换为 10 进制即为 600，单位为秒；资源数据长度 (RDLENGTH)”00 04”，表示后面的资源数据的长度，此处为 4，单位是字节；资源数据 (RDATA)”c0 a8 12 88”，转换为 bit 为”11000000 10101000 00010010 10001000”，即为主机号 192.168.18.136。 授权 (AUTHORITYs)”c0 11 00 02 00 01 00 00 02 58 00 07 04 6e 73 30 31 c0 11”，表示授权中的资源记录，其中域名 (RNAME)”c0 11” 表示 example.com；类型 (RTYPE)”00 02” 值为 2，代表 NS 类即名字服务器；类 (RCLASS)”00 01” 值为 1，代表 IN 互联网；生存时间 (RTTL)”00 00 02 58” 同 8，为 600 秒；资源数据长度 (RDLENGTH)”00 07” 表示后面的资源数据长度为 7 字节；资源数据 (RDATA)”04 6e 73 30 31 c0 11”，表示名字服务器地址 ns01.example.com。 额外信息 (ADDITIONALs)”c0 3e 00 01 00 01 00 00 02 58 00 04 c0 a8 12 87”，表示额外信息中的资源记录，其中域名 (RNAME)”c0 3e” 表示 ns01.example.com; 类型 (RTYPE)”00 01”，代表 A 类即主机号；类 (RCLASS)”00 01” 代表 IN 互联网；生存时间 (RTTL)”00 00 02 58” 为 600 秒；资源数据长度 (RDLENGTH)”00 04” 表示资源数据长度为 4 字节；资源数据 (RDATA)”c0 a8 12 87”，为主机号 192.168.18.135。 ？：为什么用户可以向名字服务器发起查询请求及为什么名字服务器能够响应域、区域与资源记录dns 服务维护了一个资源记录映射关系，每条资源记录都像一个键值对，如果这个映射中包含了用户请求的 key，那么 dns 服务就能根据这个 key 返回给用户它对应的 value。这些映射关系包含在抽象的层级概念中，如域、区域、资源记录。域 (domain)：域表示一个域名，带有层级特征，如顶级域.com、.org 等，顶级域下可以设置二级域名，二级域名下又可以设置三级域名。区域 (zone)：区域从是域表现的一个部分，带有范围特征，它描述的不是域的层级，而是域所管辖的范围。域和区域的区别：例子：域 (domain) example.com.，包含了一个三级域 cloud.example.com.，以及两个资源记录 user1.example.com 和 user2.example.com。对应的，需要有两个区域 (zone) 来管理 example.com. 和 cloud.example.com. 这两个域的范围，即 user1.example.com 和 user2.example.com 就需要在 example.com. 的区域信息中进行描述，而不是在 cloud.example.com. 的区域信息中描述。区域文件示例：$TTL 600@ IN SOA ns01.example.com. example.com. ( 0 ; serial 1D ; refresh 1H ; retry 1W ; expire 3H ) ; minimum@ NS ns01.example.com.ns01 A 192.168.18.135user A 192.168.18.136其中 SOA 表示了区域授权的起始，它包含了名字服务器域名 (mname)、区域负责人邮箱域名 (rname)、序列号 (serial)、刷新时间 (refresh)、重试间隔 (retry)、过期时间 (expire)、最小 ttl 时间 (minimun，bind8.2 之后已由第一行的 TTL 代替)。NS 指名字服务器，表示在这个区域 (如 example.com.) 中，ns01.example.com (即 192.168.18.135) 有权利回答所有 dns 查询请求，并且回答是最可靠的。如果一个区域中配置了多个名字服务器，如：$TTL 600@ IN SOA ns01.example.com. example.com. ( 0 ; serial 1D ; refresh 1H ; retry 1W ; expire 3H ) ; minimum@ NS ns01.example.com.@ NS ns02.example.com.ns01 A 192.168.18.135ns02 A 192.168.18.137user A 192.168.18.136那么 ns02 将作为辅助服务器协同 ns01 工作，它也可以响应关于该区域的 dns 查询请求。在一般的 dns 集群中，存在一个主名字服务器，一个或多个辅助名字服务器。主名字服务器的数据变更时，通过 DNS 区域信息传输协议 (AXFR) 将变更后的区域信息通知给每个与之相连的辅助名字服务器。在这个过程中，需要依赖 SOA 给出的信息，如序列号，该值是辅助名字服务器判断是否与主名字服务器同步的标志。资源记录 (resource records)：域是由域名的集合组成并描述的；资源记录表征了域名与其所对应的资源。在这个集合中，域名的顺序并不重要。一般情况下，资源记录具有以下几个属性：属主 (owner)：表示这个资源记录属于哪个域类型 (type)：类型 值 含义A 1 主机号NS 2 名字服务器MD 3 邮件目的地(已弃用)MF 4 邮件转发者(已弃用)CNAME 5 别名的规范名称SOA 6 授权区域起始MB 7 邮箱域名(试验性)MG 8 邮件组成员(试验性)MR 9 邮件重命名域名(试验性)NULL 10 空记录(试验性)WKS 11 皆知的服务描述PTR 12 域名指针HINFO 13 主机信息MINFO 14 邮件列表信息MX 15 邮件服务器TXT 16 文本字符串类 (class)类 值 含义IN 1 互联网CS 2 the CSNET class (Obsolete - used only for examples in some obsolete RFCs)(特殊网络，可查看wiki了解详情)CH 3 the CHAOS class(特殊网络，可查看wiki了解详情)HS 4 Hesiod [Dyer 87](特殊网络，可查看wiki了解详情)存活时间 (TTL)；资源数据 (RDATA)：对于 A 类型，资源数据为一个 32 位 IP 地址；CNAME 的资源数据是一个域名；MX 的资源记录是一个 16 位首选值加上用作邮件服务器的主机名；NS 的资源数据是一个主机名；PTR 的资源数据是一个域名；SOA 的资源记录是一段包含 SOA 各个属性的授权信息。？：区域之间是怎么交换信息的DNS 通信dns 可以使用 udp 及 tcp 来进行通信，使用的端口都是 53。dns 使用 udp 的原因：dns 的主要工作场景在于处理来自解析器的 dns 查询请求以及对其的反馈，udp 的传输速度快，对系统资源的开销小，非常适合这种场景。dns 使用 tcp 的原因：当使用 udp 传输数据时，数据被限制在 512 字节内，超过 512 字节，数据将被截断 (设置 TC 标志)。当解析器得到的反馈报文中 TC 标志设置为 1 时，它会认为这个报文的数据超过 512 字节限制，那么它将重发一次请求，这个时候就需要用 tcp 来进行重传 (udp 也可以进行重传)。此外，区域信息传输的过程中，同样需要使用 tcp 来传输这些数据。AXFR：授权转移 (Authoritative Transfer)，用于传输区域 (zone) 的信息。AXFR 应答报文由一系列 (包含 1) DNS 报文组成，其中第一条报文及最后一条报文需要包含区域的 SOA 资源记录，中间的报文为该区域 (zone) 的资源记录信息，如可以包含 NS 类、A 类、CNAME 类记录等。用户可以通过 dig 命令向名字服务器发起 AXFR 请求，如：[root@user ~]# dig @192.168.18.135 example.com. AXFR; &amp;lt;&amp;lt;&amp;gt;&amp;gt; DiG 9.9.4-RedHat-9.9.4-61.el7 &amp;lt;&amp;lt;&amp;gt;&amp;gt; @192.168.18.135 example.com. AXFR; (1 server found);; global options: +cmdexample.com. 600 IN SOA ns01.example.com. example.com. 0 86400 3600 604800 10800example.com. 600 IN NS ns01.example.com.master.example.com. 600 IN A 192.168.18.135ns01.example.com. 600 IN A 192.168.18.135user.example.com. 600 IN A 192.168.18.136example.com. 600 IN SOA ns01.example.com. example.com. 0 86400 3600 604800 10800;; Query time: 6 msec;; SERVER: 192.168.18.135#53(192.168.18.135);; WHEN: Thu Jun 28 11:50:34 EDT 2018;; XFR size: 6 records (messages 1, bytes 180)以下为 AXFR 请求报文：0000 00 0c 29 8f da 54 00 0c 29 75 2e c5 08 00 45 00 ..).ÚT..)u.Å..E.0010 00 5e 3e 3e 40 00 40 06 55 fb c0 a8 12 89 c0 a8 .^&amp;gt;&amp;gt;@.@.UûÀ¨..À¨0020 12 87 9c 57 00 35 7f 16 52 5b 2e be 97 6e 80 18 ...W.5..R[.¾.n..0030 00 e5 30 88 00 00 01 01 08 0a 00 01 6c 67 00 01 .å0.........lg..0040 7b 3a 00 28 a9 0d 00 20 00 01 00 00 00 00 00 01 {:.(©.. ........0050 07 65 78 61 6d 70 6c 65 03 63 6f 6d 00 00 fc 00 .example.com..ü.0060 01 00 00 29 10 00 00 00 00 00 00 00 ...)........其中”00 28 a9 0d 00 20 00 01 00 00 00 00 00 01 07 65 78 61 6d 70 6c 65 03 63 6f 6d 00 00 fc 00 01 00 00 29 10 00 00 00 00 00 00 00” 为 dns 报文信息。 首部”00 28” 表示这段报文的长度 标识为”a9 0d” 标志为”00 20”，转换为 bit 为”00000000 00100000”，其格式如下： +-----+---------+-----+-----+-----+-----+-------+--------+ |QR(1)|opcode(4)|AA(1)|TC(1)|RD(1)|RA(1)|zero(3)|rcode(4)| +-----+---------+-----+-----+-----+-----+-------+--------+ 此处的含义为，该报文为请求报文，是标准查询，非授权回答，是不可截断的，是不期望递归的，是无可用递归查询的，返回码无差错。 随后的”00 01 00 00 00 00 00 01” 分别表示问题数、回答中包含的资源记录数、授权资源记录数、额外资源记录数，每个片段有 16 位。此处的含义为，含有一个请求以及一个额外资源记录。 查询问题”07 65 78 61 6d 70 6c 65 03 63 6f 6d 00 00 fc 00 01”。其中”07 65 78 61 6d 70 6c 65 03 63 6f 6d 00” 为请求的域名 (example.com)，其格式如下： +--------+-+-+-+-+-+-+-+--------+-+-+-+--------+ |7(count)|e|x|a|m|p|l|e|3(count)|c|o|m|0(count)| +--------+-+-+-+-+-+-+-+--------+-+-+-+--------+ 之后的”00 fc” 为查询类型，转换为十进制数为 252，即为 AXFR；末尾的”00 01” 表示查询类，即”IN”。 额外信息”00 00 29 10 00 00 00 00 00 00 00”，表示此处为一条 OPT 记录，其详情可以参考 RFC 2671。以下为 AXFR 应答报文：0000 00 0c 29 75 2e c5 00 0c 29 8f da 54 08 00 45 00 ..)u.Å..).ÚT..E.0010 00 ea ec 55 40 00 40 06 a7 57 c0 a8 12 87 c0 a8 .êìU@.@.§WÀ¨..À¨0020 12 89 00 35 9c 57 2e be 97 6e 7f 16 52 85 80 18 ...5.W.¾.n..R...0030 00 e3 a7 3d 00 00 01 01 08 0a 00 01 7b 3c 00 01 .ã§=........{&amp;lt;..0040 6c 67 00 b4 a9 0d 84 00 00 01 00 06 00 00 00 00 lg.´©...........0050 07 65 78 61 6d 70 6c 65 03 63 6f 6d 00 00 fc 00 .example.com..ü.0060 01 c0 0c 00 06 00 01 00 00 02 58 00 1d 04 6e 73 .À........X...ns0070 30 31 c0 0c c0 0c 00 00 00 00 00 01 51 80 00 00 01À.À.......Q...0080 0e 10 00 09 3a 80 00 00 2a 30 c0 0c 00 02 00 01 ....:...*0À.....0090 00 00 02 58 00 02 c0 29 06 6d 61 73 74 65 72 c0 ...X..À).masterÀ00a0 0c 00 01 00 01 00 00 02 58 00 04 c0 a8 12 87 c0 ........X..À¨..À00b0 29 00 01 00 01 00 00 02 58 00 04 c0 a8 12 87 04 ).......X..À¨...00c0 75 73 65 72 c0 0c 00 01 00 01 00 00 02 58 00 04 userÀ........X..00d0 c0 a8 12 88 c0 0c 00 06 00 01 00 00 02 58 00 18 À¨..À........X..00e0 c0 29 c0 0c 00 00 00 00 00 01 51 80 00 00 0e 10 À)À.......Q.....00f0 00 09 3a 80 00 00 2a 30 ..:...*0其中”00 b4 a9 0d 84 00 00 01 00 06 00 00 00 00 07 65 78 61 6d 70 6c 65 03 63 6f 6d 00 00 fc 00 01 c0 0c 00 06 00 01 00 00 02 58 00 1d 04 6e 73 30 31 c0 0c c0 0c 00 00 00 00 00 01 51 80 00 00 0e 10 00 09 3a 80 00 00 2a 30 c0 0c 00 02 00 01 00 00 02 58 00 02 c0 29 06 6d 61 73 74 65 72 c0 0c 00 01 00 01 00 00 02 58 00 04 c0 a8 12 87 c0 29 00 01 00 01 00 00 02 58 00 04 c0 a8 12 87 04 75 73 65 72 c0 0c 00 01 00 01 00 00 02 58 00 04 c0 a8 12 88 c0 0c 00 06 00 01 00 00 02 58 00 18 c0 29 c0 0c 00 00 00 00 00 01 51 80 00 00 0e 10 00 09 3a 80 00 00 2a 30” 为 dns 报文信息。 首部”00 b4” 表示这段报文的长度 标识为”a9 0d” 标志为”84 00”，转换为 bit 为”10000100 00000000”，其格式如下： +-----+---------+-----+-----+-----+-----+-------+--------+ |QR(1)|opcode(4)|AA(1)|TC(1)|RD(1)|RA(1)|zero(3)|rcode(4)| +-----+---------+-----+-----+-----+-----+-------+--------+ 此处的含义为，该报文为应答报文，是标准查询，是授权回答，是不可截断的，是不期望递归的，是无可用递归查询的，返回码为无差错。 随后的”00 01 00 06 00 00 00 00” 分别表示问题数、回答中包含的资源记录数、授权资源记录数、额外资源记录数，每个片段有 16 位。此处的含义为，含有一个请求以及应答中包含六条资源记录数。 之后的”07 65 78 61 6d 70 6c 65 03 63 6f 6d 00 00 fc 00 01” 表示查询内容，其中”07 65 78 61 6d 70 6c 65 03 63 6f 6d 00” 为查询的域名，其格式如下： +--------+-+-+-+-+-+-+-+--------+-+-+-+--------+ |7(count)|e|x|a|m|p|l|e|3(count)|c|o|m|0(count)| +--------+-+-+-+-+-+-+-+--------+-+-+-+--------+ 之后的”00 fc” 为查询类型，转换为十进制数为 252，即为 AXFR；末尾的”00 01” 表示查询类，即”IN”。 之后的全部报文为 AXFR 的应答信息： 第一条资源记录是 SOA 记录，它的报文为”c0 0c 00 06 00 01 00 00 02 58 00 1d 04 6e 73 30 31 c0 0c c0 0c 00 00 00 00 00 01 51 80 00 00 0e 10 00 09 3a 80 00 00 2a 30”。由域名”c0 0c”(example.com)、类型”00 06”(SOA)、类”00 01”(IN)、生存时间”00 00 02 58”(600 秒)、资源数据长度”00 1d”(29 字节)、主名字服务器”04 6e 73 30 31 c0 0c”(ns01.example.com)、区域责任人邮箱”c0 0c”(example.com)、序列号”00 00 00 00”(0)、刷新时间”00 01 51 80”(86400 秒，即 1 天)、重试间隔”00 00 0e 10”(3600 秒，即 1 小时)、过期时间”00 09 3a 80”(604800 秒，即 7 天)、最小 TTL 时间”00 00 2a 30”(10800 秒，即 3 小时) 组成。 第一条资源记录是 NS 记录，它的报文为”c0 0c 00 02 00 01 00 00 02 58 00 02 c0 29”。由域名”c0 0c”(example.com)、类型”00 02”(NS)、类”00 01”(IN)、生存时间”00 00 02 58”(600 秒)、资源数据长度”00 02”(2 字节)、资源记录”c0 29”(ns01.example.com) 组成。 第三条资源记录是 A 记录，它的报文为”06 6d 61 73 74 65 72 c0 0c 00 01 00 01 00 00 02 58 00 04 c0 a8 12 87”。由域名”06 6d 61 73 74 65 72 c0 0c”(master.example.com)、类型”00 01”(A)、类”00 01”(IN)、生存时间”00 00 02 58”(600 秒)、资源数据长度”00 04”(4 字节)、资源记录”c0 a8 12 87”(192.168.18.135) 组成。 第四条资源记录是 A 记录，它的报文为”c0 29 00 01 00 01 00 00 02 58 00 04 c0 a8 12 87”。由域名”c0 29”(ns01.example.com)、类型”00 01”(A)、类”00 01”(IN)、生存时间”00 00 02 58”(600 秒)、资源数据长度”00 04”(4 字节)、资源记录”c0 a8 12 87”(192.168.18.135) 组成。 第五条资源记录是 A 记录，它的报文为”04 75 73 65 72 c0 0c 00 01 00 01 00 00 02 58 00 04 c0 a8 12 88”。由域名”04 75 73 65 72 c0 0c”(user.example.com)、类型”00 01”(A)、类”00 01”(IN)、生存时间”00 00 02 58”(600 秒)、资源数据长度”00 04”(4 字节)、资源记录”c0 a8 12 88”(192.168.18.136) 组成。 最后一条资源是 SOA 记录，它的报文与第一条是一致的。 IXFR：增量区域传输 (Incremental Zone Transfer)，与 AXFR 一样用于传输区域 (zone) 的信息，但只传输增量数据。主要用于 DNS NOTIFY。NOTIFY：用于 Master 向 Slave 通知区域信息变更。默认使用 udp 传输，Master 可以指定使用 tcp 传输。区别是，tcp 方式只发送一次 notify，超过响应等待时间后返回超时；而 udp 方式会定期发送 notify，直到发送了过多的副本 (即超时) 或者收到了对应的回复。例子：Master 与 Slave 之间使用 DNS NOTIFY 机制同步数据过程+---------------------+ 1.notify(query) +---------------------+| |-------------------&amp;gt;| || | 2.notify(response) | || |&amp;lt;-------------------| || Master | 3.SOA(query) | Slave || 192.168.18.135 |&amp;lt;-------------------| 192.168.18.137 || (ns01.example.com.) | 4.SOA(response) | (ns02.example.com.) || |-------------------&amp;gt;| || | 5.IXFR(query) | || |&amp;lt;-------------------| || | 6.IXFR(response) | || |-------------------&amp;gt;| |+---------------------+ +---------------------+ 当 Master 区域信息变更后，向 Slave 发起 notify 的请求 Slave 响应 notify 请求 Slave 向 Master 请求 SOA 信息 Master 应答 SOA 请求 Slave 根据自己的 SOA 序列号以及由 Master 处请求到的 SOA 序列号，判断自己是否需要变更 (注：如果双发的 SOA 序列号一致，那么即使区域信息是有区别的，Slave 也不会向 Master 发起更新请求)，如果需要变更，则向 Master 发起 IXFR 请求，期望同步区域信息到 Master 的那个版本 Master 应答了 Slave 的 IXFR 请求，返回了两个版本区域信息的增量记录参考 https://tools.ietf.org/html/rfc1034 https://tools.ietf.org/html/rfc1035 https://tools.ietf.org/html/rfc1995 https://tools.ietf.org/html/rfc1996 https://tools.ietf.org/html/rfc5936" }, { "title": "DNS报文格式", "url": "/posts/dns-message-format/", "categories": "Bottom Layer Knowledge", "tags": "Network, 协议解析", "date": "2022-04-18 19:17:00 +0800", "snippet": "我们知道查询一个域名，需要与 DNS 服务器进行通信。那么，DNS 通信过程大概是怎样的呢？DNS 是一个典型的 Client-Server 应用，客户端发起域名查询请求，服务端对请求进行应答：DNS 一般采用 UDP 作为传输层协议（ TCP 亦可），端口号是 53 。请求报文和应答报文均作为数据，搭载在 UDP 数据报中进行传输：很显然，DNS 请求报文和应答报文均需要满足一定的格式，才能被通信双方所理解。这就是 DNS 协议负责的范畴，它位于传输层之上，属于 应用层 协议。报文格式DNS 报文分为 请求 和 应答 两种，结构是类似的，大致分为五部分： 头部（ header ），描述报文类型，以及其下 4 个小节的情况； 问题节（ question ），保存查询问题； 答案节（ answer ），保存问题答案，也就是查询结果； 授权信息节（ authority ），保存授权信息； 附加信息节（ additional ），保存附加信息； 也有不少文献将 DNS 请求称为 DNS 查询（ query ），两者是一个意思。其中，头部是固定的，共 12 字节；其他节不固定，记录数可多可少，数目保存在头部中。头部分为 6 个字段： 标识（ identifier ），一个 16 位的 ID ，在应答中原样返回，以此匹配请求和应答； 标志（ flags ），一些标志位，共 16 位； 问题记录数（ question count ），一个 16 位整数，表示问题节中的记录个数； 答案记录数（ answer count ），一个 16 位整数，表示答案节中的记录个数； 授权信息记录数（ authority record count ），一个 16 位整数，表示授权信息节中的记录个数； 附加信息记录数（ additional record count ），一个 16 位整数，表示附加信息节中的记录个数；最后，我们来解释一下标志字段中的各个标志位： QR 位标记报文是一个查询请求，还是查询应答； 0 表示查询请求； 1 表示查询应答； 操作码（ opcode ）占 4 位，表示操作类型： 0 代表标准查询； 1 代表反向查询； 2 代表服务器状态请求； AA 位表示 权威回答（ authoritative answer ），意味着当前查询结果是由域名的权威服务器给出的； TC 位表示 截短（ truncated ），使用 UDP 时，如果应答超过 512 字节，只返回前 512 个字节； RD 位表示 期望递归 （ recursion desired ），在请求中设置，并在应答中返回； 该位为 1 时，服务器必须处理这个请求：如果服务器没有授权回答，它必须替客户端请求其他 DNS 服务器，这也是所谓的 递归查询 ； 该位为 0 时，如果服务器没有授权回答，它就返回一个能够处理该查询的服务器列表给客户端，由客户端自己进行 迭代查询 ； RA 位表示可递归（ recursion available ），如果服务器支持递归查询，就会在应答中设置该位，以告知客户端； 保留位，这 3 位目前未用，留作未来扩展； 响应码（ response code ）占 4 位，表示请求结果，常见的值包括： 0 表示没有差错； 3 表示名字差错，该差错由权威服务器返回，表示待查询的域名不存在； 问题记录客户端查询域名时，需要向服务端发送请求报文；待查询域名作为问题记录，保存在问题节中。问题节支持保存多条问题记录，记录条数则保存在 DNS 头部中的问题记录数字段。这意味着，DNS 协议单个请求能够同时查询多个域名，虽然通常只查询一个。一个问题记录由 3 个字段组成： 待查询域名（ Name ），这个字段长度不固定，由具体域名决定； 查询类型（ Type ），域名除了关联 IP 地址，还可以关联其他信息，常见类型包括（下节详细介绍）： 1 表示 A 记录，即 IP 地址； 28 表示 AAAA 记录，即 IPv6 地址； etc 类 （ Class ）通常为 1 ，表示 TCP/IP 互联网地址；最后，我们回过头来考察域名字段，它的长度是不固定的。域名按 . 切分成若干部分，再依次保存。每个部分由一个前导计数字节开头，记录当前部分的字符数。以域名 example.com. 为例，以 . 切分成 3 example 、com 以及空字符串 。请注意，空字符串 代表根域。因此，待查询域名字段依次为： 一个前导字节保存整数 8 ，然后 8 个字节保存 example 部分（二级域）； 一个前导字节保存整数 3 ，然后 3 个字节保存 com 部分（一级域）； 一个前导字节保存整数 0 ，然后 0 个字节保存 部分（根域）；由此可见，每一级域名的长度理论上可以支持多达 255 个字符。 查询类型 名称代码 描述 1 A IPv4地址 2 NS 名称服务器 5 CNAME 规范名称 15 MX 电子邮件交互 16 TXT 文本信息 28 AAAA IPv6地址 资源记录服务端处理查询请求后，需要向客户端发送应答报文；域名查询结果作为资源记录，保存在答案以及其后两节中。答案节、授权信息节和附加信息节均由一条或多条资源记录组成，记录数目保存在头部中的对应字段，不再赘述。资源记录结构和问题记录非常相似，它总共有 6 个字段，前 3 个和问题记录完全一样： 被查询域名（ Name ），与问题记录相同； 查询类型（ Type ），与问题记录相同； 类 （ Class ），与问题记录相同； 有效期（ TTL ），域名记录一般不会频繁改动，所以在有效期内可以将结果缓存起来，降低请求频率； 数据长度（ Resource Data Length ），即查询结果的长度； 数据（ Resource Data ），即查询结果；如果查询类型是 A 记录，那查询结果就是一个 IP 地址，保存于资源记录中的数据字段；而数据长度字段值为 4 ，因为 IP 地址的长度为 32 位，折合 4 字节。域名压缩我们注意到，应答报文中，会将请求报文中的问题记录原样返回。由于问题记录和资源记录都会保存域名，这意味着域名会被重复保存，而报文尺寸是有限的！为了节约报文空间，有必要解决域名重复保存问题，这也是所谓的信息压缩。具体做法如下：域名在报文中第二次出现时，只用两个字节来保存。第一个字节最高两位都是 1 ，余下部分和第二个字节组合在一起，表示域名第一次出现时在报文中的偏移量。通过这个偏移量，就可以找到对应的域名。由此一来，原来需要 21 个字节来保存的域名，现在只需区区两个字节即可搞定，数据量大大降低！实际上，域名压缩机制还可以针对域名的某个部分进行。举个例子，假设一个请求报文同时查询两个域名： example.com test.example.com请求报文中包含两个问题记录，分别对应域名 example.com 和 test.example.com 。这两个域名都有一个公共后缀 example.com ，无须重复保存。第二个域名只需保存 test 部分，然后接两个字节特殊的压缩字节1100 0000B，指向第一个问题记录中的 example.com 。如果两条问题记录顺序颠倒，结果也是类似的" }, { "title": "Linux Golang 安装流程", "url": "/posts/linux-golang-installation/", "categories": "Software Development", "tags": "Go, 安装流程, Linux", "date": "2022-04-02 23:32:00 +0800", "snippet": "Go，通常被称为 golang，它是一门由 Google 创建的现代化的开源编程语言，它允许你构建实时并且高效的应用。很多流行的应用程序，例如 Kubernetes，Docker，Prometheus 和 Terraform，都是使用 Go 来编写的。这篇教程讲解如何在 Ubuntu 20.04 上下载和安装 Go。下载 Go 压缩包在写这篇文章的时候，Go 的最新版为 1.18.1。在我们下载安装包时，请浏览Go 官方下载页面,并且检查一下是否有新的版本可用。以 root 或者其他 sudo 用户身份运行下面的命令，下载并且解压 Go 二进制文件到/usr/local目录：wget -c https://dl.google.com/go/go1.18.1.linux-amd64.tar.gz -O - | sudo tar -xz -C /usr/local调整环境变量通过将 Go 目录添加到$PATH环境变量，系统将会知道在哪里可以找到 Go 可执行文件。这个可以通过添加下面的行到/etc/profile文件（系统范围内安装）或者$HOME/.profile文件（当前用户安装）：export PATH=$PATH:/usr/local/go/bin保存文件，并且重新加载新的PATH 环境变量到当前的 shell 会话：source ~/.profile验证 Go 安装过通过打印 Go 版本号，验证安装过程。go versiongo version go1.14.2 linux/amd64测试想要测试 Go 安装过程，我们将会创建一个工作区，并且构建一个简单的程序，用来打印经典的”Hello World”信息。 默认情况下，GOPATH变量，指定为工作区的位置，设置为 。想要创建工作区目录，输入： mkdir ~/go 在工作区内，创建一个新的目录src/hello： mkdir -p ~/go/src/hello 在那个目录下，创建一个新文件，名称为hello.go package main import &quot;fmt&quot; func main() { fmt.Printf(&quot;Hello, World\\n&quot;) } 浏览到~/go/src/hello目录，并且运行go build构建程序： cd ~/go/src/hello go build 上面的这个命令将会构建一个名为hello的可执行文件。 你可以通过简单执行下面的命令，运行这个可执行文件： ./hello 输出应该像下面这样： Hello, World 现在你已经在你的 Ubuntu 系统上下载并安装了 Go，你可以开始开发你的 Go 项目了。" }, { "title": "UDP 打洞技术解析", "url": "/posts/udp-hole-punching-analysis/", "categories": "Bottom Layer Knowledge", "tags": "Network", "date": "2022-03-18 15:20:00 +0800", "snippet": "P2P 通信最大的障碍就是 NAT（网络地址转换），NAT 使得局域网内的设备也可以与公网进行通讯，但是不同 NAT 下的设备之间通讯将会变得很困难。UDP 打洞就是用来使得设备间绕过 NAT 进行通讯的一种技术。简单解释 NATNAT 大家应该十分熟悉了，它分为几种。一种就叫做 NAT，它只对 IP 地址进行转换；另一种叫做 NAPT（Network Address/Port Translation），它可以对整个会话的端点（由 IP 地址和端口号组成）做转换，这是一种更加常见的 NAT 变种。当然了，NAPT 也分为许多种，我们这里就不深入探讨了，大家如果有兴趣可以查阅相关的文献。下面就简单介绍一下 NAT 的工作原理：首先，NAT A 网下的设备 1（192.168.1.101）想与某公网 IP 通讯，设备 1 将包发给 NAT A，然后 NAT A 对源 IP 进行转换发给 NAT B（中间可能还会经过多重 NAT）。这样做的目的是，NAT B 并不知晓 NAT A 下的各个设备，他只能与 NAT A 本身通讯，因此发送给 NAT B 的包源 IP 必须是 NAT A 的公网 IP，不然 NAT B 没有办法进行回复。接下来 NAT B 将回复包再发回 NAT A，此时就是 NAT 发挥作用的时候了，NAT A 现在要做的就是将包再分发回之前的设备，如何确定要发给谁呢？NAT 中记录了一张表，之前 192.168.1.101 通过 2333 端口与 42.120.241.46 端口 443 通讯了，并且 NAT A 是用 60001 的端口转发出去的，那么这次接受到发往该 NAT 60001 端口的包时就应该再通过 2333 端口转发给 192.168.1.101。经过这样的过程，NAT A 下的设备都可以连接到互联网了！UDP 打洞原理及过程如上图所示，由于 NAT 的存在，当 NAT A 的设备 1 想与 NAT B 下的设备通讯时，必然要将目标 IP 设置为 NAT B 的公网地址，而 NAT B 转发表中并没有记录过 NAT A 与自身网络下设备的通讯记录，因此 NAT B 会将包丢掉。下面我们来看看 UDP 打洞是怎么解决这个问题的。为了能够进行 UDP 打洞，我们需要一台公网的服务器作为中转站，它是 NAT A 与 NAT B 之间的信使。（为了方便起见，我们把地址为 192.168.1.101 的设备称为设备 1，把地址为 192.168.1.2 的设备称为设备 2，信使服务器称为 S）首先，设备 1 和设备 2 都向 S 注册自己，S 中能记录各个设备此时使用的公网 IP 地址和端口号，例如设备 1 是 123.122.53.20:31000，设备 2 是 42.120.241.46:41000。然后设备 1 与设备 2 都向 S 获取对方的公网 IP 与之前预留的端口号，就像这样：然后就是最关键的一步，打洞。设备 1 向 42.120.241.46:41000 发一个包，NAT B 自然能接收到这个包，然而它不知道来自 NAT A 的包应该发给谁，因此 NAT B 将这个包舍弃。但是由于设备 1 向 42.120.241.46:41000 发过包，NAT A 会记录：以后来自 42.120.241.46:41000 的包都发给设备1。设备 2 也做相同的操作，让 NAT B 也知道：以后来自 123.122.53.20:31000 的包都发给设备 2。至此，NAT A 与 NAT B 都互相为对方保留了端口，就可以愉快地通讯了。当然了，大致原理是很简单的，实际操作起来情况可能会更复杂，会涉及到丢包、多重 NAT 等问题的处理、参考 Peer-to-Peer Communication Across Network Address Translators" }, { "title": "OpenWRT overlay 空间扩容", "url": "/posts/openwrt-overlay-space-expansion/", "categories": "Tech Projects", "tags": "OpenWRT, GeekDairy", "date": "2022-03-13 18:43:00 +0800", "snippet": " 安装 OpenWRT 咔咔塞了一大堆插件后，可怜的剩余空间被插件和日志耗尽，不得不对 OpenWRT overlay 进行扩容，本文对此进行了记录什么是 overlayOpenWRT 一般使用的文件系统是 SquashFS ，这个文件系统的特点就是：只读。一个只读的文件系统要怎么做到保存设置和安装软件的呢？这里就是使用 /overlay 的分区，overlay 顾名思义就是覆盖在上面一层的意思。虽然原来的文件不能修改，但把修改的部分放在 overlay 分区上，然后映射到原来的位置，读取的时候就可以读到修改过的文件了。为什么要用这么复杂的方法呢？ OpenWRT 当然也可以使用 EXT4 文件系统，但使用 SquashFS + overlay 的方式有一定的优点。 SquashFS 是经过压缩的，在路由器这种小型 ROM 的设备可以放下更多的东西。 OpenWRT 的恢复出厂设置也要依赖于这个方式。在你重置的时候，它只需要把 overlay 分区清空就可以了，一切都回到了刚刷进去的样子。如果是 EXT4 文件系统，就只能够备份每个修改的文件，在恢复出厂设置的时候复制回来，十分复杂。当然，SquashFS + overlay 也有它的缺点： 修改文件的时候会占用更多的空间。首先你不能够删除文件，因为删除文件实际上是在 overlay 分区中写入一个删除的标识，反而占用更多的空间。 另外在修改文件的时候相当于增加了一份文件的副本，占用了双份的空间。创建新分区首先，需要创建一个新的分区，这里使用的是 cfdisk如果此前没有安装，首先使用下列命令进行安装：opkg updateopkg install cfdisk然后输入cfdisk打开磁盘管理界面：磁盘界面这里可以看到，目前一共有两个已有分区，现在新建一个分区：选中 Free Space，再选中 New，输入需要的大小，比如 5G。接着选择 primary选择主分区选择 Write写入更改输入 yes，完成新分区的创建确认格式化分区使用命令：mkfs.ext4 /dev/sda3格式化分区格式化分区挂载新分区使用命令：mount /dev/sda3 /mnt/sda3挂载分区转移到新分区然后将原来 upper 层中的数据复制到新的分区中：cp -r /overlay/* /mnt/sda3Web 界面配置修改进入 OpenWRT Web 界面的挂载点对配置进行修改：Web 界面在挂载点下方点击添加，然后如下配置：挂载点配置完成到这一步，只需要重启 OpenWRT 即可成功扩容。重启后到 系统 -&amp;gt; 软件包 可以看到变大后的空间容量。自动挂载分区默认会在 OpenWRT 重启后会自动挂载，如果遇到没有挂载的情况，需要编辑 /etc/rc.localvim /etc/rc.local在 exit 0 之前加入一行 mount /dev/sda3 /overlay 即可。参考 OpenWrt 下把 SD 卡挂载到 /overlay ，扩大软件空间 软路由 LEDE 折腾 overlay 分区扩容之路 ESXI 下 OpenWrt 扩容 Overlay,增加安装插件空间 " }, { "title": "在 Ubuntu 上安装 Dockers Engine 流程", "url": "/posts/docker-engine-installation-on-ubuntu/", "categories": "Software Development", "tags": "Docker, 安装流程, Linux", "date": "2022-03-12 23:48:00 +0800", "snippet": "先决条件操作系统要求要安装 Docker Engine，您需要以下 Ubuntu 版本之一的 64 位版本： Ubuntu Jammy 22.04 (LTS) Ubuntu 小鬼 21.10 Ubuntu 焦点 20.04 (LTS) Ubuntu 仿生 18.04 (LTS)x86_64（或amd64)],armhf,arm64和s390x架构支持 Docker 引擎。卸载旧版本旧版本的 Docker 被称为docker,docker.io或docker-engine. 如果安装了这些，请卸载它们：apt-get如果报告没有安装这些软件包，那也没关系。/var/lib/docker/目录，包括图像、容器、卷和网络，都被保留。如果您不需要保存现有数据，并且想从全新安装开始，请参阅 本页底部的卸载 Docker 引擎部分。安装方法您可以根据需要以不同的方式安装 Docker Engine： 大多数用户 设置 Docker 的存储库并从中安装，以便于安装和升级任务。这是推荐的方法。 一些用户下载 DEB 包并 手动安装，完全手动管理升级。这在诸如在无法访问 Internet 的气隙系统上安装 Docker 等情况下很有用。 在测试和开发环境中，一些用户选择使用自动化 便利脚本来安装 Docker。使用存储库安装在新主机上首次安装 Docker Engine 之前，您需要设置 Docker 存储库。之后，您可以从存储库安装和更新 Docker。设置存储库 更新apt包索引并安装包以允许apt通过 HTTPS 使用存储库： sudo apt-get updatesudo apt-get install \\ ca-certificates \\ curl \\ gnupg \\ lsb-release 添加 Docker 的官方 GPG 密钥： sudo mkdir -p /etc/apt/keyringscurl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /etc/apt/keyrings/docker.gpg 使用以下命令设置存储库： echo \\&quot;deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.gpg] https://download.docker.com/linux/ubuntu \\$(lsb_release -cs) stable&quot; | sudo tee /etc/apt/sources.list.d/docker.list &amp;gt; /dev/null 安装 Docker 引擎 运行时收到 GPG 错误apt-get update？ 您的默认 umask 可能设置不正确，导致无法检测到 repo 的公钥文件。运行以下命令，然后再次尝试更新您的存储库：sudo chmod a+r /etc/apt/keyrings/docker.gpg 更新apt包索引，安装最新版本的 Docker Engine、containerd 和 Docker Compose，或者进入下一步安装特定版本： sudo apt-get update sudo apt-get install docker-ce docker-ce-cli containerd.io docker-compose-plugin 要安装特定版本的 Docker Engine，请在 repo 中列出可用版本，然后选择并安装： a.列出您的存储库中可用的版本： apt-cache madison docker-ce b.用第二列中的版本字符串安装特定版本，例如5:20.10.16~3-0~ubuntu-jammy sudo apt-get install docker-ce=&amp;lt;VERSION_STRING&amp;gt; docker-ce-cli=&amp;lt;VERSION_STRING&amp;gt; containerd.io docker-compose-plugin hello-world 通过运行映像来验证 Docker 引擎是否已正确安装 sudo docker run hello-world 此命令下载测试映像并在容器中运行它。当容器运行时，它会打印一条消息并退出。 Docker 引擎已安装并正在运行。该docker组已创建，但未向其中添加任何用户。您需要使用sudo来运行 Docker 命令。继续Linux 后安装以允许非特权用户运行 Docker 命令和其他可选配置步骤。升级 Docker 引擎要升级 Docker Engine，首先运行sudo apt-get update，然后按照 安装说明，选择您要安装的新版本。卸载 Docker 引擎 卸载 Docker Engine、CLI、Containerd 和 Docker Compose 软件包： sudo apt-get purge docker-ce docker-ce-cli containerd.io docker-compose-plugin 主机上的映像、容器、卷或自定义配置文件不会自动删除。要删除所有映像、容器和卷： sudo rm -rf /var/lib/dockersudo rm -rf /var/lib/containerd 参考 Install Docker Engine on Ubuntu | Docker Documentation" }, { "title": "Redis的持久化机制：RDB和AOF", "url": "/posts/redis-persistence-mechanisms-rdb-and-aof/", "categories": "Software Development", "tags": "Redis, DataBase", "date": "2022-03-03 18:01:00 +0800", "snippet": "什么是Redis持久化Redis作为一个键值对内存数据库(NoSQL)，数据都存储在内存当中，在处理客户端请求时，所有操作都在内存当中进行，如下所示：这样做有什么问题呢？其实，只要稍微有点计算机基础知识的人都知道，存储在内存当中的数据，只要服务器关机(各种原因引起的)，内存中的数据就会消失了，不仅服务器关机会造成数据消失，Redis服务器守护进程退出，内存中的数据也一样会消失。对于只把Redis当缓存来用的项目来说，数据消失或许问题不大，重新从数据源把数据加载进来就可以了，但如果直接把用户提交的业务数据存储在Redis当中，把Redis作为数据库来使用，在其放存储重要业务数据，那么Redis的内存数据丢失所造成的影响也许是毁灭性。为了避免内存中数据丢失，Redis提供了对持久化的支持，我们可以选择不同的方式将数据从内存中保存到硬盘当中，使数据可以持久化保存。Redis提供了RDB和AOF两种不同的数据持久化方式，下面我们就来详细介绍一下这种不同的持久化方式吧。RDBRDB是一种快照存储持久化方式，具体就是将Redis某一时刻的内存数据保存到硬盘的文件当中，默认保存的文件名为dump.rdb，而在Redis服务器启动时，会重新加载dump.rdb文件的数据到内存当中恢复数据。开启RDB持久化方式开启RDB持久化方式很简单，客户端可以通过向Redis服务器发送save或bgsave命令让服务器生成rdb文件，或者通过服务器配置文件指定触发RDB条件。save命令save命令是一个同步操作。# 同步数据到磁盘上&amp;gt; save 当客户端向服务器发送save命令请求进行持久化时，服务器会阻塞save命令之后的其他客户端的请求，直到数据同步完成。如果数据量太大，同步数据会执行很久，而这期间Redis服务器也无法接收其他请求，所以，最好不要在生产环境使用save命令。bgsave与save命令不同，bgsave命令是一个异步操作。# 异步保存数据集到磁盘上&amp;gt; bgsave当客户端发服务发出bgsave命令时，Redis服务器主进程会forks一个子进程来数据同步问题，在将数据保存到rdb文件之后，子进程会退出。所以，与save命令相比，Redis服务器在处理bgsave采用子线程进行IO写入，而主进程仍然可以接收其他请求，但forks子进程是同步的，所以forks子进程时，一样不能接收其他请求，这意味着，如果forks一个子进程花费的时间太久(一般是很快的)，bgsave命令仍然有阻塞其他客户的请求的情况发生。服务器配置自动触发除了通过客户端发送命令外，还有一种方式，就是在Redis配置文件中的save指定到达触发RDB持久化的条件，比如【多少秒内至少达到多少写操作】就开启RDB数据同步。例如我们可以在配置文件redis.conf指定如下的选项：# 900s内至少达到一条写命令save 900 1# 300s内至少达至10条写命令save 300 10# 60s内至少达到10000条写命令save 60 10000之后在启动服务器时加载配置文件。# 启动服务器加载配置文件redis-server redis.conf这种通过服务器配置文件触发RDB的方式，与bgsave命令类似，达到触发条件时，会forks一个子进程进行数据同步，不过最好不要通过这方式来触发RDB持久化，因为设置触发的时间太短，则容易频繁写入rdb文件，影响服务器性能，时间设置太长则会造成数据丢失。rdb文件前面介绍了三种让服务器生成rdb文件的方式，无论是由主进程生成还是子进程来生成，其过程如下： 生成临时rdb文件，并写入数据。 完成数据写入，用临时文代替代正式rdb文件。 删除原来的db文件。RDB默认生成的文件名为dump.rdb，当然，我可以通过配置文件进行更加详细配置，比如在单机下启动多个redis服务器进程时，可以通过端口号配置不同的rdb名称，如下所示：# 是否压缩rdb文件rdbcompression yes# rdb文件的名称dbfilename redis-6379.rdb# rdb文件保存目录dir ~/redis/RDB的几个优点 与AOF方式相比，通过rdb文件恢复数据比较快。 rdb文件非常紧凑，适合于数据备份。 通过RDB进行数据备，由于使用子进程生成，所以对Redis服务器性能影响较小。RDB的几个缺点 如果服务器宕机的话，采用RDB的方式会造成某个时段内数据的丢失，比如我们设置10分钟同步一次或5分钟达到1000次写入就同步一次，那么如果还没达到触发条件服务器就死机了，那么这个时间段的数据会丢失。 使用save命令会造成服务器阻塞，直接数据同步完成才能接收后续请求。 使用bgsave命令在forks子进程时，如果数据量太大，forks的过程也会发生阻塞，另外，forks子进程会耗费内存。AOF聊完了RDB,来聊聊Redis的另外一个持久化方式：AOF(Append-only file)。与RDB存储某个时刻的快照不同，AOF持久化方式会记录客户端对服务器的每一次写操作命令，并将这些写操作以Redis协议追加保存到以后缀为aof文件末尾，在Redis服务器重启时，会加载并运行aof文件的命令，以达到恢复数据的目的。开启AOF持久化方式Redis默认不开启AOF持久化方式，我们可以在配置文件中开启并进行更加详细的配置，如下面的redis.conf文件：# 开启aof机制appendonly yes# aof文件名appendfilename &quot;appendonly.aof&quot;# 写入策略,always表示每个写操作都保存到aof文件中,也可以是everysec或noappendfsync always# 默认不重写aof文件no-appendfsync-on-rewrite no# 保存目录dir ~/redis/三种写入策略在上面的配置文件中，我们可以通过appendfsync选项指定写入策略,有三个选项appendfsync always# appendfsync everysec# appendfsync no always 客户端的每一个写操作都保存到aof文件当，这种策略很安全，但是每个写请注都有IO操作，所以也很慢。 everysec appendfsync的默认写入策略，每秒写入一次aof文件，因此，最多可能会丢失1s的数据。 no Redis服务器不负责写入aof，而是交由操作系统来处理什么时候写入aof文件。更快，但也是最不安全的选择，不推荐使用。AOF文件重写AOF将客户端的每一个写操作都追加到aof文件末尾，比如对一个key多次执行incr命令，这时候，aof保存每一次命令到aof文件中，aof文件会变得非常大。incr num 1incr num 2incr num 3incr num 4incr num 5incr num 6...incr num 100000aof文件太大，加载aof文件恢复数据时，就会非常慢，为了解决这个问题，Redis支持aof文件重写，通过重写aof，可以生成一个恢复当前数据的最少命令集，比如上面的例子中那么多条命令，可以重写为：set num 100000aof文件是一个二进制文件，并不是像上面的例子一样，直接保存每个命令，而使用Redis自己的格式，上面只是方便演示。两种重写方式通过在redis.conf配置文件中的选项no-appendfsync-on-rewrite可以设置是否开启重写，这种方式会在每次fsync时都重写，影响服务器性以，因此默认值为no，不推荐使用。# 默认不重写aof文件no-appendfsync-on-rewrite no客户端向服务器发送bgrewriteaof命令，也可以让服务器进行AOF重写。# 让服务器异步重写追加aof文件命令&amp;gt; bgrewriteaofAOF重写方式也是异步操作，即如果要写入aof文件，则Redis主进程会forks一个子进程来处理，如下所示：重写aof文件的好处 压缩aof文件，减少磁盘占用量。 将aof的命令压缩为最小命令集，加快了数据恢复的速度。AOF文件损坏在写入aof日志文件时，如果Redis服务器宕机，则aof日志文件文件会出格式错误，在重启Redis服务器时，Redis服务器会拒绝载入这个aof文件，可以通过以下步骤修复aof并恢复数据。 备份现在aof文件，以防万一。 使用redis-check-aof命令修复aof文件，该命令格式如下： # 修复aof日志文件 $ redis-check-aof -fix file.aof 重启Redis服务器，加载已经修复的aof文件，恢复数据。AOF的优点AOF只是追加日志文件，因此对服务器性能影响较小，速度比RDB要快，消耗的内存较少。AOF的缺点AOF方式生成的日志文件太大，即使通过AFO重写，文件体积仍然很大。恢复数据的速度比RDB慢。RDB和AOF对比通过上面的介绍，我们了解了RDB与AOF各自的优点与缺点，到底要如何选择呢？通过下面的表示，我们可以从几个方面对比一下RDB与AOF,在应用时，要根本自己的实际需求，选择RDB或者AOF，其实，如果想要数据足够安全，可以两种方式都开启，但两种持久化方式同时进行IO操作，会严重影响服务器性能，因此有时候不得不做出选择。 方式 RDB AOF 启动优化级 低 高 体积 小 大 恢复速度 快 慢 数据安全性 会丢数据 由策略决定 轻重 重 轻 当RDB与AOF两种方式都开启时，Redis会优先使用AOF日志来恢复数据，因为AOF保存的文件比RDB文件更完整。" }, { "title": "在 PVE 虚拟环境中安装 OpenWRT 流程", "url": "/posts/install-openwrt-in-pve/", "categories": "Tech Projects", "tags": "OpenWRT, GeekDairy, PVE", "date": "2022-03-02 00:41:00 +0800", "snippet": "前言前几天捡垃圾￥230淘到一台惠普800G1 SFF 准系统，正好家里缺一台服务器，就直接配了块G3250，先尝试装上PVE实现一波AIO服务器，这篇文章记录下在 pve 环境下折腾 openwrt 的心得，顺便学习下 pve安装 PVE 在官网中下载 ISO 镜像 烧录到 U 盘中 使用U盘启动 安装，具体可参考【纯净安装】Proxmox-VE ISO原版 安装 全过程 登录PVE后台，地址为 https://IP:8006，重点：https，使用 chrome 登录时因为证书不安全的原因会被拦截，选择信任下载 OPENWRT 镜像我现在使用的是用Lean大仓库源码手动编译的版本，编译输出 gz 格式的压缩文件，需要解压为 img 格式的镜像文件分配网卡路由器最重要的就是将端口的网卡分配成 WAN 口和 LAN 口，这样才能形成一个网络拓扑结构。因为我是在 PVE 中安装虚拟机的方式使用 OPENWRT，所以需要先在 PVE 中将网卡映射到虚拟机中，路由器才能正确分配端口。 安装 PVE 的过程中，我们已经将 eth0 口(也就是图上的 enp1s0) 虚拟成了 vmbr0 因为我的服务器总共有4个网卡，所以我还需要虚拟3个网卡出来，和硬件口一一对应，比如将 en2s0 虚拟成 vmbr1，以此类推最终效果： 应用配置如果遇到了这个错误，是因为没有 ifupdown2，需要在 shell 中执行 apt install -y ifupdown2 创建OPENWRT虚拟机 点击右上角 创建虚拟机 一般：输入名称并设置开机自启，点击下一步我使用的 openwrt，注意 VM ID，这是以后在 PVE 中操作虚拟机的关键 操作系统：选择不使用任何介质，点击下一步稍后再上传镜像文件，因为需要对磁盘进行一些操 系统：全部默认，点击下一步 硬盘：全部默认，点击下一步 CPU：选择分配给虚拟机的CPU，点击下一步按个人喜好分配 CPU 个数，我分配的 4 个，CPU 权重是在多个虚拟机中竞争 CPU 时，虚拟机的优先级，默认是 1024，可以增加 OPENWET 的权重保证网络通畅 内存：按照个人喜好分配，如果只是单纯上网，1G足矣 网络：模型选择 VirtIO桥接网卡随便选，后面会将全部网卡添加进来 确认配置虚拟机 分离创建时选择的硬盘 删除未使用的磁盘0和CD/DVD驱动器(ide2) 上传之前下载的 OPENWRT img 文件 拷贝镜像上传地址 将 OPENWET 镜像导入磁盘 在 shell 中执行 ： qm importdisk 100 /var/lib/vz/template/iso/openwrt-buddha-v2_2021_-x86-64-generic-squashfs-uefi.img local-lvm 图中第一个绿框中的 100 为虚拟机的 VM ID，第二个绿框为刚刚上传的镜像地址 设置磁盘 调整引导顺序，将 sata0 磁盘启用并调整到第一位 添加虚拟网卡，将之前虚拟出来的网卡都依次添加进去，还是使用 VirtIO 模型 启动虚拟机现在就可以进入 OPENWRT 了参考 【纯净安装】Proxmox-VE ISO原版 安装 全过程 PVE安装Openwrt/LEDE软路由保姆级图文教程" }, { "title": "跳表原理", "url": "/posts/skip-list-principle/", "categories": "Bottom Layer Knowledge", "tags": "Data Structure", "date": "2022-02-28 18:58:00 +0800", "snippet": "跳表(skip list) 对标的是平衡树(AVL Tree)，是一种 插入/删除/搜索 都是 O(log n) 的数据结构。它最大的优势是原理简单、容易实现、方便扩展、效率更高。因此在一些热门的项目里用来替代平衡树，如 redis, leveldb 等。跳表的基本思想首先，跳表处理的是有序的链表（一般是双向链表，下图未表示双向），如下：这个链表中，如果要搜索一个数，需要从头到尾比较每个元素是否匹配，直到找到匹配的数为止，即时间复杂度是 O(n)。同理，插入一个数并保持链表有序，需要先找到合适的插入位置，再执行插入，总计也是 O(n) 的时间。那么如何提高搜索的速度呢？很简单，做个索引：如上图，我们新创建一个链表，它包含的元素为前一个链表的偶数个元素。这样在搜索一个元素时，我们先在上层链表进行搜索，当元素未找到时再到下层链表中搜索。例如搜索数字 19 时的路径如下图：先在上层中搜索，到达节点 17 时发现下一个节点为 21，已经大于 19，于是转到下一层搜索，找到的目标数字 19。我们知道上层的节点数目为 n/2，因此，有了这层索引，我们搜索的时间复杂度降为了：O(n/2)。同理，我们可以不断地增加层数，来减少搜索的时间：在上面的 4 层链表中搜索 25，在最上层搜索时就可以直接跳过 21 之前的所有节点，因此十分高效。更一般地，如果有 k 层，我们需要的搜索次数会小于 $ {n \\over 2^k} + k $ ，这样当层数 k 增加到 $ log_2 n$ 时，搜索的时间复杂度就变成了 $ logn $ 。其实这背后的原理和二叉搜索树或二分查找很类似，通过索引来跳过大量的节点，从而提高搜索效率。跳表索引上节的结构是“静态”的，即我们先拥有了一个链表，再在之上建了多层的索引。但是在实际使用中，我们的链表是通过多次插入/删除形成的，换句话说是“动态”的。上节的结构要求上层相邻节点与对应下层节点间的个数比是 1:2，随意插入/删除一个节点，这个要求就被被破坏了。因此跳表（skip list）表示，我们就不强制要求 1:2 了，一个节点要不要被索引，建几层的索引，都在节点插入时由抛硬币决定。当然，虽然索引的节点、索引的层数是随机的，为了保证搜索的效率，要大致保证每层的节点数目与上节的结构相当。下面是一个随机生成的跳表：可以看到它每层的节点数还和上节的结构差不多，但是上下层的节点的对应关系已经完全被打破了。现在假设节点 17 是最后插入的，在插入之前，我们需要搜索得到插入的位置：接着，抛硬币决定要建立几层的索引，伪代码如下：randomLevel() lvl := 1 -- random() that returns a random value in [0...1) while random() &amp;lt; p and lvl &amp;lt; MaxLevel do lvl := lvl + 1 return lvl上面的伪代码相当于抛硬币，如果是正面（random() &amp;lt; p）则层数加一，直到抛出反面为止。其中的 MaxLevel 是防止如果运气太好，层数就会太高，而太高的层数往往并不会提供额外的性能，一般 $ MaxLevel=log_{1/p} n $。现在假设 randomLevel 返回的结果是 2，那么就得到下面的结果。如果要删除节点，则把节点和对应的所有索引节点全部删除即可。当然，要删除节点时需要先搜索得到该节点，搜索过程中可以把路径记录下来，这样删除索引层节点的时候就不需要多次搜索了。显然，在最坏的情况下，所有节点都没有创建索引，时间复杂度为O(n)，但在平均情况下，搜索的时间复杂度却是 O(logn)，为什么呢？简单的性能分析一些严格的证明会涉及到比较复杂的概率统计学知识，所以这里只是简单地说明。每层的节点数目上面我们提到 MaxLevel，原版论文 中用 L(n) 来表示，要求 L(n) 层有 1/p 个节点，在搜索时可以不理会比 L(n) 更高的层数，直接从 L(n) 层开始搜索，这样效率最高。直观上看，第 $ l $ 层的节点中在第 $ l+1 $ 层也有索引的个数是 $ n_{l+1}=n_{lp} $ 因此第 $ l $ 层的节点个数为：\\(n_l = np^{l-1}\\)于是代入\\[n_{L(n)} = 1/p\\]得到\\[L(n) = log_{1/p}n\\]最高的层数上面推导到每层的节点数目，直观上看，如果某一层的节点数目小于等于 1，则可以认为它是最高层了代入\\[np^{l-1} = 1\\]得到层数\\[L_{max} = log_{1/p}n+1 = L(n) + 1 = O(log n)\\]实际上这个问题并没有直接的解析解，我们能知道的是，当 $ n $ 足够大时，最大能达到的层数为 $ O(logn) $搜索的时间复杂度为了计算搜索的时间复杂度，我们可以将查找的过程倒过来，从搜索最后的节点开始，一直向左或向上，直到最顶层。如下图，在路径上的每一点，都可能有两种情况： 节点有上一层的节点，向上。这种情况出现的概率是 p。 节点没有上一层的节点，向左。出现的概率是 1-p。于是，设 C(k) 为反向搜索爬到第 k 层的平均路径长度，则有：C(0) = 0C(k) = p * (情况1) + (1-p) * (情况2)将两种情况也用 C 代入，有C(k) = p*(1 + C(k–1)) + (1–p)*(1 + C(k))C(k) = C(k–1) + 1/pC(k) = k/p上式表明，搜索时，平均在每层上需要搜索的路径长度为 1/p，从平均的角度上和我们第一小节构造的“静态”结构相同（p 取 1/2）。又注意到，上小节我们知道跳表的最大层数为 $ O(logn) $，因此，搜索的复杂度 $ O(logn)/p=O(logn) $。这里我们用到的是最大层数，原论文证明时用到的是 L(n)，然后再考虑从 L(n) 层到最高层的平均节点个数小结 各种搜索结构提高效率的方式都是通过空间换时间得到的。 跳表最终形成的结构和搜索树很相似。 跳表通过随机的方式来决定新插入节点来决定索引的层数。 跳表搜索的时间复杂度是 $ O(logn) $，插入/删除也是" }, { "title": "布隆过滤器原理和使用方法", "url": "/posts/bloom-filter-principle-and-usage/", "categories": "Bottom Layer Knowledge", "tags": "Data Structure", "date": "2022-02-19 18:09:00 +0800", "snippet": "布隆过滤器是程序员的一把利器，利用它可以快速地解决项目中一些比较棘手的问题。如网页 URL 去重、垃圾邮件识别、大集合中重复元素的判断和缓存穿透等问题。布隆过滤器（Bloom Filter）是 1970 年由布隆提出的。它实际上是一个很长的二进制向量和一系列随机映射函数。布隆过滤器可以用于检索一个元素是否在一个集合中。它的优点是空间效率和查询时间都比一般的算法要好的多，缺点是有一定的误识别率和删除困难。布隆过滤器简介当你往简单数组或列表中插入新数据时，将不会根据插入项的值来确定该插入项的索引值。这意味着新插入项的索引值与数据值之间没有直接关系。这样的话，当你需要在数组或列表中搜索相应值的时候，你必须遍历已有的集合。若集合中存在大量的数据，就会影响数据查找的效率。针对这个问题，你可以考虑使用哈希表。利用哈希表你可以通过对 “值” 进行哈希处理来获得该值对应的键或索引值，然后把该值存放到列表中对应的索引位置。这意味着索引值是由插入项的值所确定的，当你需要判断列表中是否存在该值时，只需要对值进行哈希处理并在相应的索引位置进行搜索即可，这时的搜索速度是非常快的。根据定义，布隆过滤器可以检查值是 “可能在集合中” 还是 “绝对不在集合中”。“可能” 表示有一定的概率，也就是说可能存在一定为误判率。那为什么会存在误判呢？下面我们来分析一下具体的原因。布隆过滤器（Bloom Filter）本质上是由长度为 m 的位向量或位列表（仅包含 0 或 1 位值的列表）组成，最初所有的值均设置为 0，如下图所示。为了将数据项添加到布隆过滤器中，我们会提供 K 个不同的哈希函数，并将结果位置上对应位的值置为 “1”。在前面所提到的哈希表中，我们使用的是单个哈希函数，因此只能输出单个索引值。而对于布隆过滤器来说，我们将使用多个哈希函数，这将会产生多个索引值。如上图所示，当输入 “semlinker” 时，预设的 3 个哈希函数将输出 2、4、6，我们把相应位置 1。假设另一个输入 ”kakuqo“，哈希函数输出 3、4 和 7。你可能已经注意到，索引位 4 已经被先前的 “semlinker” 标记了。此时，我们已经使用 “semlinker” 和 ”kakuqo“ 两个输入值，填充了位向量。当前位向量的标记状态为：当对值进行搜索时，与哈希表类似，我们将使用 3 个哈希函数对 ”搜索的值“ 进行哈希运算，并查看其生成的索引值。假设，当我们搜索 ”fullstack“ 时，3 个哈希函数输出的 3 个索引值分别是 2、3 和 7：从上图可以看出，相应的索引位都被置为 1，这意味着我们可以说 ”fullstack“ 可能已经插入到集合中。事实上这是误报的情形，产生的原因是由于哈希碰撞导致的巧合而将不同的元素存储在相同的比特位上。幸运的是，布隆过滤器有一个可预测的误判率（FPP）：\\[P_{pf} = (1 - e ^ {- {kn \\over m}})^k\\] n 是已经添加元素的数量； k 哈希的次数； m 布隆过滤器的长度（如比特数组的大小）；极端情况下，当布隆过滤器没有空闲空间时（满），每一次查询都会返回 true 。这也就意味着 m 的选择取决于期望预计添加元素的数量 n ，并且 m 需要远远大于 n 。实际情况中，布隆过滤器的长度 m 可以根据给定的误判率（FFP）的和期望添加的元素个数 n 的通过如下公式计算：\\[m = - {n ln P_{pf} \\over (ln2)^2}\\]了解完上述的内容之后，我们可以得出一个结论，当我们搜索一个值的时候，若该值经过 K 个哈希函数运算后的任何一个索引位为 ”0“，那么该值肯定不在集合中。但如果所有哈希索引值均为 ”1“，则只能说该搜索的值可能存在集合中。布隆过滤器应用在实际工作中，布隆过滤器常见的应用场景如下： 网页爬虫对 URL 去重，避免爬取相同的 URL 地址； 反垃圾邮件，从数十亿个垃圾邮件列表中判断某邮箱是否垃圾邮箱； Google Chrome 使用布隆过滤器识别恶意 URL； Medium 使用布隆过滤器避免推荐给用户已经读过的文章； Google BigTable，Apache HBbase 和 Apache Cassandra 使用布隆过滤器减少对不存在的行和列的查找。 除了上述的应用场景之外，布隆过滤器还有一个应用场景就是解决缓存穿透的问题。所谓- 的缓存穿透就是服务调用方每次都是查询不在缓存中的数据，这样每次服务调用都会到数据库中进行查询，如果这类请求比较多的话，就会导致数据库压力增大，这样缓存就失去了意义。利用布隆过滤器我们可以预先把数据查询的主键，比如用户 ID 或文章 ID 缓存到过滤器中。当根据 ID 进行数据查询的时候，我们先判断该 ID 是否存在，若存在的话，则进行下一步处理。若不存在的话，直接返回，这样就不会触发后续的数据库查询。需要注意的是缓存穿透不能完全解决，我们只能将其控制在一个可以容忍的范围内。布隆过滤器实战布隆过滤器有很多实现和优化，由 Google 开发著名的 Guava 库就提供了布隆过滤器（Bloom Filter）的实现。在基于 Maven 的 Java 项目中要使用 Guava 提供的布隆过滤器，只需要引入以下依赖：&amp;lt;dependency&amp;gt; &amp;lt;groupId&amp;gt;com.google.guava&amp;lt;/groupId&amp;gt; &amp;lt;artifactId&amp;gt;guava&amp;lt;/artifactId&amp;gt; &amp;lt;version&amp;gt;28.0-jre&amp;lt;/version&amp;gt;&amp;lt;/dependency&amp;gt;在导入 Guava 库后，我们新建一个 BloomFilterDemo 类，在 main 方法中我们通过 BloomFilter.create 方法来创建一个布隆过滤器，接着我们初始化 1 百万条数据到过滤器中，然后在原有的基础上增加 10000 条数据并判断这些数据是否存在布隆过滤器中：import com.google.common.base.Charsets;import com.google.common.hash.BloomFilter;import com.google.common.hash.Funnels;public class BloomFilterDemo { public static void main(String[] args) { int total = 1000000; // 总数量 BloomFilter&amp;lt;CharSequence&amp;gt; bf = BloomFilter.create(Funnels.stringFunnel(Charsets.UTF_8), total); // 初始化 1000000 条数据到过滤器中 for (int i = 0; i &amp;lt; total; i++) { bf.put(&quot;&quot; + i); } // 判断值是否存在过滤器中 int count = 0; for (int i = 0; i &amp;lt; total + 10000; i++) { if (bf.mightContain(&quot;&quot; + i)) { count++; } } System.out.println(&quot;已匹配数量 &quot; + count); }}当以上代码运行后，控制台会输出以下结果：已匹配数量 1000309很明显以上的输出结果已经出现了误报，因为相比预期的结果多了 309 个元素，误判率为：309/(1000000 + 10000) * 100 ≈ 0.030594059405940593如果要提高匹配精度的话，我们可以在创建布隆过滤器的时候设置误判率 fpp：BloomFilter&amp;lt;CharSequence&amp;gt; bf = BloomFilter.create( Funnels.stringFunnel(Charsets.UTF_8), total, 0.0002);在 BloomFilter 内部，误判率 fpp 的默认值是 0.03：public static &amp;lt;T&amp;gt; BloomFilter&amp;lt;T&amp;gt; create(Funnel&amp;lt;? super T&amp;gt; funnel, long expectedInsertions) { return create(funnel, expectedInsertions, 0.03D);}在重新设置误判率为 0.0002 之后，我们重新运行程序，这时控制台会输出以下结果：已匹配数量 1000003通过观察以上的结果，可知误判率 fpp 的值越小，匹配的精度越高。当减少误判率 fpp 的值，需要的存储空间也越大，所以在实际使用过程中需要在误判率和存储空间之间做个权衡。" }, { "title": "Redis 缓存雪崩、击穿、穿透", "url": "/posts/redis-cache-avalanche-breakdown-penetration/", "categories": "Software Development", "tags": "Redis, Internet Security", "date": "2022-02-19 16:51:00 +0800", "snippet": "缓存雪崩雪崩定义举个简单的例子:如果所有首页的Key失效时间都是12小时，中午12点刷新的，假设有个秒杀活动大量用户涌入，假设当时每秒 6000 个请求，本来缓存在可以扛住每秒 5000 个请求，但是缓存当时所有的Key都失效了。此时 1 秒 6000 个请求全部落数据库，数据库必然扛不住，它会报一下警，真实情况可能DBA都没反应过来就直接挂了。此时，如果没用什么特别的方案来处理这个故障，DBA 很着急，重启数据库，但是数据库立马又被新的流量给打死了。同一时间大面积失效，那一瞬间Redis跟没有一样，那这个数量级别的请求直接打到数据库几乎是灾难性的，如果打挂的是一个用户服务的库，那其他依赖他的库所有的接口几乎都会报错，如果没做熔断等策略基本上就是瞬间挂一片的节奏雪崩解决方案处理缓存雪崩简单，在批量往Redis存数据的时候，把每个Key的失效时间都加个随机值就好了，这样可以保证数据不会在同一时间大面积失效setRedis(Key, alue, ime + Math.random() * 10000);如果Redis是集群部署，将热点数据均匀分布在不同的Redis库中也能避免全部失效的问题，如果单个服务都是对应的单个Redis分片，可以为了方便数据的管理，但是也同样有了可能会失效这样的弊端，失效时间随机是个好策略。或者设置热点数据永远不过期，有更新操作就更新缓存就好了（比如运维更新了首页商品，那刷下缓存就完事了，不要设置过期时间），电商首页的数据也可以用这个操作，保险。缓存穿透穿透定义缓存穿透是指缓存和数据库中都没有的数据，而用户不断发起请求，我们数据库的 id 都是1开始自增上去的，如发起为id值为 -1 的数据或 id 为特别大不存在的数据。这时的用户很可能是攻击者，攻击会导致数据库压力过大，严重会击垮数据库如果不对参数做校验，数据库id都是大于0的，我一直用小于0的参数去请求你，每次都能绕开Redis直接打到数据库，数据库也查不到，每次都这样，并发高点就容易崩掉了穿透解决方案缓存穿透可以在接口层增加校验，比如用户鉴权校验，参数做校验，不合法的参数直接代码Return，比如：id 做基础校验，id &amp;lt;=0的直接拦截等。 永远不要不要相信任何调用方，记得做参数校验，你永远不知道有多少在酒吧点炒饭的用户举个简单的例子，你这个接口是分页查询的，但是你没对分页参数的大小做限制，调用的人万一一口气查 Integer.MAX_VALUE 一次请求就要你几秒，多几个并发你不就挂了么从缓存取不到的数据，在数据库中也没有取到，这时也可以将对应Key的Value对写为null、位置错误、稍后重试这样的值具体取啥问产品，或者看具体的场景，缓存有效时间可以设置短点，如30秒（设置太长会导致正常情况也没法使用）。这样可以防止攻击用户反复用同一个id暴力攻击，但是我们要知道正常用户是不会在单秒内发起这么多次请求的，那网关层Nginx本渣我也记得有配置项，可以让运维大大对单个IP每秒访问次数超出阈值的IP都拉黑。布隆过滤器（Bloom Filter）Redis还有一个高级用法布隆过滤器（Bloom Filter）这个也能很好的防止缓存穿透的发生，原理也很简单就是利用高效的数据结构和算法快速判断出你这个Key是否在数据库中存在，不存在return就好了，存在就去查了DB刷新KV再return。布隆过滤器原理和使用方法缓存击穿击穿定义缓存击穿嘛，这个跟缓存雪崩有点像，但是又有一点不一样，缓存雪崩是因为大面积的缓存失效，打崩了DB，而缓存击穿不同的是缓存击穿是指一个Key非常热点，在不停的扛着大并发，大并发集中对这一个点进行访问，当这个Key在失效的瞬间，持续的大并发就穿破缓存，直接请求数据库，就像在一个完好无损的桶上凿开了一个洞。击穿解决方案设置热点数据永远不过期。或者加上互斥锁就能搞定了" }, { "title": "B树和B+树的插入、删除解析", "url": "/posts/b-tree-and-b-tree-insert-and-delete/", "categories": "Bottom Layer Knowledge", "tags": "Data Structure", "date": "2022-02-15 20:05:00 +0800", "snippet": "B树B树的定义B树也称B-树,它是一颗多路平衡查找树。我们描述一颗B树时需要指定它的阶数，阶数表示了一个结点最多有多少个孩子结点，一般用字母m表示阶数。当m取2时，就是我们常见的二叉搜索树。 颗m阶的B树定义如下： 每个结点最多有m-1个关键字。 1根结点最少可以只有1个关键字。 1非根结点至少有Math.ceil(m/2)-1个关键字。 1每个结点中的关键字都按照从小到大的顺序排列，每个关键字的左子树中的所有关键字都小于它，而右子树中的所有关键字都大于它。 1所有叶子结点都位于同一层，或者说根结点到每个叶子结点的长度都相同。上图是一颗阶数为4的B树。在实际应用中的B树的阶数m都非常大（通常大于100），所以即使存储大量的数据，B树的高度仍然比较小。每个结点中存储了关键字（key）和关键字对应的数据（data），以及孩子结点的指针。我们将一个key和其对应的data称为一个记录。但为了方便描述，除非特别说明，后续文中就用key来代替（key, value）键值对这个整体。在数据库中我们将B树（和B+树）作为索引结构，可以加快查询速速，此时B树中的key就表示键，而data表示了这个键对应的条目在硬盘上的逻辑地址。B树的插入操作插入操作是指插入一条记录，即（key, value）的键值对。如果B树中已存在需要插入的键值对，则用需要插入的value替换旧的value。若B树不存在这个key,则一定是在叶子结点中进行插入操作。 根据要插入的key的值，找到叶子结点并插入。 判断当前结点key的个数是否小于等于m-1，若满足则结束，否则进行第3步。 以结点中间的key为中心分裂成左右两部分，然后将这个中间的key插入到父结点中，这个key的左子树指向分裂后的左半部分，这个key的右子支指向分裂后的右半部分，然后将当前结点指向父结点，继续进行第3步。 下面以5阶B树为例，介绍B树的插入操作，在5阶B树中，结点最多有4个key,最少有2个key 在空树中插入39 此时根结点就一个key，此时根结点也是叶子结点 继续插入22，97和41 根结点此时有4个key 继续插入53 插入后超过了最大允许的关键字个数4，所以以key值为41为中心进行分裂，结果如下图所示，分裂后当前结点指针指向父结点，满足B树条件，插入操作结束。当阶数m为偶数时，需要分裂时就不存在排序恰好在中间的key，那么我们选择中间位置的前一个key或中间位置的后一个key为中心进行分裂即可。 依次插入13，21，40，同样会造成分裂，结果如下图所示。 依次插入30，27, 33 ；36，35，34 ；24，29，结果如下图所示。 插入key值为26的记录，插入后的结果如下图所示。 当前结点需要以27为中心分裂，并向父结点进位27，然后当前结点指向父结点，结果如下图所示。 分裂后当前结点指向新的根，此时无需调整。 分裂后当前结点指向新的根，此时无需调整。 最后再依次插入key为17,28,29,31,32的记录，结果如下图所示。 在实现B树的代码中，为了使代码编写更加容易，我们可以将结点中存储记录的数组长度定义为m而非m-1，这样方便底层的结点由于分裂向上层插入一个记录时，上层有多余的位置存储这个记录。同时，每个结点还可以存储它的父结点的引用，这样就不必编写递归程序。一般来说，对于确定的m和确定类型的记录，结点大小是固定的，无论它实际存储了多少个记录。但是分配固定结点大小的方法会存在浪费的情况，比如key为28,29所在的结点，还有2个key的位置没有使用，但是已经不可能继续在插入任何值了，因为这个结点的前序key是27,后继key是30,所有整数值都用完了。所以如果记录先按key的大小排好序，再插入到B树中，结点的使用率就会很低，最差情况下使用率仅为50%。B树的删除操作删除操作是指，根据key删除记录，如果B树中的记录中不存对应key的记录，则删除失败。 如果当前需要删除的key位于非叶子结点上，则用后继key（这里的后继key均指后继记录的意思）覆盖要删除的key，然后在后继key所在的子支中删除该后继key。此时后继key一定位于叶子结点上，这个过程和二叉搜索树删除结点的方式类似。删除这个记录后执行第2步 该结点key个数大于等于Math.ceil(m/2)-1，结束删除操作，否则执行第3步。 如果兄弟结点key个数大于Math.ceil(m/2)-1，则父结点中的key下移到该结点，兄弟结点中的一个key上移，删除操作结束。否则，将父结点中的key下移与当前结点及它的兄弟结点中的key合并，形成一个新的结点。原父结点中的key的两个孩子指针就变成了一个孩子指针，指向这个新结点。然后当前结点的指针指向父结点，重复上第2步。有些结点它可能即有左兄弟，又有右兄弟，那么我们任意选择一个兄弟结点进行操作即可。下面以5阶B树为例，介绍B树的删除操作，5阶B树中，结点最多有4个key,最少有2个key 原始状态 在上面的B树中删除21，删除后结点中的关键字个数仍然大于等2，所以删除结束。 在上述情况下接着删除27。从上图可知27位于非叶子结点中，所以用27的后继替换它。从图中可以看出，27的后继为28，我们用28替换27，然后在28（原27）的右孩子结点中删除28。删除后的结果如 删除后发现，当前叶子结点的记录的个数小于2，而它的兄弟结点中有3个记录（当前结点还有一个右兄弟，选择右兄弟就会出现合并结点的情况，不论选哪一个都行，只是最后B树的形态会不一样而已），我们可以从兄弟结点中借取一个key。所以父结点中的28下移，兄弟结点中的26上移,删除结束。结果如下图所示。 在上述情况下接着32，结果如下图。 当删除后，当前结点中只key，而兄弟结点中也仅有2个key。所以只能让父结点中的30下移和这个两个孩子结点中的key合并，成为一个新的结点，当前结点的指针指向父结点。结果如下图所示。 当前结点key的个数满足条件，故删除结束。 上述情况下，我们接着删除key为40的记录，删除后结果如下图所示。 同理，当前结点的记录数小于2，兄弟结点中没有多余key，所以父结点中的key下移，和兄弟（这里我们选择左兄弟，选择右兄弟也可以）结点合并，合并后的指向当前结点的指针就指向了父结点。 同理，对于当前结点而言只能继续合并了，最后结果如下所示。 合并后结点当前结点满足条件，删除结束。B+树B+树的定义各种资料上B+树的定义各有不同，一种定义方式是关键字个数和孩子结点个数相同。这里我们采取维基百科上所定义的方式，即关键字个数比孩子结点个数小1，这种方式是和B树基本等价的。上图就是一颗阶数为4的B+树。除此之外B+树还有以下的要求。 B+树包含2种类型的结点：内部结点（也称索引结点）和叶子结点。根结点本身即可以是内部结点，也可以是叶子结点。根结点的关键字个数最少可以只有1个。 B+树与B树最大的不同是内部结点不保存数据，只用于索引，所有数据（或者说记录）都保存在叶子结点中。 m阶B+树表示了内部结点最多有m-1个关键字（或者说内部结点最多有m个子树），阶数m同时限制了叶子结点最多存储m-1个记录。 内部结点中的key都按照从小到大的顺序排列，对于内部结点中的一个key，左树中的所有key都小于它，右子树中的key都大于等于它。叶子结点中的记录也按照key的大小排列。 每个叶子结点都存有相邻叶子结点的指针，叶子结点本身依关键字的大小自小而大顺序链接。B+树的插入操作 若为空树，创建一个叶子结点，然后将记录插入其中，此时这个叶子结点也是根结点，插入操作结束。 针对叶子类型结点：根据key值找到叶子结点，向这个叶子结点插入记录。插入后，若当前结点key的个数小于等于m-1，则插入结束。否则将这个叶子结点分裂成左右两个叶子结点，左叶子结点包含前m/2个记录，右结点包含剩下的记录，将第m/2+1个记录的key进位到父结点中（父结点一定是索引类型结点），进位到父结点的key左孩子指针向左结点,右孩子指针向右结点。将当前结点的指针指向父结点，然后执行第3步。 针对索引类型结点：若当前结点key的个数小于等于m-1，则插入结束。否则，将这个索引类型结点分裂成两个索引结点，左索引结点包含前(m-1)/2个key，右结点包含m-(m-1)/2个key，将第m/2个key进位到父结点中，进位到父结点的key左孩子指向左结点, 进位到父结点的key右孩子指向右结点。将当前结点的指针指向父结点，然后重复第3步。 下面是一颗5阶B树的插入过程，5阶B数的结点最少2个key，最多4个key。 空树中插入5 依次插入8，10，15 插入16 插入16后超过了关键字的个数限制，所以要进行分裂。在叶子结点分裂时，分裂出来的左结点2个记录，右边3个记录，中间key成为索引结点中的key，分裂后当前结点指向了父结点（根结点）。结果如下图所示。 当然我们还有另一种分裂方式，给左结点3个记录，右结点2个记录，此时索引结点中的key就变为15。 插入17 插入18，插入后如下图所示 当前结点的关键字个数大于5，进行分裂。分裂成两个结点，左结点2个记录，右结点3个记录，关键字16进位到父结点（索引类型）中，将当前结点的指针指向父结点。 当前结点的关键字个数满足条件，插入结束。 插入若干数据后 在上图中插入7，结果如下图所示 当前结点的关键字个数超过4，需要分裂。左结点2个记录，右结点3个记录。分裂后关键字7进入到父结点中，将当前结点的指针指向父结点，结果如下图所示。 当前结点的关键字个数超过4，需要继续分裂。左结点2个关键字，右结点2个关键字，关键字16进入到父结点中，将当前结点指向父结点，结果如下图所示。 当前结点的关键字个数满足条件，插入结束。B+树的删除操作如果叶子结点中没有相应的key，则删除失败。否则执行下面的步骤 删除叶子结点中对应的key。删除后若结点的key的个数大于等于Math.ceil(m-1)/2 – 1，删除操作结束,否则执行第2步。 若兄弟结点key有富余（大于Math.ceil(m-1)/2 – 1），向兄弟结点借一个记录，同时用借到的key替换父结（指当前结点和兄弟结点共同的父结点）点中的key，删除结束。否则执行第3步。 若兄弟结点中没有富余的key,则当前结点和兄弟结点合并成一个新的叶子结点，并删除父结点中的key（父结点中的这个key两边的孩子指针就变成了一个指针，正好指向这个新的叶子结点），将当前结点指向父结点（必为索引结点），执行第4步（第4步以后的操作和B树就完全一样了，主要是为了更新索引结点）。 若索引结点的key的个数大于等于Math.ceil(m-1)/2 – 1，则删除操作结束。否则执行第5步 若兄弟结点有富余，父结点key下移，兄弟结点key上移，删除结束。否则执行第6步 当前结点和兄弟结点及父结点下移key合并成一个新的结点。将当前结点指向父结点，重复第4步。注意，通过B+树的删除操作后，索引结点中存在的key，不一定在叶子结点中存在对应的记录。下面是一颗5阶B树的删除过程，5阶B数的结点最少2个key，最多4个key。 初始状态 删除22,删除后结果如下图 删除后叶子结点中key的个数大于等于2，删除结束 删除15，删除后的结果如下图所示 删除后当前结点只有一个key,不满足条件，而兄弟结点有三个key，可以从兄弟结点借一个关键字为9的记录,同时更新将父结点中的关键字由10也变为9，删除结束。 删除7，删除后的结果如下图所示 当前结点关键字个数小于2，（左）兄弟结点中的也没有富余的关键字（当前结点还有个右兄弟，不过选择任意一个进行分析就可以了，这里我们选择了左边的），所以当前结点和兄弟结点合并，并删除父结点中的key，当前结点指向父结点。 此时当前结点的关键字个数小于2，兄弟结点的关键字也没有富余，所以父结点中的关键字下移，和两个孩子结点合并，结果如下图所示。 参考内容 B+树介绍 从MySQL Bug#67718浅谈B+树索引的分裂优化 B+树的几点总结" }, { "title": "数据库事务隔离级别", "url": "/posts/database-transaction-isolation-level/", "categories": "Software Development", "tags": "DataBase", "date": "2022-02-08 16:45:00 +0800", "snippet": "数据库事务的隔离级别有4个，由低到高依次为Read uncommitted 、Read committed、Repeatable read 、Serializable ，这四个级别可以逐个解决脏读 、不可重复读 、幻读 这几类问题。√: 可能出现 ×: 不会出现   脏读 不可重复读 幻读 Read uncommitted √ √ √ Read committed × √ √ Repeatable read × × √ Serializable × × × 注意：我们讨论隔离级别的场景，主要是在多个事务并发 的情况下，因此，接下来的讲解都围绕事务并发。Read uncommitted 读未提交公司发工资了，领导把5000元打到singo的账号上，但是该事务并未提交，而singo正好去查看账户，发现工资已经到账，是5000元整，非常高 兴。可是不幸的是，领导发现发给singo的工资金额不对，是2000元，于是迅速回滚了事务，修改金额后，将事务提交，最后singo实际的工资只有 2000元，singo空欢喜一场。出现上述情况，即我们所说的脏读 ，两个并发的事务，“事务A：领导给singo发工资”、“事务B：singo查询工资账户”，事务B读取了事务A尚未提交的数据。当隔离级别设置为Read uncommitted 时，就可能出现脏读，如何避免脏读，请看下一个隔离级别。Read committed 读提交singo拿着工资卡去消费，系统读取到卡里确实有2000元，而此时她的老婆也正好在网上转账，把singo工资卡的2000元转到另一账户，并在 singo之前提交了事务，当singo扣款时，系统检查到singo的工资卡已经没有钱，扣款失败，singo十分纳闷，明明卡里有钱，为 何……出现上述情况，即我们所说的不可重复读 ，两个并发的事务，“事务A：singo消费”、“事务B：singo的老婆网上转账”，事务A事先读取了数据，事务B紧接了更新了数据，并提交了事务，而事务A再次读取该数据时，数据已经发生了改变。当隔离级别设置为Read committed 时，避免了脏读，但是可能会造成不可重复读。大多数数据库的默认级别就是Read committed，比如Sql Server , Oracle。如何解决不可重复读这一问题，请看下一个隔离级别。Repeatable read 重复读当隔离级别设置为Repeatable read 时，可以避免不可重复读。当singo拿着工资卡去消费时，一旦系统开始读取工资卡信息（即事务开始），singo的老婆就不可能对该记录进行修改，也就是singo的老婆不能在此时转账。虽然Repeatable read避免了不可重复读，但还有可能出现幻读 。singo的老婆工作在银行部门，她时常通过银行内部系统查看singo的信用卡消费记录。有一天，她正在查询到singo当月信用卡的总消费金额 （select sum(amount) from transaction where month = 本月）为80元，而singo此时正好在外面胡吃海塞后在收银台买单，消费1000元，即新增了一条1000元的消费记录（insert transaction … ），并提交了事务，随后singo的老婆将singo当月信用卡消费的明细打印到A4纸上，却发现消费总额为1080元，singo的老婆很诧异，以为出 现了幻觉，幻读就这样产生了。 注：Mysql的默认隔离级别就是Repeatable read。Serializable 序列化Serializable 是最高的事务隔离级别，同时代价也花费最高，性能很低，一般很少使用，在该级别下，事务顺序执行，不仅可以避免脏读、不可重复读，还避免了幻像读。" }, { "title": "HashMap的原理和动态扩容", "url": "/posts/the-principle-of-hashmap-and-dynamic-scaling/", "categories": "Software Development", "tags": "Java, Data Structure", "date": "2022-02-03 16:34:00 +0800", "snippet": "HashMap的底层实现HashMap基于Map接口实现，继承AbstractMap，它存储的内容是键值对(key:value)，它的key是唯一的，且key和value都可以为null。此外，HashMap中的映射不是有序的。HashMap 的实现不是同步的，这意味着它不是线程安全的。如果想要线程安全的HashMap，可以通过Collections类的静态方法synchronizedMap获得线程安全的HashMap，或者ConcurrentHashmap。它之所以有相当快的查询速度主要是因为它是通过计算哈希值来决定存储的位置。初始容量，负载因子是影响HashMap性能的重要参数。其中容量表示HashMap中数组的大小，初始容量是创建HashMap时的容量，负载因子是HashMap在其扩容之前可以达到多满的一种尺度，它衡量的是HashMap的空间的使用程度，负载因子越大表示HashMap元素的填满程度。负载因子越大，填满程度越高，好处是空间利用率高了，但冲突的机会加大了，链表长度会越来越长，查找效率降低。负载因子越小，填满程度越低，好处是冲突的机会减小了，但空间浪费严重，表中的数据将过于稀疏（很多空间还没用，就开始扩容了）。系统默认负载因子为0.75，一般情况下我们是无需修改的。JDK1.8之前和JDK1.8之后的内部结构JDK1.8 之前 HashMap 底层是数组和链表结合在一起使用也就是链表散列。HashMap 通过 key 的 hashCode 经过扰动函数处理过后得到 hash 值，然后通过hash &amp;amp; (n - 1) 判断当前元素存放的位置（这里的 n 指的是数组的长度），如果当前位置存在元素的话，就判断该元素与要存入的元素的 hash 值以及 key 是否相同，如果相同的话，直接覆盖，不相同就通过拉链法解决冲突。所谓扰动函数指的就是 HashMap 的 hash 方法。使用 hash 方法也就是扰动函数是为了防止一些实现比较差的 hashCode() 方法 换句话说使用扰动函数之后可以减少碰撞。JDK 1.8 HashMap 的 hash 方法源码如下，相比于 JDK 1.7 hash 方法更加简化，但是原理不变。static final int hash(Object key) { int h; // key.hashCode()：返回散列值也就是hashcode // ^ ：按位异或 // &amp;gt;&amp;gt;&amp;gt;:无符号右移，忽略符号位，空位都以0补齐 return (key == null) ? 0 : (h = key.hashCode()) ^ (h &amp;gt;&amp;gt;&amp;gt; 16);}对比一下 JDK1.7的 HashMap 的 hash 方法源码.static int hash(int h) { // This function ensures that hashCodes that differ only by // constant multiples at each bit position have a bounded // number of collisions (approximately 8 at default load factor). h ^= (h &amp;gt;&amp;gt;&amp;gt; 20) ^ (h &amp;gt;&amp;gt;&amp;gt; 12); return h ^ (h &amp;gt;&amp;gt;&amp;gt; 7) ^ (h &amp;gt;&amp;gt;&amp;gt; 4);}整个过程本质上就是三步： 拿到key的hashCode值 将hashCode的高位参与运算，重新计算hash值 将计算出来的hash值与(table.length - 1)进行&amp;amp;运算相比于 JDK1.8 的 hash 方法 ，JDK 1.7 的 hash 方法的性能会稍差一点点，因为毕竟扰动了 4 次。所谓 “拉链法” 就是：将链表和数组相结合。也就是说创建一个链表数组，数组中每个格就是一个链表。若遇到哈希冲突，则将冲突键值以头插或者尾插的方式插入数组下标所在的链表。JDK1.8之前的内部结构相比于之前的版本， JDK1.8之后在解决哈希冲突时有了较大的变化，当链表长度大于阈值（默认为8）时且数组长度不小于64时，将链表转化为红黑树，以减少搜索时间。JDK1.8之后的HashMap底层数据结构TreeMap、TreeSet以及JDK1.8之后的HashMap底层都用到了红黑树。红黑树就是为了解决二叉查找树的缺陷，因为二叉查找树在某些情况下会退化成一个线性结构。一句话总结：JDK1.8后，HashMap存储的数据结构由数组+链表的方式，变化为数组+链表+红黑树的方式，在性能上进一步得到提升。HashMap扩容什么时候扩容JDK 1.7:扩容必须同时满足两个条件： 存放新值的时候当前已有元素的个数达到阈值； 存放新值的时候发生哈希冲突（当前key的hash值计算出来的数组下标位置已存在值）JDK 1.8:发生扩容的时候有两种情况： 已有的元素达到阈值了； HashMap准备转为红黑树但又发现数组长度小于64。扩容方法JDK 1.7 新建一个数组，容量为原来的2倍，并通过transfer方法，遍历原来table中每个位置的链表，并对每个元素进行重新hash，得到在新数组的位置后插入。最后重新计算阈值。 并发时可能会产生死锁：复制链表时逆序，形成环形链表。 因为原数组中的数据必须重新计算其在新数组中的位置，再放进新数组，特别耗性能。如果我们已经预知HashMap中元素的个数，那么预设元素的个数能够有效的提高HashMap的性能，避免map进行频繁的扩容。JDK 1.8 不管怎么样都不需要重新再计算hash； 复制链表时元素的相对顺序不会改变； 不会在并发扩容中发生死锁。HashMap 的长度必须是2的整数次幂 HashMap的数组长度一定保持2的整数次幂，比如长度16的二进制表示为 10000，那么n-1就是15，二进制为01111，同理扩容后的数组长度为32，二进制表示为100000，n-1为31，二进制表示为011111。这样会保证低位全为1，而扩容后只有一位差异，也就是多出了最左位的1，这样在计算 h &amp;amp; (n-1)的时候，只要h对应的最左边的那一个差异位为0，就能保证得到的新的数组下标和旧数组下标一致，大大减少了之前已经哈希好的旧数组的数据位置重新调换。 n取2的整数次幂，n-1的值是低位全为1，这种情况下，对于h低位部分来说，任何一位的变化都会对结果产生影响，哈希冲突的几率降低，这样就能使元素在表中均匀地散列。 最后，n为2的整数次幂的话，h&amp;amp;(n-1)就相当于对n取模，位运算相比取余运算提升了效率。" }, { "title": "7种 JVM 垃圾回收器概览", "url": "/posts/7-kinds-of-jvm-garbage-collectors-overview/", "categories": "Software Development", "tags": "Java, JVM", "date": "2022-01-18 15:44:00 +0800", "snippet": "堆内存详解上面这个图大家应该已经很明白了吧。大家就可以理解成一个房子被分成了几个房间，每个房间的作用不同而已，有的是婴儿住的，有的是父母住的，有的是爷爷奶奶住的 堆内存被划分为两块，一块的年轻代，另一块是老年代。 年轻代又分为Eden和survivor。他俩空间大小比例默认为8:2, 幸存区又分为s0和s1。这两个空间大小是一模一样的，就是一对双胞胎，他俩是1:1的比例堆内存垃圾回收过程 新生成的对象首先放到Eden区，当Eden区满了会触发Minor GC。 第一步GC活下来的对象，会被移动到survivor区中的S0区，S0区满了之后会触发Minor GC，S0区存活下来的对象会被移动到S1区，S0区空闲。 S1满了之后在GC，存活下来的再次移动到S0区，S1区空闲，这样反反复复GC，每GC一次，对象的年龄就涨一岁，达到某个值后（15），就会进入老年代。 在发生一次Minor GC后（前提条件），老年代可能会出现Major GC，这个视垃圾回收器而定。Full GC触发条件 手动调用System.gc，会不断的执行Full GC 老年代空间不足/满了 方法区空间不足/满了 注意们需要记住一个单词：stop-the-world。它会在任何一种GC算法中发生。stop-the-world 意味着JVM因为需要执行GC而停止应用程序的执行。 当stop-the-world 发生时，除GC所需的线程外，所有的线程都进入等待状态，直到GC任务完成。GC优化很多时候就是减少stop-the-world 的发生。回收哪些区域的对象需要注意的是，JVM GC只回收堆内存和方法区内的对象。而栈内存的数据，在超出作用域后会被JVM自动释放掉，所以其不在JVM GC的管理范围内。堆内存常见参数配置 参数 描述 -Xms 堆内存初始大小，单位m、g -Xmx 堆内存最大允许大小，一般不要大于物理内存的80% -XX:PermSize 非堆内存初始大小，一般应用设置初始化200m，最大1024m就够了 -XX:MaxPermSize 非堆内存最大允许大小 -XX:NewSize（-Xns） 年轻代内存初始大小 -XX:MaxNewSize（-Xmn） 年轻代内存最大允许大小 -XX:SurvivorRatio=8 年轻代中Eden区与Survivor区的容量比例值，默认为8，即8:1 -Xss 堆栈内存大小 -XX:NewRatio=老年代/新生代 设置老年代和新生代的大小比例 -XX:+PrintGC jvm启动后，只要遇到GC就会打印日志 -XX:+PrintGCDetails 查看GC详细信息，包括各个区的情况 -XX:MaxDirectMemorySize 在NIO中可以直接访问直接内存，这个就是设置它的大小，不设置默认就是最大堆空间的值-Xmx -XX:+DisableExplicitGC 关闭System.gc() -XX:MaxTenuringThreshold 垃圾可以进入老年代的年龄 -Xnoclassgc 禁用垃圾回收 -XX:TLABWasteTargetPercent TLAB占eden区的百分比，默认是1% -XX:+CollectGen0First FullGC时是否先YGC，默认false TLAB 内存TLAB全称是Thread Local Allocation Buffer即线程本地分配缓存，从名字上看是一个线程专用的内存分配区域，是为了加速对象分配而生的。每一个线程都会产生一个TLAB，该线程独享的工作区域，java虚拟机使用这种TLAB区来避免多线程冲突问题，提高了对象分配的效率。TLAB空间一般不会太大，当大对象无法在TLAB分配时，则会直接分配到堆上。 参数 描述 -Xx:+UseTLAB 使用TLAB -XX:+TLABSize 设置TLAB大小 -XX:TLABRefillWasteFraction 设置维护进入TLAB空间的单个对象大小，他是一个比例值，默认为64，即如果对象大于整个空间的1/64，则在堆创建 -XX:+PrintTLAB 查看TLAB信息 -Xx:ResizeTLAB 自调整TLABRefillWasteFraction阀值。 垃圾回收器总览新生代可配置的回收器：Serial、ParNew、Parallel Scavenge老年代配置的回收器：CMS、Serial Old、Parallel Old新生代和老年代区域的回收器之间进行连线，说明他们之间可以搭配使用。新生代垃圾回收器Serial 垃圾回收器Serial收集器是最基本的、发展历史最悠久的收集器。俗称为：串行回收器，采用复制算法进行垃圾回收特点串行回收器是指使用单线程进行垃圾回收的回收器。每次回收时，串行回收器只有一个工作线程。对于并行能力较弱的单CPU计算机来说，串行回收器的专注性和独占性往往有更好的性能表现。它存在Stop The World问题，及垃圾回收时，要停止程序的运行。使用-XX:+UseSerialGC参数可以设置新生代使用这个串行回收器ParNew 垃圾回收器ParNew其实就是Serial的多线程版本，除了使用多线程之外，其余参数和Serial一模一样。俗称：并行垃圾回收器，采用复制算法进行垃圾回收特点ParNew默认开启的线程数与CPU数量相同，在CPU核数很多的机器上，可以通过参数-XX:ParallelGCThreads来设置线程数。它是目前新生代首选的垃圾回收器，因为除了ParNew之外，它是唯一一个能与老年代CMS配合工作的。它同样存在Stop The World问题使用-XX:+UseParNewGC参数可以设置新生代使用这个并行回收器ParallelGC 回收器ParallelGC使用复制算法回收垃圾，也是多线程的。特点就是非常关注系统的吞吐量，吞吐量=代码运行时间/(代码运行时间+垃圾收集时间)-XX:MaxGCPauseMillis：设置最大垃圾收集停顿时间，可用把虚拟机在GC停顿的时间控制在MaxGCPauseMillis范围内，如果希望减少GC停顿时间可以将MaxGCPauseMillis设置的很小，但是会导致GC频繁，从而增加了GC的总时间，降低了吞吐量。所以需要根据实际情况设置该值。-Xx:GCTimeRatio：设置吞吐量大小，它是一个0到100之间的整数，默认情况下他的取值是99，那么系统将花费不超过1/(1+n)的时间用于垃圾回收，也就是1/(1+99)=1%的时间。另外还可以指定-XX:+UseAdaptiveSizePolicy打开自适应模式，在这种模式下，新生代的大小、eden、from/to的比例，以及晋升老年代的对象年龄参数会被自动调整，以达到在堆大小、吞吐量和停顿时间之间的平衡点。使用-XX:+UseParallelGC参数可以设置新生代使用这个并行回收器老年代垃圾回收器SerialOld 垃圾回收器SerialOld是Serial回收器的老年代回收器版本，它同样是一个单线程回收器。用途 一个是在JDK1.5及之前的版本中与Parallel Scavenge收集器搭配使用， 另一个就是作为CMS收集器的后备预案，如果CMS出现Concurrent Mode Failure，则SerialOld将作为后备收集器。使用算法：标记 - 整理算法ParallelOldGC 回收器老年代ParallelOldGC回收器也是一种多线程的回收器，和新生代的ParallelGC回收器一样，也是一种关注吞吐量的回收器，他使用了标记压缩算法进行实现。-XX:+UseParallelOldGc进行设置老年代使用该回收器-XX:+ParallelGCThreads也可以设置垃圾收集时的线程数量CMS 回收器CMS全称为:Concurrent Mark Sweep意为并发标记清除，他使用的是标记清除法。主要关注系统停顿时间。使用-XX:+UseConcMarkSweepGC进行设置老年代使用该回收器。使用-XX:ConcGCThreads设置并发线程数量。特点CMS并不是独占的回收器，也就说CMS回收的过程中，应用程序仍然在不停的工作，又会有新的垃圾不断的产生，所以在使用CMS的过程中应该确保应用程序的内存足够可用。CMS不会等到应用程序饱和的时候才去回收垃圾，而是在某一阀值的时候开始回收，回收阀值可用指定的参数进行配置：-XX:CMSInitiatingoccupancyFraction来指定，默认为68，也就是说当老年代的空间使用率达到68%的时候，会执行CMS回收。如果内存使用率增长的很快，在CMS执行的过程中，已经出现了内存不足的情况，此时CMS回收就会失败，虚拟机将启动老年代串行回收器；SerialOldGC进行垃圾回收，这会导致应用程序中断，直到垃圾回收完成后才会正常工作。这个过程GC的停顿时间可能较长，所以-XX:CMSInitiatingoccupancyFraction的设置要根据实际的情况。之前我们在学习算法的时候说过，标记清除法有个缺点就是存在内存碎片的问题，那么CMS有个参数设置-XX:+UseCMSCompactAtFullCollecion可以使CMS回收完成之后进行一次碎片整理。-XX:CMSFullGCsBeforeCompaction参数可以设置进行多少次CMS回收之后，对内存进行一次压缩。G1 回收器G1收集器是一款在server端运行的垃圾收集器，专门针对于拥有多核处理器和大内存的机器，在JDK 7u4版本发行时被正式推出，在JDK9中更被指定为官方GC收集器。它满足高吞吐量的同时满足GC停顿的时间尽可能短。G1收集器专门针对以下应用场景设计 可以像CMS收集器一样可以和应用并发运行 压缩空闲的内存碎片，却不需要冗长的GC停顿 对GC停顿可以做更好的预测 不想牺牲大量的吞吐量性能 不需要更大的Java HeapG1从长期计划来看是以取代CMS为目标。与CMS相比有几个不同点使得G1成为GC的更好解决方案。第一点：G1会压缩空闲内存使之足够紧凑，做法是用regions代替细粒度的空闲列表进行分配，减少内存碎片的产生。第二点：G1的STW更可控，G1在停顿时间上添加了预测机制，用户可以指定期望停顿时间。G1收集器的特点 设置一个垃圾的预期停顿时间。根据Region的大小和回收价值进行最有效率的回收。 内存不再固定划分新生代和老年代，使用Region对于内存进行分块，实现了根据系统资源动态分代。 Region可能属于新生代或者老年代，同时分配给新生代还是老年代是由G1自己控制的。 选择最小回收时间以及最多回收对象的region进行垃圾的回收操作。" }, { "title": "JVM 的垃圾回收机制", "url": "/posts/jvm-gc-mechanism/", "categories": "Software Development", "tags": "Java, JVM", "date": "2022-01-17 20:08:00 +0800", "snippet": "哪些内存需要回收猿们都知道JVM的内存结构包括五大区域：程序计数器、虚拟机栈、本地方法栈、堆区、方法区。其中程序计数器、虚拟机栈、本地方法栈3个区域随线程而生、随线程而灭，因此这几个区域的内存分配和回收都具备确定性，就不需要过多考虑回收的问题，因为方法结束或者线程结束时，内存自然就跟随着回收了。而Java堆区和方法区则不一样、不一样!(怎么不一样说的朗朗上口)，这部分内存的分配和回收是动态的，正是垃圾收集器所需关注的部分。垃圾收集器在对堆区和方法区进行回收前，首先要确定这些区域的对象哪些可以被回收，哪些暂时还不能回收，这就要用到判断对象是否存活的算法！引用计数算法算法分析引用计数是垃圾收集器中的早期策略。在这种方法中，堆中每个对象实例都有一个引用计数。当一个对象被创建时，就将该对象实例分配给一个变量，该变量计数设置为1。当任何其它变量被赋值为这个对象的引用时，计数加1（a = b,则b引用的对象实例的计数器+1），但当一个对象实例的某个引用超过了生命周期或者被设置为一个新值时，对象实例的引用计数器减1。任何引用计数器为0的对象实例可以被当作垃圾收集。当一个对象实例被垃圾收集时，它引用的任何对象实例的引用计数器减1。优缺点-优点：引用计数收集器可以很快的执行，交织在程序运行中。对程序需要不被长时间打断的实时环境比较有利。-缺点：无法检测出循环引用。如父对象有一个对子对象的引用，子对象反过来引用父对象。这样，他们的引用计数永远不可能为0。示例代码public class ReferenceFindTest { public static void main(String[] args) { MyObject object1 = new MyObject(); MyObject object2 = new MyObject(); object1.object = object2; object2.object = object1; object1 = null; object2 = null; }}这段代码是用来验证引用计数算法不能检测出循环引用。最后面两句将object1和object2赋值为null，也就是说object1和object2指向的对象已经不可能再被访问，但是由于它们互相引用对方，导致它们的引用计数器都不为0，那么垃圾收集器就永远不会回收它们。可达性分析算法可达性分析算法是从离散数学中的图论引入的，程序把所有的引用关系看作一张图，从一个节点GC ROOT开始，寻找对应的引用节点，找到这个节点以后，继续寻找这个节点的引用节点，当所有的引用节点寻找完毕之后，剩余的节点则被认为是没有被引用到的节点，即无用的节点，无用的节点将会被判定为是可回收的对象。在Java语言中，可作为GC Roots的对象包括下面几种： 虚拟机栈中引用的对象（栈帧中的本地变量表）； 方法区中类静态属性引用的对象； 方法区中常量引用的对象； 本地方法栈中JNI（Native方法）引用的对象。Java中的引用无论是通过引用计数算法判断对象的引用数量，还是通过可达性分析算法判断对象的引用链是否可达，判定对象是否存活都与“引用”有关。在Java语言中，将引用又分为强引用、软引用、弱引用、虚引用4种，这四种引用强度依次逐渐减弱。 强引用  在程序代码中普遍存在的，类似 Object obj = new Object() 这类引用，只要强引用还存在，垃圾收集器永远不会回收掉被引用的对象。 软引用  用来描述一些还有用但并非必须的对象。对于软引用关联着的对象，在系统将要发生内存溢出异常之前，将会把这些对象列进回收范围之中进行第二次回收。如果这次回收后还没有足够的内存，才会抛出内存溢出异常。 弱引用  也是用来描述非必需对象的，但是它的强度比软引用更弱一些，被弱引用关联的对象只能生存到下一次垃圾收集发生之前。当垃圾收集器工作时，无论当前内存是否足够，都会回收掉只被弱引用关联的对象。 虚引用  也叫幽灵引用或幻影引用（名字真会取，很魔幻的样子），是最弱的一种引用关系。一个对象是否有虚引用的存在，完全不会对其生存时间构成影响，也无法通过虚引用来取得一个对象实例。它的作用是能在这个对象被收集器回收时收到一个系统通知。 无论引用计数算法还是可达性分析算法都是基于强引用而言的。对象死亡（被回收）前的最后一次挣扎即使在可达性分析算法中不可达的对象，也并非是“非死不可”，这时候它们暂时处于“缓刑”阶段，要真正宣告一个对象死亡，至少要经历两次标记过程。第一次标记：如果对象在进行可达性分析后发现没有与GC Roots相连接的引用链，那它将会被第一次标记；第二次标记：第一次标记后接着会进行一次筛选，筛选的条件是此对象是否有必要执行finalize()方法。在finalize()方法中没有重新与引用链建立关联关系的，将被进行第二次标记。第二次标记成功的对象将真的会被回收，如果对象在finalize()方法中重新与引用链建立了关联关系，那么将会逃离本次回收，继续存活。猿们还跟的上吧，嘿嘿。方法区如何判断是否需要回收猿们，方法区存储内容是否需要回收的判断可就不一样咯。方法区主要回收的内容有：废弃常量和无用的类。对于废弃常量也可通过引用的可达性来判断，但是对于无用的类则需要同时满足下面3个条件：该类所有的实例都已经被回收，也就是Java堆中不存在该类的任何实例；加载该类的ClassLoader已经被回收；该类对应的java.lang.Class对象没有在任何地方被引用，无法在任何地方通过反射访问该类的方法。常用的垃圾收集算法标记-清除算法标记-清除算法采用从根集合（GC Roots）进行扫描，对存活的对象进行标记，标记完毕后，再扫描整个空间中未被标记的对象，进行回收，如下图所示。标记-清除算法不需要进行对象的移动，只需对不存活的对象进行处理，在存活对象比较多的情况下极为高效，但由于标记-清除算法直接回收不存活的对象，因此会造成内存碎片。复制算法复制算法的提出是为了克服句柄的开销和解决内存碎片的问题。它开始时把堆分成 一个对象 面和多个空闲面， 程序从对象面为对象分配空间，当对象满了，基于copying算法的垃圾 收集就从根集合（GC Roots）中扫描活动对象，并将每个 活动对象复制到空闲面(使得活动对象所占的内存之间没有空闲洞)，这样空闲面变成了对象面，原来的对象面变成了空闲面，程序会在新的对象面中分配内存。标记-整理算法标记-整理算法采用标记-清除算法一样的方式进行对象的标记，但在清除时不同，在回收不存活的对象占用的空间后，会将所有的存活对象往左端空闲空间移动，并更新对应的指针。标记-整理算法是在标记-清除算法的基础上，又进行了对象的移动，因此成本更高，但是却解决了内存碎片的问题。具体流程见下图：分代收集算法分代收集算法是目前大部分JVM的垃圾收集器采用的算法。它的核心思想是根据对象存活的生命周期将内存划分为若干个不同的区域。一般情况下将堆区划分为老年代（Tenured Generation）和新生代（Young Generation），在堆区之外还有一个代就是永久代（Permanet Generation）。老年代的特点是每次垃圾收集时只有少量对象需要被回收，而新生代的特点是每次垃圾回收时都有大量的对象需要被回收，那么就可以根据不同代的特点采取最适合的收集算法。年轻代（Young Generation）的回收算法 所有新生成的对象首先都是放在年轻代的。年轻代的目标就是尽可能快速的收集掉那些生命周期短的对象。 新生代内存按照8:1:1的比例分为一个eden区和两个survivor(survivor0,survivor1)区。一个Eden区，两个 Survivor区(一般而言)。大部分对象在Eden区中生成。回收时先将eden区存活对象复制到一个survivor0区，然后清空eden区，当这个survivor0区也存放满了时，则将eden区和survivor0区存活对象复制到另一个survivor1区，然后清空eden和这个survivor0区，此时survivor0区是空的，然后将survivor0区和survivor1区交换，即保持survivor1区为空， 如此往复。 当survivor1区不足以存放 eden和survivor0的存活对象时，就将存活对象直接存放到老年代。若是老年代也满了就会触发一次Full GC，也就是新生代、老年代都进行回收。 新生代发生的GC也叫做Minor GC，MinorGC发生频率比较高(不一定等Eden区满了才触发)。 年老代（Old Generation）的回收算法 在年轻代中经历了N次垃圾回收后仍然存活的对象，就会被放到年老代中。因此，可以认为年老代中存放的都是一些生命周期较长的对象。 内存比新生代也大很多(大概比例是1:2)，当老年代内存满时触发Major GC即Full GC，Full GC发生频率比较低，老年代对象存活时间比较长，存活率标记高。 持久代（Permanent Generation）的回收算法用于存放静态文件，如Java类、方法等。持久代对垃圾回收没有显著影响，但是有些应用可能动态生成或者调用一些class，例如Hibernate 等，在这种时候需要设置一个比较大的持久代空间来存放这些运行过程中新增的类。持久代也称方法区，具体的回收可参见上文方法区如何判断是否需要回收。常见的垃圾收集器常见的垃圾收集器 下面一张图是HotSpot虚拟机包含的所有收集器 Serial收集器（复制算法)新生代单线程收集器，标记和清理都是单线程，优点是简单高效。是client级别默认的GC方式，可以通过-XX:+UseSerialGC来强制指定。 Serial Old收集器(标记-整理算法)老年代单线程收集器，Serial收集器的老年代版本。 ParNew收集器(停止-复制算法)　新生代收集器，可以认为是Serial收集器的多线程版本,在多核CPU环境下有着比Serial更好的表现。 Parallel Scavenge收集器(停止-复制算法)并行收集器，追求高吞吐量，高效利用CPU。吞吐量一般为99%， 吞吐量= 用户线程时间/(用户线程时间+GC线程时间)。适合后台应用等对交互相应要求不高的场景。是server级别默认采用的GC方式，可用-XX:+UseParallelGC来强制指定，用-XX:ParallelGCThreads=4来指定线程数。 Parallel Old收集器(停止-复制算法)Parallel Scavenge收集器的老年代版本，并行收集器，吞吐量优先。 CMS(Concurrent Mark Sweep)收集器（标记-清理算法）高并发、低停顿，追求最短GC回收停顿时间，cpu占用比较高，响应时间快，停顿时间短，多核cpu 追求高响应时间的选择。垃圾回收器详情： 7种 JVM 垃圾回收器概览GC是什么时候触发的由于对象进行了分代处理，因此垃圾回收区域、时间也不一样。GC有两种类型：Scavenge GC和Full GC。Scavenge GC一般情况下，当新对象生成，并且在Eden申请空间失败时，就会触发Scavenge GC，对Eden区域进行GC，清除非存活对象，并且把尚且存活的对象移动到Survivor区。然后整理Survivor的两个区。这种方式的GC是对年轻代的Eden区进行，不会影响到年老代。因为大部分对象都是从Eden区开始的，同时Eden区不会分配的很大，所以Eden区的GC会频繁进行。因而，一般在这里需要使用速度快、效率高的算法，使Eden去能尽快空闲出来。Full GC对整个堆进行整理，包括Young、Tenured和Perm。Full GC因为需要对整个堆进行回收，所以比Scavenge GC要慢，因此应该尽可能减少Full GC的次数。在对JVM调优的过程中，很大一部分工作就是对于Full GC的调节。有如下原因可能导致Full GC： 年老代（Tenured）被写满； 持久代（Perm）被写满； System.gc()被显示调用； 上一次GC之后Heap的各域分配策略动态变化；" }, { "title": "Spring Bean 循环依赖为什么需要三级缓存", "url": "/posts/why-spring-bean-cyclic-dependencies-need-three-levels-of-caching/", "categories": "Software Development", "tags": "Java, Spring", "date": "2022-01-09 15:01:00 +0800", "snippet": " 这里指的是单例的、非构造依赖的循环引用。很多人都知道Spring用了三层缓存来解决循环依赖，但是不知道其原因，为什么是三级缓存？二级缓存不行吗？一级缓存不可以 ？三级缓存Spring 解决循环依赖的核心就是提前暴露对象，而提前暴露的对象就是放置于第二级缓存中。缓存的底层都是Map，至于它们属于第几层是由Spring获取数据顺序以及其作用来表现的。三级缓存的说明： 名称 作用 singletonObjects 一级缓存，存放完整的 Bean。 earlySingletonObjects 二级缓存，存放提前暴露的Bean，Bean 是不完整的，未完成属性注入和执行 初始化（init） 方法。 singletonFactories 三级缓存，存放的是 Bean 工厂，主要是生产 Bean，存放到二级缓存中。 在DefaultSingletonBeanRegistry类中： /** Cache of singleton objects: bean name to bean instance. */ private final Map&amp;lt;String, Object&amp;gt; singletonObjects = new ConcurrentHashMap&amp;lt;&amp;gt;(256); /** Cache of singleton factories: bean name to ObjectFactory. */ private final Map&amp;lt;String, ObjectFactory&amp;lt;?&amp;gt;&amp;gt; singletonFactories = new HashMap&amp;lt;&amp;gt;(16); /** Cache of early singleton objects: bean name to bean instance. */ private final Map&amp;lt;String, Object&amp;gt; earlySingletonObjects = new ConcurrentHashMap&amp;lt;&amp;gt;(16);为什么使用三级缓存第一级缓存 singletonObjects先说一级缓存singletonObjects。实际上，一级依赖已经可以解决循环依赖的问题，假设两个beanA和beanB相互依赖，beanA被实例化后，放入一级缓存，即使没有进行初始化，但是beanA的引用已经创建（栈到堆的引用已经确定），其他依赖beanB已经可以持有beanA的引用，但是这个bean在没有初始化完成前，其内存（堆）里的字段、方法等还不能正常使用，but，这并不影响对象之间引用持有；这个时候beanA依赖的beanB实例化，beanB可以顺利拿到beanA的引用，完成beanB的实例化与初始化，并放入一级缓存，在beanB完成创建后，beanA通过缓存顺利拿到beanB的引用，至此，循环依赖只需一层缓存就能完成。一级缓存的关键点在与：bean实例化与初始化的分离。从JVM的角度，实例化后，对象已经存在，其内的属性都是初始默认值，只有在初始化后才会赋值，以及持有其他对象的引用。通过这个特性，在实例化后，我们就可以将对象的引用放入缓存交给需要引用依赖的其他对象，这个过程就是提前暴露。第三级缓存 singletonFactories上述我们通过一级缓存已经拿到的对象有什么问题？根本问题就是，我们拿到的是bean的原始引用，如果我们需要的是bean的代理对象怎么办？Spring里充斥了大量的动态代理模式的架构，典型的AOP就是动态代理模式实现的，再比如我们经常使用的配置类注解@Configuration在缺省情况下（full mode），其内的所有@Bean都是处于动态代理模式，除非手动指定proxyBeanMethods = false将配置转成简略模式（lite mode）。所以，Spring在bean实例化后，将原始bean放入第三级缓存singletonFactories中，第三级缓存里实际存入的是ObjectFactory接口签名的回调实现。// 函数签名addSingletonFactory(String beanName, ObjectFactory&amp;lt;?&amp;gt; singletonFactory) // 具体实现由回调决定 addSingletonFactory(beanName, () -&amp;gt; getEarlyBeanReference(beanName, mbd, bean));那么如果有动态代理的需求，里面可以埋点进行处理，将原始bean包装后返回。protected Object getEarlyBeanReference(String beanName, RootBeanDefinition mbd, Object bean) { Object exposedObject = bean; if (!mbd.isSynthetic() &amp;amp;&amp;amp; hasInstantiationAwareBeanPostProcessors()) { for (BeanPostProcessor bp : getBeanPostProcessors()) { if (bp instanceof SmartInstantiationAwareBeanPostProcessor) { SmartInstantiationAwareBeanPostProcessor ibp = (SmartInstantiationAwareBeanPostProcessor) bp; exposedObject = ibp.getEarlyBeanReference(exposedObject, beanName); } } } return exposedObject;}通过第三级缓存我们可以拿到可能经过包装的对象，解决对象代理封装的问题。说说第二级缓存 earlySingletonObjects为什么需要earlySingletonObjects这个二级缓存？并且，如果只有一个缓存的情况下，为什么不直接使用singletonFactories这个缓存，即可实现代理又可以缓存数据。从软件设计角度考虑，三个缓存代表三种不同的职责，根据单一职责原理，从设计角度就需分离三种职责的缓存，所以形成三级缓存的状态。再次说说三级缓存的划分及其作用 一级缓存singletonObjects是完整的bean，它可以被外界任意使用，并且不会有歧义。 二级缓存earlySingletonObjects是不完整的bean，没有完成初始化，它与singletonObjects的分离主要是职责的分离以及边界划分，可以试想一个Map缓存里既有完整可使用的bean，也有不完整的，只能持有引用的bean，在复杂度很高的架构中，很容易出现歧义，并带来一些不可预知的错误。 三级缓存singletonFactories，其职责就是包装一个bean，有回调逻辑，所以它的作用非常清晰，并且只能处于第三层。在实际使用中，要获取一个bean，先从一级缓存一直查找到三级缓存，缓存bean的时候是从三级到一级的顺序保存，并且缓存bean的过程中，三个缓存都是互斥的，只会保持bean在一个缓存中，而且，最终都会在一级缓存中。" }, { "title": "JVM类加载机制", "url": "/posts/jvm-class-loading-mechanism/", "categories": "Software Development", "tags": "Java, JVM", "date": "2022-01-05 15:12:00 +0800", "snippet": "类的加载机制Java虚拟机把描述类的数据从Class文件加载到内存，并对数据进行校验、转换解析和初始化，最终形成可以被虚拟机直接使用的Java类型，这个过程被称作虚拟机的类加载机制。类的生命周期类从被加载到虚拟机内存中开始，到卸载出内存为止，它的整个生命周期包括：加载，验证，准备，解析，初始化,使用,卸载这7个阶段.其中其中验证、准备、解析3个部分统称为连接.加载、验证、准备、初始化和卸载这五个阶段的顺序是确定的，类型的加载过程必须按照这种顺序按部就班地开始，而解析阶段则不一定：它在某些情况下可以在初始化阶段之后再开始，这是为了支持Java语言的运行时绑定特性（也称为动态绑定或晚期绑定） 注意，这里的几个阶段是按顺序开始，而不是按顺序进行或完成，因为这些阶段通常都是互相交叉地混合进行的，通常在一个阶段执行的过程中调用或激活另一个阶段。加载：查找并加载类的二进制数据在加载阶段，虚拟机需要完成以下3件事情： 通过一个类的全限定名来获取定义此类的二进制字节流。 将这个字节流所代表的静态存储结构转化为方法区的运行时数据结构。 在内存中生成一个代表这个类的java.lang.Class对象，作为方法区这个类的各种数据的访问入口。验证：确保被加载的类的正确性验证是连接阶段的第一步，这一阶段的目的是为了确保Class文件的字节流中包含的信息符合当前虚拟机的要求，并且不会危害虚拟机自身的安全。验证阶段大致会完成4个阶段的检验动作: 文件格式验证: 验证字节流是否符合Class文件格式的规范；例如: 是否以0xCAFEBABE开头、主次版本号是否在当前虚拟机的处理范围之内、常量池中的常量是否有不被支持的类型。 元数据验证：对字节码描述的信息进行语义分析(注意: 对比javac编译阶段的语义分析)，以保证其描述的信息符合Java语言规范的要求；例如: 这个类是否有父类，除了java.lang.Object之外。 字节码验证：通过数据流和控制流分析，确定程序语义是合法的、符合逻辑的。 符号引用验证：确保解析动作能正确执行。验证阶段是非常重要的，但不是必须的，它对程序运行期没有影响，如果所引用的类经过反复验证，那么可以考虑采用-Xverifynone参数来关闭大部分的类验证措施，以缩短虚拟机类加载的时间。准备：为类的静态变量分配内存，并将其初始化为默认值 准备阶段是正式为类变量分配内存并设置类变量初始值的阶段，这些变量所使用的内存都将在方法区中进行分配。该阶段的注意事项： 这时候进行内存分配的仅包括类变量（被static修饰的变量），而不包括实例变量，实例变量将会在对象实例化时随着对象一起分配在Java堆中。 这里所设置的初始值通常情况下是数据类型默认的零值(如0、0L、null、false等)，而不是被在Java代码中被显式地赋予的值。比如：假设一个类变量的定义为: public static int value = 3; 那么变量value在准备阶段过后的初始值为0，而不是3，因为这时候尚未开始执行任何Java方法，而把value赋值为3的put static指令是在程序编译后，存放于类构造器()方法之中的，所以把value赋值为3的动作将在初始化阶段才会执行。 对基本数据类型来说，对于类变量(static)和全局变量，如果不显式地对其赋值而直接使用，则系统会为其赋予默认的零值，而对于局部变量来说，在使用前必须显式地为其赋值，否则编译时不通过。 对于同时被static和final修饰的常量，必须在声明的时候就为其显式地赋值，否则编译时不通过；而只被final修饰的常量则既可以在声明时显式地为其赋值，也可以在类初始化时显式地为其赋值，总之，在使用前必须为其显式地赋值，系统不会为其赋予默认零值。 对于引用数据类型reference来说，如数组引用、对象引用等，如果没有对其进行显式地赋值而直接使用，系统都会为其赋予默认的零值，即null。 如果在数组初始化时没有对数组中的各元素赋值，那么其中的元素将根据对应的数据类型而被赋予默认的零值。 如果类字段的字段属性表中存在ConstantValue属性，即同时被final和static修饰，那么在准备阶段变量value就会被初始化为ConstValue属性所指定的值。假设上面的类变量value被定义为: public static final int value = 3;编译时Javac将会为value生成ConstantValue属性，在准备阶段虚拟机就会根据ConstantValue的设置将value赋值为3。我们可以理解为static final常量在编译期就将其结果放入了调用它的类的常量池中解析：把类中的符号引用转换为直接引用解析阶段是虚拟机将常量池内的符号引用替换为直接引用的过程，解析动作主要针对类或接口、字段、类方法、接口方法、方法类型、方法句柄和调用点限定符7类符号引用进行。符号引用就是一组符号来描述目标，可以是任何字面量。直接引用就是直接指向目标的指针、相对偏移量或一个间接定位到目标的句柄。初始化：对类的静态变量，静态代码块执行初始化操作初始化，为类的静态变量赋予正确的初始值，JVM负责对类进行初始化，主要对类变量进行初始化。在Java中对类变量进行初始值设定有两种方式: 声明类变量是指定初始值 使用静态代码块为类变量指定初始值类初始化的步骤 假如这个类还没有被加载和连接，则程序先加载并连接该类 假如该类的直接父类还没有被初始化，则先初始化其直接父类 假如类中有初始化语句，则系统依次执行这些初始化语句触发类初始化的时机只有当对类的主动使用的时候才会导致类的初始化，类的主动使用包括以下六种: 使用new关键字实例化对象的时候。 读取或设置一个类型的静态字段（被final修饰、已在编译期把结果放入常量池的静态字段除外）的时候。 调用一个类型的静态方法的时候。 使用java.lang.reflect包的方法对类型进行反射调用的时候，如果类型没有进行过初始化，则需要先触发其初始化。 当初始化类的时候，如果发现其父类还没有进行过初始化，则需要先触发其父类的初始化。 当虚拟机启动时，用户需要指定一个要执行的主类（包含main()方法的那个类），虚拟机会先初始以下几种情况不会执行类初始化 通过子类引用父类的静态字段，只会触发父类的初始化，而不会触发子类的初始化。 定义对象数组，不会触发该类的初始化。 常量在编译期间会存入调用类的常量池中，本质上并没有直接引用定义常量的类，不会触 发定义常量所在的类。 通过类名获取 Class 对象，不会触发类的初始化。 通过 Class.forName 加载指定类时，如果指定参数 initialize 为 false 时，也不会触发类初 始化，其实这个参数是告诉虚拟机，是否要对类进行初始化。 通过 ClassLoader 默认的 loadClass 方法，也不会触发初始化动作。使用类访问方法区内的数据结构的接口， 对象是Heap区的数据。卸载Java虚拟机将结束生命周期的几种情况 执行了System.exit()方法 程序正常执行结束 程序在执行过程中遇到了异常或错误而异常终止 由于操作系统出现错误而导致Java虚拟机进程终止类加载器什么是类加载器虚拟机设计团队把类加载阶段中的“通过一个类的全限定名来获取描述此类的二进制字节流”这个动作放到Java虚拟机外部去实现，以便让应用程序自己决定如何去获取所需要的类。 实现这个动作的代码模块称为“类加载器”。类加载器的层次双亲委派模型要求除了顶层的启动类加载器外，其余的类加载器都应有自己的父类加载器。不过这里类加载器之间的父子关系一般不是以继承（Inheritance）的关系来实现的，而是通常使用组合（Composition）关系来复用父加载器的代码。从Java虚拟机的角度来讲，只存在两种不同的类加载器：一种是启动类加载器（Bootstrap ClassLoader），这个类加载器使用C++语言实现，是虚拟机自身的一部分；另一种就是所有其他的类加载器，这些类加载器都由Java语言实现，独立于虚拟机外部，并且全都继承自抽象类java.lang.ClassLoader。从Java开发人员的角度来看，类加载器还可以划分得更细致一些，绝大部分Java程序都会使用到以下3种系统提供的类加载器:启动类加载器(Bootstrap ClassLoader)这个类将器负责将存放在＜JAVA_HOME＞\\lib目录中的，或者被-Xbootclasspath参数所指定的路径中的，并且是虚拟机识别的（按照文件名识别，如rt.jar、tools.jar，名字不符合的类库即使放在lib目录中也不会被加载）类库加载到虚拟机内存中。扩展类加载器(Extension ClassLoader)这个加载器由sun.misc.Launcher$ExtClassLoader实现，它负责加载＜JAVA_HOME＞\\lib\\ext目录中的，或者被java.ext.dirs系统变量所指定的路径中的所有类库，开发者可以直接使用扩展类加载器。应用程序类加载器(Application ClassLoader)这个类加载器由sun.misc.Launcher$AppClassLoader来实现。由于应用程序类加载器是ClassLoader类中的getSystem-ClassLoader()方法的返回值，所以有些场合中也称它为“系统类加载器”。它负责加载用户类路径（ClassPath）上所有的类库，开发者同样可以直接在代码中使用这个类加载器。如果应用程序中没有自定义过自己的类加载器，一般情况下这个就是程序中默认的类加载器。我们的应用程序都是由这3种类加载器互相配合进行加载的，如果有必要，还可以加入自己定义的类加载器。类加载的三种方式 命令行启动应用时候由JVM初始化加载 通过Class.forName()方法动态加载 通过ClassLoader.loadClass()方法动态加载代码示例：public class loaderTest { public static void main(String[] args) throws ClassNotFoundException { ClassLoader loader = HelloWorld.class.getClassLoader(); System.out.println(loader); //使用ClassLoader.loadClass()来加载类，不会执行初始化块 loader.loadClass(&quot;Test2&quot;); //使用Class.forName()来加载类，默认会执行初始化块 // Class.forName(&quot;Test2&quot;); //使用Class.forName()来加载类，并指定ClassLoader，初始化时不执行静态块 // Class.forName(&quot;Test2&quot;, false, loader); } }public class Test2 { static { System.out.println(&quot;静态初始化块执行了！&quot;); } }Class.forName()和ClassLoader.loadClass()区别 Class.forName(): 将类的.class文件加载到jvm中之外，还会对类进行解释，执行类中的static块； ClassLoader.loadClass(): 只干一件事情，就是将.class文件加载到jvm中，不会执行static中的内容,只有在newInstance才会去执行static块。 Class.forName(name, initialize, loader):带参函数也可控制是否加载static块。并且只有调用了newInstance()方法采用调用构造函数，创建类的对象 。JVM类加载机制全盘负责当一个类加载器负责加载某个Class时，该Class所依赖的和引用的其他Class也将由该类加载器负责载入，除非显示使用另外一个类加载器来载入。父类委托先让父类加载器试图加载该类，只有在父类加载器无法加载该类时才尝试从自己的类路径中加载该类。缓存机制缓存机制将会保证所有加载过的Class都会被缓存，当程序中需要使用某个Class时，类加载器先从缓存区寻找该Class，只有缓存区不存在，系统才会读取该类对应的二进制数据，并将其转换成Class对象，存入缓存区。这就是为什么修改了Class后，必须重启JVM，程序的修改才会生效。双亲委派机制双亲委派模型的工作过程是：如果一个类加载器收到了类加载的请求，它首先不会自己去尝试加载这个类，而是把这个请求委派给父类加载器去完成，每一个层次的类加载器都是如此，因此所有的加载请求最终都应该传送到最顶层的启动类加载器中，只有当父加载器反馈自己无法完成这个加载请求（它的搜索范围中没有找到所需的类）时，子加载器才会尝试自己去完成加载。举例如下： 当AppClassLoader加载一个class时，它首先不会自己去尝试加载这个类，而是把类加载请求委派给父类加载器ExtClassLoader去完成。 当ExtClassLoader加载一个class时，它首先也不会自己去尝试加载这个类，而是把类加载请求委派给BootStrapClassLoader去完成。 如果BootStrapClassLoader加载失败(例如在$JAVA_HOME/jre/lib里未查找到该class)，会使用ExtClassLoader来尝试加载； 若ExtClassLoader也加载失败，则会使用AppClassLoader来加载，如果AppClassLoader也加载失败，则会报出异常ClassNotFoundException。类的双亲委派机制上图展示的类加载器之间的这种层次关系，称为类加载器的双亲委派模型（Parents Delegation Model）。 双亲委派模型要求除了顶层的启动类加载器外，其余的类加载器都应当有自己的父类加载器。 这里类加载器之间的父子关系一般不会以继承（Inheritance）的关系来实现，而是都使用组合（Composition）关系来复用父加载器的代码。类加载器的双亲委派模型在JDK1.2期间被引入并被广泛应用于之后几乎所有的Java程序中，但它并不是一个强制性的约束模型，而是Java设计者推荐给开发者的一种类加载器实现方式.双亲委派模型的工作过程是：如果一个类加载器收到了类加载的请求，它首先不会自己去尝试加载这个类，而是把这个请求委派给父类加载器去完成，每一个层次的类加载器都是如此，因此所有的加载请求最终都应该传送到最顶层的启动类加载器中，只有当父加载器反馈自己无法完成这个加载请求（它的搜索范围中没有找到所需的类）时，子加载器才会尝试自己去完成加载。使用双亲委派模型来组织类加载器之间的关系，有一个显而易见的好处就是Java类随着它的类加载器一起具备了一种带有优先级的层次关系。例如类java.lang.Object，它存放在rt.jar之中，无论哪一个类加载器要加载这个类，最终都是委派给处于模型最顶端的启动类加载器进行加载，因此Object类在程序的各种类加载器环境中都是同一个类。相反，如果没有使用双亲委派模型，由各个类加载器自行去加载的话，如果用户自己编写了一个称为java.lang.Object的类，并放在程序的ClassPath中，那系统中将会出现多个不同的Object类，Java类型体系中最基础的行为也就无法保证，应用程序也将会变得一片混乱。双亲委派优势 系统类防止内存中出现多份同样的字节码 保证Java程序安全稳定运行双亲委派代码实现public Class&amp;lt;?&amp;gt; loadClass(String name)throws ClassNotFoundException { return loadClass(name, false);}protected synchronized Class&amp;lt;?&amp;gt; loadClass(String name, boolean resolve)throws ClassNotFoundException { // 首先判断该类型是否已经被加载 Class c = findLoadedClass(name); if (c == null) { //如果没有被加载，就委托给父类加载或者委派给启动类加载器加载 try { if (parent != null) { //如果存在父类加载器，就委派给父类加载器加载 c = parent.loadClass(name, false); } else { //如果不存在父类加载器，就检查是否是由启动类加载器加载的类，通过调用本地方法native Class findBootstrapClass(String name) c = findBootstrapClass0(name); } } catch (ClassNotFoundException e) { // 如果父类加载器和启动类加载器都不能完成加载任务，才调用自身的加载功能 c = findClass(name); } } if (resolve) { resolveClass(c); } return c;}这段代码的逻辑清晰易懂：先检查请求加载的类型是否已经被加载过，若没有则调用父加载器的loadClass()方法，若父加载器为空则默认使用启动类加载器作为父加载器。假如父类加载器加载失败，抛出ClassNotFoundException异常的话，才调用自己的findClass()方法尝试进行加载。自定义类加载器通常情况下，我们都是直接使用系统类加载器。但是，有的时候，我们也需要自定义类加载器。比如应用是通过网络来传输 Java 类的字节码，为保证安全性，这些字节码经过了加密处理，这时系统类加载器就无法对其进行加载，这样则需要自定义类加载器来实现。自定义类加载器一般都是继承自 ClassLoader 类，从上面对 loadClass 方法来分析来看，我们只需要重写 findClass 方法即可。下面我们通过一个示例来演示自定义类加载器的流程:自定义类加载器的核心在于对字节码文件的获取，如果是加密的字节码则需要在该类中对文件进行解密。由于这里只是演示，我并未对class文件进行加密，因此没有解密的过程。public class MyClassLoader extends ClassLoader { private String root; protected Class&amp;lt;?&amp;gt; findClass(String name) throws ClassNotFoundException { byte[] classData = loadClassData(name); if (classData == null) { throw new ClassNotFoundException(); } else { return defineClass(name, classData, 0, classData.length); } } private byte[] loadClassData(String className) { String fileName = root + File.separatorChar + className.replace(&#39;.&#39;, File.separatorChar) + &quot;.class&quot;; try { InputStream ins = new FileInputStream(fileName); ByteArrayOutputStream baos = new ByteArrayOutputStream(); int bufferSize = 1024; byte[] buffer = new byte[bufferSize]; int length = 0; while ((length = ins.read(buffer)) != -1) { baos.write(buffer, 0, length); } return baos.toByteArray(); } catch (IOException e) { e.printStackTrace(); } return null; } public String getRoot() { return root; } public void setRoot(String root) { this.root = root; } public static void main(String[] args) { MyClassLoader classLoader = new MyClassLoader(); classLoader.setRoot(&quot;D:\\\\temp&quot;); Class&amp;lt;?&amp;gt; testClass = null; try { testClass = classLoader.loadClass(&quot;io.optimus-xs.jvm.classloader.Test2&quot;); Object object = testClass.newInstance(); System.out.println(object.getClass().getClassLoader()); } catch (ClassNotFoundException e) { e.printStackTrace(); } catch (InstantiationException e) { e.printStackTrace(); } catch (IllegalAccessException e) { e.printStackTrace(); } }}这里有几点需要注意 : 这里传递的文件名需要是类的全限定性名称，即io.optimus-xs.jvm.classloader.Test2格式的，因为 defineClass 方法是按这种格式进行处理的。 最好不要重写loadClass方法，因为这样容易破坏双亲委托模式。 这类Test 类本身可以被 AppClassLoader 类加载，因此我们不能把io/optimus-xs/jvm/classloader/Test2.class 放在类路径下。否则，由于双亲委托机制的存在，会直接导致该类由 AppClassLoader 加载，而不会通过我们自定义类加载器来加载。" }, { "title": "Spring Bean 的生命周期", "url": "/posts/spring-bean-s-lifecycle/", "categories": "Software Development", "tags": "Java, Spring", "date": "2022-01-03 13:34:00 +0800", "snippet": "生命周期的概要流程Spring Bean 的整个生命周期Google Spring Bean 的生命周期，大多以下图给出的流程作为答案但是当我第一次看到这个图时，人麻了，“Aware，BeanPostProcessor……这些都是什么啊？而且这么多步骤，太多了，该怎么记啊？”。其实要记忆该过程，还是需要我们先去理解，本文将从以下两方面去帮助理解 Bean 的生命周期 生命周期的概要流程：对 Bean 的生命周期进行概括，并且结合代码来理解； 扩展点的作用：详细介绍 Bean 生命周期中所涉及到的扩展点的作用。只有四个！是的，Spring Bean的生命周期只有这四个阶段。把这四个阶段和每个阶段对应的扩展点糅合在一起虽然没有问题，但是这样非常凌乱，难以记忆。要彻底搞清楚Spring的生命周期，首先要把这四个阶段牢牢记住。实例化和属性赋值对应构造方法和setter方法的注入，初始化和销毁是用户能自定义扩展的两个阶段 实例化 Instantiation 属性赋值 Populate 初始化 Initialization 销毁 Destruction 实例化：第 1 步，实例化一个 bean 对象； 属性赋值：第 2 步，为 bean 设置相关属性和依赖； 初始化：第 3~7 步，步骤较多，其中第 5、6 步为初始化操作，第 3、4 步为在初始化前执行，第 7 步在初始化后执行，该阶段结束，才能被用户使用； 销毁：第 8~10步，第8步不是真正意义上的销毁（还没使用呢），而是先在使用前注册了销毁的相关调用接口，为了后面第9、10步真正销毁 bean 时再执行相应的方法。实例化 -&amp;gt; 属性赋值 -&amp;gt; 初始化 -&amp;gt; 销毁主要逻辑都在doCreate()方法中，逻辑很清晰，就是顺序调用以下三个方法，这三个方法与三个生命周期阶段一一对应，非常重要，在后续扩展接口分析中也会涉及。 createBeanInstance() -&amp;gt; 实例化 populateBean() -&amp;gt; 属性赋值 initializeBean() -&amp;gt; 初始化下面我们结合代码来直观的看下，在 doCreateBean() 方法中能看到依次执行了这 4 个阶段：// AbstractAutowireCapableBeanFactory.javaprotected Object doCreateBean(final String beanName, final RootBeanDefinition mbd, final @Nullable Object[] args) throws BeanCreationException { // 1. 实例化 BeanWrapper instanceWrapper = null; if (instanceWrapper == null) { instanceWrapper = createBeanInstance(beanName, mbd, args); } Object exposedObject = bean; try { // 2. 属性赋值 populateBean(beanName, mbd, instanceWrapper); // 3. 初始化 exposedObject = initializeBean(beanName, exposedObject, mbd); } // 4. 销毁-注册回调接口 try { registerDisposableBeanIfNecessary(beanName, bean, mbd); } return exposedObject;}由于初始化包含了第 3~7步，较复杂，所以我们进到 initializeBean() 方法里具体看下其过程（注释的序号对应图中序号）：// AbstractAutowireCapableBeanFactory.javaprotected Object initializeBean(final String beanName, final Object bean, @Nullable RootBeanDefinition mbd) { // 3. 检查 Aware 相关接口并设置相关依赖 if (System.getSecurityManager() != null) { AccessController.doPrivileged((PrivilegedAction&amp;lt;Object&amp;gt;) () -&amp;gt; { invokeAwareMethods(beanName, bean); return null; }, getAccessControlContext()); } else { invokeAwareMethods(beanName, bean); } // 4. BeanPostProcessor 前置处理 Object wrappedBean = bean; if (mbd == null || !mbd.isSynthetic()) { wrappedBean = applyBeanPostProcessorsBeforeInitialization(wrappedBean, beanName); } // 5. 若实现 InitializingBean 接口，调用 afterPropertiesSet() 方法 // 6. 若配置自定义的 init-method方法，则执行 try { invokeInitMethods(beanName, wrappedBean, mbd); } catch (Throwable ex) { throw new BeanCreationException( (mbd != null ? mbd.getResourceDescription() : null), beanName, &quot;Invocation of init method failed&quot;, ex); } // 7. BeanPostProceesor 后置处理 if (mbd == null || !mbd.isSynthetic()) { wrappedBean = applyBeanPostProcessorsAfterInitialization(wrappedBean, beanName); } return wrappedBean;}在 invokInitMethods() 方法中会检查 InitializingBean 接口和 init-method 方法，销毁的过程也与其类似：// DisposableBeanAdapter.javapublic void destroy() { // 9. 若实现 DisposableBean 接口，则执行 destory()方法 if (this.invokeDisposableBean) { try { if (System.getSecurityManager() != null) { AccessController.doPrivileged((PrivilegedExceptionAction&amp;lt;Object&amp;gt;) () -&amp;gt; { ((DisposableBean) this.bean).destroy(); return null; }, this.acc); } else { ((DisposableBean) this.bean).destroy(); } } } // 10. 若配置自定义的 detory-method 方法，则执行 if (this.destroyMethod != null) { invokeCustomDestroyMethod(this.destroyMethod); } else if (this.destroyMethodName != null) { Method methodToInvoke = determineDestroyMethod(this.destroyMethodName); if (methodToInvoke != null) { invokeCustomDestroyMethod(ClassUtils.getInterfaceMethodIfPossible(methodToInvoke)); } }}从 Spring 的源码我们可以直观的看到其执行过程，而我们记忆其过程便可以从这 4 个阶段出发，实例化、属性赋值、初始化、销毁。其中细节较多的便是初始化，涉及了 Aware、BeanPostProcessor、InitializingBean、init-method 的概念。这些都是 Spring 提供的扩展点，其具体作用将在下一节讲述。常见扩展点极其作用第一大类：影响多个Bean的接口实现了这些接口的Bean会切入到多个Bean的生命周期中。正因为如此，这些接口的功能非常强大，Spring内部扩展也经常使用这些接口，例如自动注入以及AOP的实现都和他们有关。 BeanPostProcessor InstantiationAwareBeanPostProcessor这两兄弟可能是Spring扩展中最重要的两个接口！InstantiationAwareBeanPostProcessor作用于实例化阶段的前后，BeanPostProcessor作用于初始化阶段的前后。正好和第一、第三个生命周期阶段对应。通过图能更好理解：InstantiationAwareBeanPostProcessor实际上继承了BeanPostProcessor接口，严格意义上来看他们不是两兄弟，而是两父子。但是从生命周期角度我们重点关注其特有的对实例化阶段的影响，图中省略了从BeanPostProcessor继承的方法。InstantiationAwareBeanPostProcessor extends BeanPostProcessorInstantiationAwareBeanPostProcessor分析：postProcessBeforeInstantiation调用点，忽略无关代码：@Override protected Object createBean(String beanName, RootBeanDefinition mbd, @Nullable Object[] args) throws BeanCreationException { try { // Give BeanPostProcessors a chance to return a proxy instead of the target bean instance. // postProcessBeforeInstantiation方法调用点，这里就不跟进了， // 有兴趣的同学可以自己看下，就是for循环调用所有的InstantiationAwareBeanPostProcessor Object bean = resolveBeforeInstantiation(beanName, mbdToUse); if (bean != null) { return bean; } } try { // 上文提到的doCreateBean方法，可以看到 // postProcessBeforeInstantiation方法在创建Bean之前调用 Object beanInstance = doCreateBean(beanName, mbdToUse, args); if (logger.isTraceEnabled()) { logger.trace(&quot;Finished creating instance of bean &#39;&quot; + beanName + &quot;&#39;&quot;); } return beanInstance; } }可以看到，postProcessBeforeInstantiation在doCreateBean之前调用，也就是在bean实例化之前调用的，英文源码注释解释道该方法的返回值会替换原本的Bean作为代理，这也是Aop等功能实现的关键点。postProcessAfterInstantiation调用点，忽略无关代码：protected void populateBean(String beanName, RootBeanDefinition mbd, @Nullable BeanWrapper bw) { // Give any InstantiationAwareBeanPostProcessors the opportunity to modify the // state of the bean before properties are set. This can be used, for example, // to support styles of field injection. boolean continueWithPropertyPopulation = true; // InstantiationAwareBeanPostProcessor#postProcessAfterInstantiation() // 方法作为属性赋值的前置检查条件，在属性赋值之前执行，能够影响是否进行属性赋值！ if (!mbd.isSynthetic() &amp;amp;&amp;amp; hasInstantiationAwareBeanPostProcessors()) { for (BeanPostProcessor bp : getBeanPostProcessors()) { if (bp instanceof InstantiationAwareBeanPostProcessor) { InstantiationAwareBeanPostProcessor ibp = (InstantiationAwareBeanPostProcessor) bp; if (!ibp.postProcessAfterInstantiation(bw.getWrappedInstance(), beanName)) { continueWithPropertyPopulation = false; break; } } } } // 忽略后续的属性赋值操作代码}可以看到该方法在属性赋值方法内，但是在真正执行赋值操作之前。其返回值为boolean，返回false时可以阻断属性赋值阶段（continueWithPropertyPopulation = false;）。关于BeanPostProcessor执行阶段的源码穿插在下文Aware接口的调用时机分析中，因为部分Aware功能的就是通过他实现的!只需要先记住BeanPostProcessor在初始化前后调用就可以了。BeanPostProcessorBeanPostProcessor 是 Spring 为修改 bean提供的强大扩展点，其可作用于容器中所有 bean，其定义如下：public interface BeanPostProcessor { // 初始化前置处理 default Object postProcessBeforeInitialization(Object bean, String beanName) throws BeansException { return bean; } // 初始化后置处理 default Object postProcessAfterInitialization(Object bean, String beanName) throws BeansException { return bean; }}常用场景有： 对于标记接口的实现类，进行自定义处理。例如3.1节中所说的ApplicationContextAwareProcessor，为其注入相应依赖；再举个例子，自定义对实现解密接口的类，将对其属性进行解密处理； 为当前对象提供代理实现。例如 Spring AOP 功能，生成对象的代理类，然后返回。// AbstractAutoProxyCreator.javapublic Object postProcessBeforeInstantiation(Class&amp;lt;?&amp;gt; beanClass, String beanName) { TargetSource targetSource = getCustomTargetSource(beanClass, beanName); if (targetSource != null) { if (StringUtils.hasLength(beanName)) { this.targetSourcedBeans.add(beanName); } Object[] specificInterceptors = getAdvicesAndAdvisorsForBean(beanClass, beanName, targetSource); Object proxy = createProxy(beanClass, beanName, specificInterceptors, targetSource); this.proxyTypes.put(cacheKey, proxy.getClass()); // 返回代理类 return proxy; } return null;}第二大类：只调用一次的接口这一大类接口的特点是功能丰富，常用于用户自定义扩展。第二大类中又可以分为两类： Aware类型的接口 生命周期接口无所不知的AwareAware类型的接口的作用就是让我们能够拿到Spring容器中的一些资源。基本都能够见名知意，Aware之前的名字就是可以拿到什么资源，例如BeanNameAware可以拿到BeanName，以此类推。调用时机需要注意：所有的Aware方法都是在初始化阶段之前调用的！若 Spring 检测到 bean 实现了 Aware 接口，则会为其注入相应的依赖。所以通过让bean 实现 Aware 接口，则能在 bean 中获得相应的 Spring 容器资源。Spring 中提供的 Aware 接口有： BeanNameAware：注入当前 bean 对应 beanName； BeanClassLoaderAware：注入加载当前 bean 的 ClassLoader； BeanFactoryAware：注入 当前BeanFactory容器 的引用。其代码实现如下：// AbstractAutowireCapableBeanFactory.javaprivate void invokeAwareMethods(final String beanName, final Object bean) { if (bean instanceof Aware) { if (bean instanceof BeanNameAware) { ((BeanNameAware) bean).setBeanName(beanName); } if (bean instanceof BeanClassLoaderAware) { ((BeanClassLoaderAware) bean).setBeanClassLoader(bcl); } if (bean instanceof BeanFactoryAware) { ((BeanFactoryAware) bean).setBeanFactory(AbstractAutowireCapableBeanFactory.this); } }}以上是针对 BeanFactory 类型的容器，而对于 ApplicationContext 类型的容器，也提供了 Aware 接口，只不过这些 Aware 接口的注入实现，是通过 BeanPostProcessor 的方式注入的，但其作用仍是注入依赖。 EnvironmentAware：注入 Enviroment，一般用于获取配置属性； EmbeddedValueResolverAware：注入 EmbeddedValueResolver（Spring EL解析器），一般用于参数解析； ApplicationContextAware（ResourceLoader、ApplicationEventPublisherAware、MessageSourceAware）：注入 ApplicationContext 容器本身。 这几个接口可能让人有点懵，实际上这几个接口可以一起记，其返回值实质上都是当前的ApplicationContext对象，因为ApplicationContext是一个复合接口，如下： public interface ApplicationContext extends EnvironmentCapable, ListableBeanFactory, HierarchicalBeanFactory, MessageSource, ApplicationEventPublisher, ResourcePatternResolver {} 这里涉及ApplicationContext和BeanFactory的区别，可以从ApplicationContext继承的这几个接口入手，除去BeanFactory相关的两个接口就是ApplicationContext独有的功能，这里不详细说明。 其代码实现如下：// ApplicationContextAwareProcessor.javaprivate void invokeAwareInterfaces(Object bean) { if (bean instanceof EnvironmentAware) { ((EnvironmentAware)bean).setEnvironment(this.applicationContext.getEnvironment()); } if (bean instanceof EmbeddedValueResolverAware) { ((EmbeddedValueResolverAware)bean).setEmbeddedValueResolver(this.embeddedValueResolver); } if (bean instanceof ResourceLoaderAware) { ((ResourceLoaderAware)bean).setResourceLoader(this.applicationContext); } if (bean instanceof ApplicationEventPublisherAware) { ((ApplicationEventPublisherAware)bean).setApplicationEventPublisher(this.applicationContext); } if (bean instanceof MessageSourceAware) { ((MessageSourceAware)bean).setMessageSource(this.applicationContext); } if (bean instanceof ApplicationContextAware) { ((ApplicationContextAware)bean).setApplicationContext(this.applicationContext); }}Aware调用时机源码分析详情如下，忽略了部分无关代码。代码位置就是我们上文提到的initializeBean方法详情，这也说明了Aware都是在初始化阶段之前调用的！ // 见名知意，初始化阶段调用的方法 protected Object initializeBean(final String beanName, final Object bean, @Nullable RootBeanDefinition mbd) { // 这里调用的是Group1中的三个Bean开头的Aware invokeAwareMethods(beanName, bean); Object wrappedBean = bean; // 这里调用的是Group2中的几个Aware， // 而实质上这里就是前面所说的BeanPostProcessor的调用点！ // 也就是说与Group1中的Aware不同，这里是通过BeanPostProcessor（ApplicationContextAwareProcessor）实现的。 wrappedBean = applyBeanPostProcessorsBeforeInitialization(wrappedBean, beanName); // 下文即将介绍的InitializingBean调用点 invokeInitMethods(beanName, wrappedBean, mbd); // BeanPostProcessor的另一个调用点 wrappedBean = applyBeanPostProcessorsAfterInitialization(wrappedBean, beanName); return wrappedBean; }可以看到并不是所有的Aware接口都使用同样的方式调用。Bean××Aware都是在代码中直接调用的，而ApplicationContext相关的Aware都是通过BeanPostProcessor#postProcessBeforeInitialization()实现的。感兴趣的可以自己看一下ApplicationContextAwareProcessor这个类的源码，就是判断当前创建的Bean是否实现了相关的Aware方法，如果实现了会调用回调方法将资源传递给Bean。至于Spring为什么这么实现，应该没什么特殊的考量。也许和Spring的版本升级有关。基于对修改关闭，对扩展开放的原则，Spring对一些新的Aware采用了扩展的方式添加。BeanPostProcessor的调用时机也能在这里体现，包围住invokeInitMethods方法，也就说明了在初始化阶段的前后执行。关于Aware接口的执行顺序，其实只需要记住针对 BeanFactory 类型容器的Aware接口在针对 ApplicationContext 类型容器的Aware接口执行之前就行了生命周期接口至于剩下的两个生命周期接口就很简单了，实例化和属性赋值都是Spring帮助我们做的，能够自己实现的有初始化和销毁两个生命周期阶段。InitializingBean 和 init-methodInitializingBean 和 init-method 是 Spring 为 bean 初始化提供的扩展点。 InitializingBean 对应生命周期的初始化阶段，在上面源码的invokeInitMethods(beanName, wrappedBean, mbd);方法中调用。InitializingBean接口 的定义如下：public interface InitializingBean { void afterPropertiesSet() throws Exception;}在 afterPropertiesSet() 方法写初始化逻辑。指定 init-method 方法，指定初始化方法：&amp;lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&amp;gt;&amp;lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd&quot;&amp;gt; &amp;lt;bean id=&quot;demo&quot; class=&quot;com.chaycao.Demo&quot; init-method=&quot;init()&quot;/&amp;gt; &amp;lt;/beans&amp;gt; 有一点需要注意，因为Aware方法都是执行在初始化方法之前，所以可以在初始化方法中放心大胆的使用Aware接口获取的资源，这也是我们自定义扩展Spring的常用方式。除了实现InitializingBean接口之外还能通过注解或者xml配置的方式指定初始化方法，至于这几种定义方式的调用顺序其实没有必要记。因为这几个方法对应的都是同一个生命周期，只是实现方式不同，我们一般只采用其中一种方式。DisposableBean 和 destory-methodDisposableBean 类似于InitializingBean，对应生命周期的销毁阶段，以ConfigurableApplicationContext#close()方法作为入口，实现是通过循环取所有实现了DisposableBean接口的Bean然后调用其destroy()方法, DisposableBean 和 destory-method 与上述类似总结Spring Bean的生命周期分为四个阶段和多个扩展点。扩展点又可以分为影响多个Bean和影响单个Bean。整理如下：四个阶段 实例化 Instantiation 属性赋值 Populate 初始化 Initialization 销毁 Destruction多个扩展点 影响多个Bean BeanPostProcessor InstantiationAwareBeanPostProcessor 影响单个Bean Aware BeanFactory 类型容器的Aware接口 BeanNameAware BeanClassLoaderAware BeanFactoryAware ApplicationContext 类型容器的Aware接口 EnvironmentAware EmbeddedValueResolverAware ApplicationContextAware(ResourceLoaderAware\\ApplicationEventPublisherAware\\MessageSourceAware) 生命周期 InitializingBean DisposableBean 扩展点按生命周期划分 初始化的具体操作，有 Aware 接口的依赖注入、BeanPostProcessor 在初始化前后的处理以及 InitializingBean 和 init-method 的初始化操作； 销毁的具体操作，有注册相关销毁回调接口，最后通过DisposableBean 和 destory-method 进行销毁。参考 请别再问Spring Bean的生命周期了！ 聊聊spring的那些扩展机制 如何记忆 Spring Bean 的生命周期" }, { "title": "Java 动态代理实现方法", "url": "/posts/java-dynamic-proxy-implementation-methods/", "categories": "Software Development", "tags": "Java", "date": "2021-12-29 15:33:00 +0800", "snippet": "动态代理作用静态代理要说动态代理，必须先聊聊静态代理。假设现在项目经理有一个需求：在项目现有所有类的方法前后打印日志。你如何在不修改已有代码的前提下，完成这个需求？我首先想到的是静态代理。具体做法是：1.为现有的每一个类都编写一个对应的代理类，并且让它实现和目标类相同的接口（假设都有）2.在创建代理对象时，通过构造器塞入一个目标对象，然后在代理对象的方法内部调用目标对象同名方法，并在调用前后打印日志。也就是说，代理对象 = 增强代码 + 目标对象（原对象）。有了代理对象后，就不用原对象了静态代理的缺陷程序员要手动为每一个目标类编写对应的代理类。如果当前系统已经有成百上千个类，工作量太大了，而且不易维护，一旦接口更改，代理类和目标类都需要更改。所以，现在我们的努力方向是：如何少写或者不写代理类，却能完成代理功能？对象的创建过程创建对象的过程实际上可以换个角度，也说得通所谓的Class对象，是Class类的实例，而Class类是描述所有类的，比如Person类，Student类可以看出，要创建一个实例，最关键的就是得到对应的Class对象。只不过对于初学者来说，new这个关键字配合构造方法，实在太好用了，底层隐藏了太多细节，一句 Person p = new Person();直接把对象返回给你了。我自己刚开始学Java时，也没意识到Class对象的存在。分析到这里，貌似有了思路：能否不写代理类，而直接得到代理Class对象，然后根据它创建代理实例（反射）。Class对象包含了一个类的所有信息，比如构造器、方法、字段等。如果我们不写代理类，这些信息从哪获取呢？苦思冥想，突然灵光一现：代理类和目标类理应实现同一组接口。之所以实现相同接口，是为了尽可能保证代理对象的内部结构和目标对象一致，这样我们对代理对象的操作最终都可以转移到目标对象身上，代理对象只需专注于增强代码的编写。还是上面这幅图：所以，可以这样说：接口拥有代理对象和目标对象共同的类信息。所以，我们可以从接口那得到理应由代理类提供的信息。但是别忘了，接口是无法创建对象的，怎么办？当然是让代理类动态的生成啦，也就是动态代理。动态代理为什么类可以动态的生成？这就涉及到Java虚拟机的类加载机制了，推荐翻看《深入理解Java虚拟机》7.3节 类加载的过程。Java虚拟机类加载过程主要分为五个阶段：加载、验证、准备、解析、初始化。其中加载阶段需要完成以下3件事情： 通过一个类的全限定名来获取定义此类的二进制字节流 将这个字节流所代表的静态存储结构转化为方法区的运行时数据结构 在内存中生成一个代表这个类的 java.lang.Class 对象，作为方法区这个类的各种数据访问入口由于JVM规范对这3点要求并不具体，所以实际的实现是非常灵活的，关于第1点，获取类的二进制字节流（class字节码）就有很多途径： 从ZIP包获取，这是JAR、EAR、WAR等格式的基础 从网络中获取，典型的应用是 Applet 运行时计算生成，这种场景使用最多的是动态代理技术，在 java.lang.reflect.Proxy 类中，就是用了 ProxyGenerator.generateProxyClass 来为特定接口生成形式为 *$Proxy 的代理类的二进制字节流 由其它文件生成，典型应用是JSP，即由JSP文件生成对应的Class类 从数据库中获取等等所以，动态代理就是想办法，根据接口或目标对象，计算出代理类的字节码，然后再加载到JVM中使用。但是如何计算？如何生成？情况也许比想象的复杂得多，我们需要借助现有的方案。动态代理使用场景 AOP—面向切面编程，程序解耦 简言之当你想要对一些类的内部的一些方法，在执行前和执行后做一些共同的的操作，而在方法中执行个性化操作的时候–用动态代理。在业务量庞大的时候能够降低代码量，增强可维护性。 想要自定义第三放类库中的某些方法 我引用了一个第三方类库，但他的一些方法不满足我的需求，我想自己重写一下那几个方法，或在方法前后加一些特殊的操作–用动态代理。但需要注意的是，这些方法有局限性 JDK动态代理 利用反射机制生成一个实现代理接口的匿名类，在调用具体方法前调用InvokeHandler来处理。JDK从1.3版本就开始支持动态代理类的创建。主要核心类只有2个：java.lang.reflect.Proxy和java.lang.reflect.InvocationHandler。Proxy有个静态方法：getProxyClass(ClassLoader, interfaces)，只要你给它传入类加载器和一组接口，它就给你返回代理Class对象。用通俗的话说，getProxyClass()这个方法，会从你传入的接口Class中，“拷贝”类结构信息到一个新的Class对象中，但新的Class对象带有构造器，是可以创建对象的。打个比方，一个大内太监（接口Class），空有一身武艺（类信息），但是无法传给后人。现在江湖上有个妙手神医（Proxy类），发明了克隆大法（getProxyClass），不仅能克隆太监的一身武艺，还保留了小DD（构造器）…（这到底是道德の沦丧，还是人性的扭曲，欢迎走进动态代理）所以，一旦我们明确接口，完全可以通过接口的Class对象，创建一个代理Class，通过代理Class即可创建代理对象。所以，按我理解，Proxy.getProxyClass()这个方法的本质就是：以Class造Class。不过实际编程中，一般不用getProxyClass()，而是使用Proxy类的另一个静态方法：Proxy.newProxyInstance()，直接返回代理实例，连中间得到代理Class对象的过程都帮你隐藏： 代理对象的本质就是：和目标对象实现相同接口的实例。代理Class可以叫任何名字，whatever，只要它实现某个接口，就能成为该接口类型。目标接口类/** * 目标接口类 */public interface UserManager { void addUser(String username, String password); void delUser(String username);}接口实现类/** * 动态代理： * 1. 特点：字节码随用随创建，随用随加载 * 2. 作用：不修改源码的基础上对方法增强 * 3. 分类： * 1）基于接口的动态代理 * 1. 基于接口的动态代理： * 1）涉及的类：Proxy * 2）提供者：JDK官方 * 3）如何创建代理对象： * 使用Proxy类中的newProxyInstance方法 * 4）创建代理对象的要求 * 被代理类最少实现一个接口，如果没有则不能使用 * 5）newProxyInstance方法的参数： * ClassLoader：类加载器，它是用于加载代理对象字节码的。和被代理对象使用相同的类加载器。固定写法。 * Class[]：字节码数组，它是用于让代理对象和被代理对象有相同方法。固定写法。 * InvocationHandler：用于提供增强的代码，它是让我们写如何代理。我们一般都是些一个该接口的实现类，通常情况下都是匿名内部类 * 2）基于子类的动态代理 */public class JDKProxy implements InvocationHandler { // 用于指向被代理对象 private Object targetObject; public Object newProxy(Object targetObject) { // 将被代理对象传入进行代理 this.targetObject = targetObject; // 返回代理对象 return Proxy.newProxyInstance(this.targetObject.getClass().getClassLoader(),this.targetObject.getClass().getInterfaces(),this); } /** * 被代理对象的任何方法执行时，都会被invoke方法替换，即：代理对象执行被代理对象中的任何方法时，实际上执行的时当前的invoke方法 * @param proxy（代理对象的引用） * @param method（当前执行的方法） * @param args（当前执行方法所需的参数） * @return（和被代理对象方法有相同的返回值） * @throws Throwable */ @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable { // 在原来的方法上增加了日志打印功能，增强代码 printLog(); Object ret = null; // 调用invoke方法（即执行了代理对象调用被调用对象中的某个方法） ret = method.invoke(targetObject, args); return ret; } /** * 模拟日志打印 */ private void printLog() { System.out.println(&quot;日志打印：printLog()&quot;); }}测试类public class TestJDKProxy { public static void main(String[] args) { UserManager userManager = new UserManagerImpl(); JDKProxy jdkProxy = new JDKProxy(); UserManager userManagerProxy = (UserManager)jdkProxy.newProxy(userManager); System.out.println(&quot;--------------------没有使用增强过的方法--------------------&quot;); userManager.addUser(&quot;root&quot;,&quot;root&quot;); userManager.delUser(&quot;root&quot;); System.out.println(&quot;--------------------使用代理对象增强过的方法--------------------&quot;); userManagerProxy.addUser(&quot;scott&quot;,&quot;tiger&quot;); userManagerProxy.delUser(&quot;scott&quot;); }}测试结果--------------------没有使用增强过的方法--------------------调用了UserManagerImpl.addUser()方法！调用了UserManagerImpl.delUser()方法！--------------------使用代理对象增强过的方法--------------------日志打印：printLog()调用了UserManagerImpl.addUser()方法！日志打印：printLog()调用了UserManagerImpl.delUser()方法！Cglib动态代理 利用ASM（开源的Java字节码编辑库，操作字节码）开源包，将代理对象类的class文件加载进来，通过修改其字节码生成子类来处理。Spring在5.X之前默认的动态代理实现一直是jdk动态代理。但是从5.X开始，spring就开始默认使用Cglib来作为动态代理实现。并且springboot从2.X开始也转向了Cglib动态代理实现。是什么导致了spring体系整体转投Cglib呢，jdk动态代理又有什么缺点呢？那么我们现在就要来说下Cglib的动态代理。Cglib是一个开源项目，它的底层是字节码处理框架ASM，Cglib提供了比jdk更为强大的动态代理。主要相比jdk动态代理的优势有：jdk动态代理只能基于接口，代理生成的对象只能赋值给接口变量，而Cglib就不存在这个问题，Cglib是通过生成子类来实现的，代理对象既可以赋值给实现类，又可以赋值给接口。Cglib速度比jdk动态代理更快，性能更好。 JDK代理只能对实现接口的类生成代理；CGlib是针对类实现代理，对指定的类生成一个子类，并覆盖其中的方法，这种通过继承类的实现方式，不能代理final修饰的类。/** * 动态代理： * 1. 特点：字节码随用随创建，随用随加载 * 2. 作用：不修改源码的基础上对方法增强 * 3. 分类： * 1）基于接口的动态代理 * 2）基于子类的动态代理 * 1. 基于子类的动态代理： * 1）涉及的类：Enhancer * 2）提供者：第三方cglib库 * 3）如何创建代理对象： * 使用Enhancer类中的create方法 * 4）创建代理对象的要求 * 被代理类不能是最终类 * 5）create方法的参数： * Class：字节码，它是用于指定被代理对象的字节码。固定写法。 * Callback()：用于提供增强的代码，它是让我们写如何代理。我们一般都是些一个该接口的实现类。固定写法。 */public class CGLibProxy implements MethodInterceptor { // 用于指向被代理对象 private Object targetObject; // 用于创建代理对象 public Object createProxy(Object targetObject) { this.targetObject = targetObject; return new Enhancer().create(this.targetObject.getClass(),this); } /** * * @param proxy（代理对象的引用） * @param method（当前执行的方法） * @param args（当前执行方法所需的参数） * @param methodProxy（当前执行方法的代理对象） * @return（和被代理对象方法有相同的返回值） * @throws Throwable */ @Override public Object intercept(Object proxy, Method method, Object[] args, MethodProxy methodProxy) throws Throwable { Object ret = null; // 过滤方法 if (&quot;addUser&quot;.equals(method.getName())) { // 日志打印 printLog(); } ret = method.invoke(targetObject, args); return ret; } /** * 模拟日志打印 */ private void printLog() { System.out.println(&quot;日志打印：printLog()&quot;); }}测试类public class TestCGLibProxy { public static void main(String[] args) { CGLibProxy cgLibProxy = new CGLibProxy(); UserManager userManager = new UserManagerImpl(); UserManager cgLibProxyProxy = (UserManager)cgLibProxy.createProxy(userManager); System.out.println(&quot;--------------------没有使用增强过的方法--------------------&quot;); userManager.addUser(&quot;root&quot;,&quot;root&quot;); userManager.delUser(&quot;root&quot;); System.out.println(&quot;--------------------使用代理对象增强过的方法--------------------&quot;); cgLibProxyProxy.addUser(&quot;scott&quot;,&quot;tiger&quot;); cgLibProxyProxy.delUser(&quot;scott&quot;); }}测试结果--------------------没有使用增强过的方法--------------------调用了UserManagerImpl.addUser()方法！调用了UserManagerImpl.delUser()方法！--------------------使用代理对象增强过的方法--------------------日志打印：printLog()调用了UserManagerImpl.addUser()方法！调用了UserManagerImpl.delUser()方法！javassist动态代理Javassist是一个开源的分析、编辑和创建Java字节码的类库，可以直接编辑和生成Java生成的字节码。相对于bcel, asm等这些工具，开发者不需要了解虚拟机指令，就能动态改变类的结构，或者动态生成类。在日常使用中，javassit通常被用来动态修改字节码。它也能用来实现动态代理的功能。创建JavassitProxy，用作统一代理：public class JavassitProxy { private Object bean; public JavassitProxy(Object bean) { this.bean = bean; } public Object getProxy() throws IllegalAccessException, InstantiationException { ProxyFactory f = new ProxyFactory(); f.setSuperclass(bean.getClass()); f.setFilter(m -&amp;gt; ListUtil.toList(&quot;wakeup&quot;,&quot;sleep&quot;).contains(m.getName())); Class c = f.createClass(); MethodHandler mi = (self, method, proceed, args) -&amp;gt; { String methodName = method.getName(); if (methodName.equals(&quot;wakeup&quot;)){ System.out.println(&quot;早安~~~&quot;); }else if(methodName.equals(&quot;sleep&quot;)){ System.out.println(&quot;晚安~~~&quot;); } return method.invoke(bean, args); }; Object proxy = c.newInstance(); ((Proxy)proxy).setHandler(mi); return proxy; }}执行代码：public static void main(String[] args) throws Exception{ JavassitProxy proxy = new JavassitProxy(new Student(&quot;张三&quot;)); Student student = (Student) proxy.getProxy(); student.wakeup(); student.sleep(); proxy = new JavassitProxy(new Doctor(&quot;王教授&quot;)); Doctor doctor = (Doctor) proxy.getProxy(); doctor.wakeup(); doctor.sleep(); proxy = new JavassitProxy(new Dog(&quot;旺旺&quot;)); Dog dog = (Dog) proxy.getProxy(); dog.wakeup(); dog.sleep(); proxy = new JavassitProxy(new Cat(&quot;咪咪&quot;)); Cat cat = (Cat) proxy.getProxy(); cat.wakeup(); cat.sleep();}熟悉的配方，熟悉的味道，大致思路也是类似的。同样把原始bean构造传入。可以看到，javassist也是用”凭空“生成子类的方式类来解决，代码的最后也是调用了原始bean的目标方法完成代理。javaassit比较有特点的是，可以对所需要代理的方法用filter来设定，里面可以像Criteria构造器那样进行构造ByteBuddy动态代理ByteBuddy也是一个大名鼎鼎的开源库，和Cglib一样，也是基于ASM实现。还有一个名气更大的库叫Mockito，相信不少人用过这玩意写过测试用例，其核心就是基于ByteBuddy来实现的，可以动态生成mock类，非常方便。另外ByteBuddy另外一个大的应用就是java agent，其主要作用就是在class被加载之前对其拦截，插入自己的代码。ByteBuddy非常强大，是一个神器。可以应用在很多场景。但是这里，只介绍用ByteBuddy来做动态代理，关于其他使用方式，可能要专门写一篇来讲述，这里先给自己挖个坑。来，还是熟悉的例子，熟悉的配方。用ByteBuddy我们再来实现一遍前面的例子创建ByteBuddyProxy，做统一代理：public class ByteBuddyProxy { private Object bean; public ByteBuddyProxy(Object bean) { this.bean = bean; } public Object getProxy() throws Exception{ Object object = new ByteBuddy().subclass(bean.getClass()) .method(ElementMatchers.namedOneOf(&quot;wakeup&quot;,&quot;sleep&quot;)) .intercept(InvocationHandlerAdapter.of(new AopInvocationHandler(bean))) .make() .load(ByteBuddyProxy.class.getClassLoader()) .getLoaded() .newInstance(); return object; } public class AopInvocationHandler implements InvocationHandler { private Object bean; public AopInvocationHandler(Object bean) { this.bean = bean; } @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable { String methodName = method.getName(); if (methodName.equals(&quot;wakeup&quot;)){ System.out.println(&quot;早安~~~&quot;); }else if(methodName.equals(&quot;sleep&quot;)){ System.out.println(&quot;晚安~~~&quot;); } return method.invoke(bean, args); } }}执行代码：public static void main(String[] args) throws Exception{ ByteBuddyProxy proxy = new ByteBuddyProxy(new Student(&quot;张三&quot;)); Student student = (Student) proxy.getProxy(); student.wakeup(); student.sleep(); proxy = new ByteBuddyProxy(new Doctor(&quot;王教授&quot;)); Doctor doctor = (Doctor) proxy.getProxy(); doctor.wakeup(); doctor.sleep(); proxy = new ByteBuddyProxy(new Dog(&quot;旺旺&quot;)); Dog dog = (Dog) proxy.getProxy(); dog.wakeup(); dog.sleep(); proxy = new ByteBuddyProxy(new Cat(&quot;咪咪&quot;)); Cat cat = (Cat) proxy.getProxy(); cat.wakeup(); cat.sleep();}思路和之前还是一样，ByteBuddy也是采用了创造子类的方式来实现动态代理各种动态代理的对比前面介绍了4种动态代理对于同一例子的实现。对于代理的模式可以分为2种： JDK动态代理采用接口代理的模式，代理对象只能赋值给接口，允许多个接口 Cglib，Javassist，ByteBuddy这些都是采用了子类代理的模式，代理对象既可以赋值给接口，又可以复制给具体实现类Spring5.X，Springboot2.X只有都采用了Cglib作为动态代理的实现，那是不是cglib性能是最好的呢？JDK代理和CGLIB代理对比JDK代理使用的是反射机制实现aop的动态代理，CGLIB代理使用字节码处理框架asm，通过修改字节码生成子类。所以jdk动态代理的方式创建代理对象效率较高，执行效率较低，cglib创建效率较低，执行效率高；JDK动态代理机制是委托机制，具体说动态实现接口类，在动态生成的实现类里面委托hanlder去调用原始实现类方法，CGLIB则使用的继承机制，具体说被代理类和代理类是继承关系，所以代理类是可以赋值给被代理类的，如果被代理类有接口，那么代理类也可以赋值给接口。JDK Proxy 的优势： 最小化依赖关系，减少依赖意味着简化开发和维护，JDK 本身的支持，可能比 cglib 更加可靠。 平滑进行 JDK 版本升级，而字节码类库通常需要进行更新以保证在新版 Java 上能够使用。 代码实现简单。基于类似 cglib 框架的优势： 无需实现接口，达到代理类无侵入 只操作我们关心的类，而不必为其他相关类增加工作量。 高性能参考 Java 动态代理作用是什么？ 动态代理的两种实现方式 动态代理大揭秘，带你彻底弄清楚动态代理！ Java 动态代理详解" }, { "title": "Ubuntu 安装 Redis 流程", "url": "/posts/redis-installation-on-ubuntu/", "categories": "Software Development", "tags": "Redis, 安装流程, Linux", "date": "2021-05-08 00:11:00 +0800", "snippet": "Redis 是一个开源的在内存存储键值对数据的存储程序。它可以被用作数据库，缓存，信息暂存，并且支持各种数据结构，例如：字符串，哈希值，列表，集合等等。 Redis 通过 Redis Sentinel 和 Redis 集群中多个 Redis 节点的自动分块处理，提供了高可用性。这篇文章描述了如何在 Ubuntu 20.04 上安装和配置 Redis。安装 Redis在 Ubuntu 上安装 Redis 非常简单直接。Redis 5.0 被包含在默认的 Ubuntu 20.04 软件源中。想要安装它，以 root 或者其他 sudo 身份运行下面的命令：sudo apt updatesudo apt install redis-server一旦安装完成，Redis 服务将会自动启动。想要检查服务的状态，输入下面的命令：sudo systemctl status redis-server你应该看到下面这些：● redis-server.service - Advanced key-value store Loaded: loaded (/lib/systemd/system/redis-server.service; enabled; vendor preset: enabled) Active: active (running) since Sat 2020-06-06 20:03:08 UTC; 10s ago... 如果你的服务器上禁用 IPv6，那么 Redis 服务将会启动失败。就这些。你已经在你的 Ubuntu 20.04 上安装并运行了 Redis。配置 Redis 远程访问默认情况下，Redis 不允许远程连接。你仅仅只能从127.0.0.1（localhost）连接 Redis 服务器 - Redis 服务器正在运行的机器上。如果你正在使用单机，数据库也同样在这台机器上，你不需要启用远程访问。想要配置 Redis 来接受远程访问，使用你的文本编辑器打开 Redis 配置文件：sudo nano /etc/redis.conf定位到以bind 127.0.0.1 ::1开头的一行，并且取消它的注释： 如果你的服务器有局域网 IP，并且你想要 Redis 从局域网可以访问 Redis，在这一行后面加上服务器局域网 IP 地址。保存这个文件，并且重启 Redis 服务，使应用生效：sudo systemctl restart redis-server使用下面的命令来验证 Redis 服务器正在监听端口6379：ss -an | grep 6379你应该能看到类似下面的信息：tcp LISTEN 0 511 0.0.0.0:6379 0.0.0.0:*tcp LISTEN 0 511 [::]:6379 [::]:* 下一步，你将需要配置你的防火墙，允许网络流量通过 TCP 端口6379。通常你想要允许从一个指定 IP 地址或者一个指定 IP 范围来访问 Redis 服务器。例如，想要允许从192.168.31.10/24的连接，运行下面的命令：sudo ufw allow proto tcp from 192.168.121.0/24 to any port 6379 确保你的防火墙被配置仅仅接受来自受信任 IP 的连接。此时，你应该可以从远程位置通过 TCP 连接到 Redis 的 6379 端口。想要验证所有设置都设置好了，你可以尝试使用redis-cli从你的远程机器上 ping 一下 Redis 服务器。redis-cli -h &amp;lt;REDIS_IP_ADDRESS&amp;gt; ping这个命令将会返回一个响应：PONG" }, { "title": "Ubuntu 安装 JDK 流程", "url": "/posts/jdk-installation-on-ubuntu/", "categories": "Software Development", "tags": "Java, 安装流程, Linux", "date": "2021-05-08 00:11:00 +0800", "snippet": "在篇文章，将会描述如何在 Ubuntu 20.04 上安装 Java。开始之前有很多不同的 Java 实现。OpenJDK 和 Oracle Java 是最主要的两个 Java 实现，除了 Oracle Java 拥有极少的一些额外特性之外，它们两个基本没有什么不同。 Oracle Java 授权仅仅允许作为非商业软件的使用，例如：个人用途和开发用途。默认的 Ubuntu 20.04 源仓库包含了两个 OpenJDK 软件包，, Java Runtime Environment (JRE) 和 Java Development Kit (JDK)。JRE 主要包含了 Java 虚拟机（JVM），类和允许你运行 Java 程序的二进制包。 JDK 包含 JRE 和用于构建 Java 应用的开发/调试工具和库文件。如果你不确定要安装哪一个版本的 Java，我们通常推荐安装 OpenJDK (JDK 11)版本。一些基于 Java 的应用可能需要运行在指定的 Java 版本下，你应该查阅应用文档。 OpenJDK 11 和 OpenJDK 8 都在默认的 Ubuntu 20.04 软件源仓库中，并且可以使用apt软件包管理工具进行安装。安装 OpenJDK 11在写作的时候，Java 11 是 Java 的一个长期支持版本（LTS）。它同时也是 Ubuntu 20.04的默认 Java 开发和运行环境。以 root 或者其他 sudo 权限用户身份 运行下面的命令，更新软件包索引，并且安装OpenJDK 11 JDK 软件包：sudo apt updatesudo apt install openjdk-11-jdk一旦安装完成，你可以通过检查 Java 版本来验证它：java -version输出类似下面这样：openjdk version &quot;11.0.7&quot; 2020-04-14OpenJDK Runtime Environment (build 11.0.7+10-post-Ubuntu-3ubuntu1)OpenJDK 64-Bit Server VM (build 11.0.7+10-post-Ubuntu-3ubuntu1, mixed mode, sharing)就这些！此时，你已经成功地在你的 Ubuntu 系统上安装好了 Java。JRE 被包含在 JDK 软件包中。如果你仅仅需要 JRE，安装openjdk-11-jre软件包。最小 Java 运行环境，安装openjdk-11-jdk-headless软件包。安装 OpenJDK 8Java 8，前一个 Java LTS 版本，目前仍被广泛应用。如果你的应用运行在 Java 8 上，你可以通过输入下面的命令，安装它：sudo apt updatesudo apt install openjdk-8-jdk通过检查 Java 版本，来验证安装过程：java -version输出将会像下面这样：openjdk version &quot;1.8.0_252&quot;OpenJDK Runtime Environment (build 1.8.0_252-8u252-b09-1ubuntu1-b09)OpenJDK 64-Bit Server VM (build 25.252-b09, mixed mode)设置默认版本如果你在你的 Ubuntu 系统上安装了多个 Java 版本，你可以输入下面的命令，检测哪个版本被设置成了默认值：java -version想要修改默认的版本，使用update-alternatives命令：sudo update-alternatives --config java输出像下面这样：There are 2 choices for the alternative java (providing /usr/bin/java). Selection Path Priority Status------------------------------------------------------------* 0 /usr/lib/jvm/java-11-openjdk-amd64/bin/java 1111 auto mode 1 /usr/lib/jvm/java-11-openjdk-amd64/bin/java 1111 manual mode 2 /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java 1081 manual modePress &amp;lt;enter&amp;gt; to keep the current choice[*], or type selection number:所有已经安装的 Java 版本将会列出来。输入你想要设置为默认值的序号，并且按”Enter”。JAVA_HOME 环境变量在一些 Java 应用中，环境变量JAVA_HOME被用来表示 Java 安装位置。想要设置 JAVA_HOME 变量，首先使用update-alternatives找到 Java 安装路径:udo update-alternatives --config java在这个例子中，安装路径如下： OpenJDK 11 is located at /usr/lib/jvm/java-11-openjdk-amd64/bin/java OpenJDK 8 is located at /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java一旦你发现你偏好的 Java 安装路径，打开/etc/environment文件：sudo nano /etc/environment假设你想设置 JAVA_HOME 指定到 OpenJDK 11，在文件的末尾，添加下面的行：JAVA_HOME=&quot;/usr/lib/jvm/java-11-openjdk-amd64&quot;想要让修改在当前 shell 生效，你可以登出系统，再登入系统，或者运行下面的命令：source /etc/environment验证 JAVA_HOME 环境变量被正确设置：echo $JAVA_HOME你应该可以看到 Java 安装路径：/usr/lib/jvm/java-11-openjdk-amd64卸载 Java你可以使用 apt 卸载 Java，就像卸载任何软件包一样。例如，想要卸载default-jdk软件包，输入：sudo apt remove openjdk-11-jdk" }, { "title": "使用 SpringBoot 发送邮件", "url": "/posts/send-email-with-springboot/", "categories": "Software Development", "tags": "Java, Spring, DevDairy", "date": "2021-04-27 16:11:00 +0800", "snippet": "依赖Java 发送邮件依赖 jakarta 项目（原 javaEE）提供的 jakarta.mail 组件, Maven 坐标： &amp;lt;dependency&amp;gt; &amp;lt;groupId&amp;gt;com.sun.mail&amp;lt;/groupId&amp;gt; &amp;lt;artifactId&amp;gt;jakarta.mail&amp;lt;/artifactId&amp;gt; &amp;lt;version&amp;gt;1.6.4&amp;lt;/version&amp;gt; &amp;lt;scope&amp;gt;compile&amp;lt;/scope&amp;gt; &amp;lt;/dependency&amp;gt;Spring 官方 又将其进行进一步封装成开箱即用的 spring-boot-starter-mail 项目： &amp;lt;dependency&amp;gt; &amp;lt;groupId&amp;gt;org.springframework.boot&amp;lt;/groupId&amp;gt; &amp;lt;artifactId&amp;gt;spring-boot-starter-mail&amp;lt;/artifactId&amp;gt; &amp;lt;/dependency&amp;gt;在 Spring Boot 项目中我们引入上面的 spring-boot-starter-mail 依赖即可为你的项目集成邮件功能。接下来我们来对邮件功能进行参数配置。邮箱配置spring-boot-starter-mail 的配置由 MailProperties 配置类提供。在 application.yml 配置文件中以 spring.mail 为前缀。我们来看看都有哪些配置项。# 字符集编码 默认 UTF-8spring.mail.default-encoding=UTF-8# SMTP 服务器 host qq邮箱的为 smtp.qq.com 端口 465 587spring.mail.host=smtp.qq.com# SMTP 服务器端口 不同的服务商不一样spring.mail.port=465# SMTP 服务器使用的协议spring.mail.protocol=smtp# SMTP服务器需要身份验证 所以 要配置用户密码# 发送端的用户邮箱名spring.mail.username=usname@Gmail.com# 发送端的密码 注意保密spring.mail.password=oooooxxxxxxxx# 指定mail会话的jndi名称 优先级较高 一般我们不使用该方式spring.mail.jndi-name=# 这个比较重要 针对不同的SMTP服务器 都有自己的一些特色配置该属性 提供了这些配置的 key value 封装方案 例如 Gmail SMTP 服务器超时配置 spring.mail.properties.mail.smtp.timeout= 5000spring.mail.properties.&amp;lt;key&amp;gt; =# 指定是否在启动时测试邮件服务器连接，默认为falsespring.mail.test-connection=false针对不同的邮箱有不同的配置，所以我们介绍几种我们常用的邮箱配置，可以直接拿来配置。 但是请注意很多邮箱需要手动开启 SMTP 功能，请务必确保该功能打开。如果在公有云上部署请避免使用 25 端口QQ 邮箱# 需要开启 smtpspring.mail.host=smtp.qq.comspring.mail.port=465# 发件人的邮箱spring.mail.username=usname@Gmail.com# qq 邮箱的第三方授权码 并非个人密码spring.mail.password=afshgskdbgsdghgwwq#开启ssl 否则 503 错误spring.mail.properties.mail.smtp.ssl.enable=true163 信箱# 需要在设置中开启 smtpspring.mail.host=smtp.163.comspring.mail.port=465# 发件人的邮箱spring.mail.username=youraccount@163.com# 邮箱的授权码 并非个人密码spring.mail.password=afshgskdbgsdghgwwqspring.mail.properties.mail.smtp.ssl.enable=truespring.mail.properties.mail.imap.ssl.socketFactory.fallback=falsespring.mail.properties.mail.smtp.ssl.socketFactory.class=javax.net.ssl.SSLSocketFactoryspring.mail.properties.mail.smtp.auth=truespring.mail.properties.mail.smtp.starttls.enable=truespring.mail.properties.mail.smtp.starttls.required=truegmailspring.mail.host=smtp.gmail.comspring.mail.port=587spring.mail.username=youraccount@gmail.com# 安全建议使用应用程序密码代替Gmail密码。参见相关文档spring.mail.password=yourpassword# 个性配置spring.mail.properties.mail.debug=truespring.mail.properties.mail.transport.protocol=smtpspring.mail.properties.mail.smtp.auth=truespring.mail.properties.mail.smtp.connectiontimeout=5000spring.mail.properties.mail.smtp.timeout=5000spring.mail.properties.mail.smtp.writetimeout=5000# TLS , port 587spring.mail.properties.mail.smtp.starttls.enable=true# SSL, post 465#spring.mail.properties.mail.smtp.socketFactory.port = 465#spring.mail.properties.mail.smtp.socketFactory.class = javax.net.ssl.SSLSocketFactoryoutlookspring.mail.host=smtp-mail.outlook.comspring.mail.port=587spring.mail.username=youraccount@outlook.comspring.mail.password=yourpasswordspring.mail.properties.mail.protocol=smtpspring.mail.properties.mail.tls=truespring.mail.properties.mail.smtp.auth=truespring.mail.properties.mail.smtp.starttls.enable=truespring.mail.properties.mail.smtp.ssl.trust=smtp-mail.outlook.com邮件发送服务配置完毕后我们就可以构建我们自己的邮件发送服务了纯文本邮件最简单的就是发送纯文本邮件了，完整代码如下：@Componentpublic class EmailService { @Resource private JavaMailSender javaMailSender; @Value(&quot;${spring.mail.username}&quot;) private String from; /** * 发送纯文本邮件. * * @param to 目标email 地址 * @param subject 邮件主题 * @param text 纯文本内容 */ public void sendMail(String to, String subject, String text) { SimpleMailMessage message = new SimpleMailMessage(); message.setFrom(from); message.setTo(to); message.setSubject(subject); message.setText(text); javaMailSender.send(message); }}带附件的邮件有时候我们需要在邮件中携带附件。我们就需要发送 Mime 信息了，代码如下: /** * 发送邮件并携带附件. * 请注意 from 、 to 邮件服务器是否限制邮件大小 * * @param to 目标email 地址 * @param subject 邮件主题 * @param text 纯文本内容 * @param filePath 附件的路径 当然你可以改写传入文件 */ public void sendMailWithAttachment(String to, String subject, String text, String filePath) throws MessagingException { File attachment = new File(filePath); MimeMessage mimeMessage = javaMailSender.createMimeMessage(); MimeMessageHelper helper=new MimeMessageHelper(mimeMessage,true); helper.setFrom(from); helper.setTo(to); helper.setSubject(subject); helper.setText(text); helper.addAttachment(attachment.getName(),attachment); javaMailSender.send(mimeMessage); } 这里需要注意的是 from 、 to 邮件服务器是否限制邮件大小，避免邮件超出限定大小。富文本邮件现在很多的场景是通过电子邮件发送宣传营销的富文本，甚至图文并茂带链接。所以这个功能非常实用。可以通过前端编写适配邮件的 html 模板。将数据动态化注入模板即可。我们先来写一个 html :&amp;lt;html lang=&quot;en&quot;&amp;gt;&amp;lt;head&amp;gt; &amp;lt;meta http-equiv=&quot;content-type&quot; content=&quot;text/html&quot; charset=&quot;UTF-8&quot;&amp;gt; &amp;lt;title&amp;gt;&amp;lt;/title&amp;gt;&amp;lt;/head&amp;gt;&amp;lt;body&amp;gt;&amp;lt;h2&amp;gt;你好，朋友&amp;lt;/h2&amp;gt;&amp;lt;/body&amp;gt;&amp;lt;/html&amp;gt;上面大致上跟我们平时的 html 基本一致，区别在于如果有内嵌的图片元素比如 img 标签 ，其 src 中需要使用占位符，规则为 cid:后紧接着一个你自己定义的标记。比如 qr 。后面会在代码中体现这个 qr。如果使用占位符则必须指定 否则图片无法显示！ 当然你也可以直接把图片的 url 链接写入模板，就像下面:&amp;lt;html lang=&quot;en&quot;&amp;gt;&amp;lt;body&amp;gt; &amp;lt;h2&amp;gt;你好，朋友&amp;lt;/h2&amp;gt;&amp;lt;/body&amp;gt;&amp;lt;/html&amp;gt;然后我们编写 Java 代码 如下： /** * 发送富文本邮件. * * @param to 目标email 地址 * @param subject 邮件主题 * @param text 纯文本内容 * @param filePath 附件的路径 当然你可以改写传入文件 */ public void sendRichMail(String to, String subject, String text, String filePath) throws MessagingException { MimeMessage mimeMessage = javaMailSender.createMimeMessage(); MimeMessageHelper helper=new MimeMessageHelper(mimeMessage,true); helper.setFrom(from); helper.setTo(to); helper.setSubject(subject); helper.setText(text,true); // 图片占位写法 如果图片链接写入模板 注释下面这一行 helper.addInline(&quot;qr&quot;,new FileSystemResource(filePath)); javaMailSender.send(mimeMessage); } 如果你采用类似上面第二个 HTML 模板，图片逻辑就不需要了，注释掉 helper.addInline() 方法即可" }, { "title": "在 SpringBoot 中集成 Redis", "url": "/posts/integrate-redis-in-springboot/", "categories": "Software Development", "tags": "Java, Spring, Redis", "date": "2021-04-15 13:47:00 +0800", "snippet": "Redis 简介一个系统在于数据库交互的过程中，内存的速度远远快于硬盘速度，当我们重复地获取相同数据时，我们一次又一次地请求数据库或远程服务，者无疑时性能上地浪费（这会导致大量时间被浪费在数据库查询或者远程方法调用上致使程序性能恶化），于是有了“缓存”。Redis 是目前业界使用最广泛的内存数据存储。相比 Memcached，Redis 支持更丰富的数据结构，例如 hashes, lists, sets 等，同时支持数据持久化。除此之外，Redis 还提供一些类数据库的特性，比如事务，HA，主从库。Redis 与其他 key - value 缓存产品有以下三个特点： edis支持数据的持久化，可以将内存中的数据保存在磁盘中，重启的时候可以再次加载进行使用。 edis不仅仅支持简单的key-value类型的数据，同时还提供list，set，zset，hash等数据结构的存储。 edis支持数据的备份，即master-slave模式的数据备份。可以说 Redis 兼具了缓存系统和数据库的一些特性，因此有着丰富的应用场景。本文介绍 Redis 在 Spring Boot 中两个典型的应用场景。Spring CacheSpringCache简介Spring Cache是Spring框架提供的对缓存使用的抽象类，支持多种缓存，比如Redis、EHCache等，集成很方便。同时提供了多种注解来简化缓存的使用，可对方法进行缓存。关于SpringCache 注解的简单介绍 @CacheConfig:主要用于配置该类中会用到的一些共用的缓存配置 @Cacheable:主要方法返回值加入缓存。同时在查询时，会先从缓存中取，若不存在才再发起对数据库的访问。 @CachePut:配置于函数上，能够根据参数定义条件进行缓存，与@Cacheable不同的是，每次回真实调用函数，所以主要用于数据新增和修改操作上。 @CacheEvict:配置于函数上，通常用在删除方法上，用来从缓存中移除对应数据 @Caching:配置于函数上，组合多个Cache注解使用。SpringCache 注解@CacheConfig所有的@Cacheable（）里面都有一个value＝“xxx”的属性，这显然如果方法多了，写起来也是挺累的，如果可以一次性声明完 那就省事了， 所以，有了@CacheConfig这个配置，@CacheConfig is a class-level annotation that allows to share the cache names，如果你在你的方法写别的名字，那么依然以方法的名字为准。@CacheConfig是一个类级别的注解。/** * 测试服务层 */@Service@CacheConfig(value = &quot;taskLog&quot;)public class TaskLogService { @Autowired private TaskLogMapper taskLogMapper; @Autowired private net.sf.ehcache.CacheManager cacheManager; /** * 缓存的key */ public static final String CACHE_KEY = &quot;taskLog&quot;; /** * 添加tasklog * @param tasklog * @return */ @CachePut(key = &quot;#tasklog.id&quot;) public Tasklog create(Tasklog tasklog){ System.out.println(&quot;CREATE&quot;); System.err.println (tasklog); taskLogMapper.insert(tasklog); return tasklog; } /** * 根据ID获取Tasklog * @param id * @return */ @Cacheable(key = &quot;#id&quot;) public Tasklog findById(String id){ System.out.println(&quot;FINDBYID&quot;); System.out.println(&quot;ID:&quot;+id); return taskLogMapper.selectById(id); }}@Cacheable@Cacheable 的作用 主要针对方法配置，能够根据方法的请求参数对其结果进行缓存 value、cacheNames：两个等同的参数（cacheNames为Spring 4新增，作为value的别名），用于指定缓存存储的集合名。由于Spring 4中新增了@CacheConfig，因此在Spring 3中原本必须有的value属性，也成为非必需项了 key：缓存对象存储在Map集合中的key值，非必需，缺省按照函数的所有参数组合作为key值，若自己配置需使用SpEL表达式，比如：@Cacheable(key = “#p0”)：使用函数第一个参数作为缓存的key值，更多关于SpEL表达式的详细内容可参考官方文档 condition：缓存对象的条件，非必需，也需使用SpEL表达式，只有满足表达式条件的内容才会被缓存，比如：@Cacheable(key = “#p0”, condition = “#p0.length() &amp;lt; 3”)，表示只有当第一个参数的长度小于3的时候才会被缓存，若做此配置上面的AAA用户就不会被缓存，读者可自行实验尝试。 unless：另外一个缓存条件参数，非必需，需使用SpEL表达式。它不同于condition参数的地方在于它的判断时机，该条件是在函数被调用之后才做判断的，所以它可以通过对result进行判断。 keyGenerator：用于指定key生成器，非必需。若需要指定一个自定义的key生成器，我们需要去实现org.springframework.cache.interceptor.KeyGenerator接口，并使用该参数来指定。需要注意的是：该参数与key是互斥的 cacheManager：用于指定使用哪个缓存管理器，非必需。只有当有多个时才需要使用 cacheResolver：用于指定使用那个缓存解析器，非必需。需通过org.springframework.cache.interceptor.CacheResolver接口来实现自己的缓存解析器，并用该参数指定。作用和配置方法 参数 解释 example value 缓存的名称，在 spring 配置文件中定义，必须指定至少一个 例如: @Cacheable(value=”mycache”) @Cacheable(value={”cache1”,”cache2”} key 缓存的 key，可以为空，如果指定要按照 SpEL 表达式编写，如果不指定，则缺省按照方法的所有参数进行组合 @Cacheable(value=”testcache”,key=”#userName”) condition 缓存的条件，可以为空，使用 SpEL 编写，返回 true 或者 false，只有为 true 才进行缓存 @Cacheable(value=”testcache”,condition=”#userName.length()&amp;gt;2”) /** * 根据ID获取Tasklog * @param id * @return */ @Cacheable(value = CACHE_KEY, key = &quot;#id&quot;,condition = &quot;#result != null&quot;) public Tasklog findById(String id){ System.out.println(&quot;FINDBYID&quot;); System.out.println(&quot;ID:&quot;+id); return taskLogMapper.selectById(id); }@CachePut@CachePut 的作用 主要针对方法配置，能够根据方法的请求参数对其结果进行缓存，和 @Cacheable 不同的是，它每次都会触发真实方法的调用作用和配置方法 参数 解释 example value 缓存的名称，在 spring 配置文件中定义，必须指定至少一个 @CachePut(value=”my cache”) key 缓存的 key，可以为空，如果指定要按照 SpEL 表达式编写，如果不指定，则缺省按照方法的所有参数进行组合 @CachePut(value=”testcache”,key=”#userName”) condition 缓存的条件，可以为空，使用 SpEL 编写，返回 true 或者 false，只有为 true 才进行缓存 @CachePut(value=”testcache”,condition=”#userName.length()&amp;gt;2”) /** * 添加tasklog * @param tasklog * @return */ @CachePut(value = CACHE_KEY, key = &quot;#tasklog.id&quot;) public Tasklog create(Tasklog tasklog){ System.out.println(&quot;CREATE&quot;); System.err.println (tasklog); taskLogMapper.insert(tasklog); return tasklog; }@CacheEvict@CachEvict 的作用 主要针对方法配置，能够根据一定的条件对缓存进行清空作用和配置方法 参数 解释 example value 缓存的名称，在 spring 配置文件中定义，必须指定至少一个 @CacheEvict(value=”my cache”) key 缓存的 key，可以为空，如果指定要按照 SpEL 表达式编写，如果不指定，则缺省按照方法的所有参数进行组合 @CacheEvict(value=”testcache”,key=”#userName”) condition 缓存的条件，可以为空，使用 SpEL 编写，返回 true 或者 false，只有为 true 才进行缓存 @CacheEvict(value=”testcache”,condition=”#userName.length()&amp;gt;2”) allEntries 是否清空所有缓存内容，缺省为 false，如果指定为 true，则方法调用后将立即清空所有缓存 @CachEvict(value=”testcache”,allEntries=true) beforeInvocation 是否在方法执行前就清空，缺省为 false，如果指定为 true，则在方法还没有执行的时候就清空缓存，缺省情况下，如果方法执行抛出异常，则不会清空缓存 @CachEvict(value=”testcache”，beforeInvocation=true) /** * 根据ID删除Tasklog * @param id */ @CacheEvict(value = CACHE_KEY, key = &quot;#id&quot;) public void delete(String id){ System.out.println(&quot;DELETE&quot;); System.out.println(&quot;ID:&quot;+id); taskLogMapper.deleteById(id); }@Caching有时候我们可能组合多个Cache注解使用；比如用户新增成功后，我们要添加id–&amp;gt;user；username—&amp;gt;user；email—&amp;gt;user的缓存；此时就需要@Caching组合多个注解标签了。@Caching(put = {@CachePut(value = &quot;user&quot;, key = &quot;#user.id&quot;),@CachePut(value = &quot;user&quot;, key = &quot;#user.username&quot;),@CachePut(value = &quot;user&quot;, key = &quot;#user.email&quot;)})public User save(User user) {}自定义缓存注解比如之前的那个@Caching组合，会让方法上的注解显得整个代码比较乱，此时可以使用自定义注解把这些注解组合到一个注解中，如：@Caching(put = { @CachePut(value = &quot;user&quot;, key = &quot;#user.id&quot;), @CachePut(value = &quot;user&quot;, key = &quot;#user.username&quot;), @CachePut(value = &quot;user&quot;, key = &quot;#user.email&quot;)})@Target({ElementType.METHOD, ElementType.TYPE})@Retention(RetentionPolicy.RUNTIME)@Inheritedpublic @interface UserSaveCache {}这样我们在方法上使用如下代码即可，整个代码显得比较干净。@UserSaveCachepublic User save(User user){}Spring Cache提供的SpEL上下文数据 名字 位置 描述 示例 methodName root对象 当前被调用的方法名 #root.methodName method root对象 当前被调用的方法 #root.method.name target root对象 当前被调用的目标对象 #root.target targetClass root对象 当前被调用的目标对象类 #root.targetClass args root对象 当前被调用的方法的参数列表 #root.args[0] caches root对象 当前方法调用使用的缓存列表（如@Cacheable(value={“cache1”, “cache2”})），则有两个cache #root.caches[0].name argument name 执行上下文 当前被调用的方法的参数，如findById(Long id)，我们可以通过#id拿到参数 #user.id result 执行上下文 方法执行后的返回值（仅当方法执行之后的判断有效，如‘unless’，’cache evict’的beforeInvocation=false） #result SpringCache和Redis集成过程操作步骤我们要把一个查询函数加入缓存功能，大致需要三步。 在函数执行前，我们需要先检查缓存中是否存在数据，如果存在则返回缓存数据。 如果不存在，就需要在数据库的数据查询出来。 最后把数据存放在缓存中，当下次调用此函数时，就可以直接使用缓存数据，减轻了数据库压力。Spring Cacahe 运行流程 首先执行@CacheEvict（如果beforeInvocation=true且condition 通过），如果allEntries=true，则清空所有 接着收集@Cacheable（如果condition 通过，且key对应的数据不在缓存），放入cachePutRequests（也就是说如果cachePutRequests为空，则数据在缓存中） 如果cachePutRequests为空且没有@CachePut操作，那么将查找@Cacheable的缓存，否则result=缓存数据（也就是说只要当没有cache put请求时才会查找缓存） 如果没有找到缓存，那么调用实际的API，把结果放入result 如果有@CachePut操作(如果condition 通过)，那么放入cachePutRequests 执行cachePutRequests，将数据写入缓存（unless为空或者unless解析结果为false）； 执行@CacheEvict（如果beforeInvocation=false 且 condition 通过），如果allEntries=true，则清空所有 流程中需要注意的就是2/3/4步： 如果有@CachePut操作，即使有@Cacheable也不会从缓存中读取；问题很明显，如果要混合多个注解使用，不能组合使用@CachePut和@Cacheable； 官方说应该避免这样使用（解释是如果带条件的注解相互排除的场景）；不过个人感觉还是不要考虑这个好，让用户来决定如何使用，否则一会介绍的场景不能满足。具体操作添加依赖&amp;lt;!-- springboot redis依赖--&amp;gt; &amp;lt;dependency&amp;gt; &amp;lt;groupId&amp;gt;org.springframework.boot&amp;lt;/groupId&amp;gt; &amp;lt;artifactId&amp;gt;spring-boot-starter-data-redis&amp;lt;/artifactId&amp;gt; &amp;lt;/dependency&amp;gt; 注: 其实我们从官方文档可以看到spring-boot-starter-data-redis 已经包含了jedis客户端，我们在使用jedis连接池的时候不必再添加jedis依赖。配置SpringCache，Redis连接等信息@Configuration@EnableCachingpublic class RedisConfig { /** * 申明缓存管理器，会创建一个切面（aspect）并触发Spring缓存注解的切点（pointcut） * 根据类或者方法所使用的注解以及缓存的状态，这个切面会从缓存中获取数据，将数据添加到缓存之中或者从缓存中移除某个值 * @return */ @Bean public RedisCacheManager cacheManager(RedisConnectionFactory redisConnectionFactory) { return RedisCacheManager.create(redisConnectionFactory); } @Bean public RedisTemplate redisTemplate(RedisConnectionFactory factory) { // 创建一个模板类 RedisTemplate&amp;lt;String, Object&amp;gt; template = new RedisTemplate&amp;lt;String, Object&amp;gt;(); // 将刚才的redis连接工厂设置到模板类中 template.setConnectionFactory(factory); // 设置key的序列化器 template.setKeySerializer(new StringRedisSerializer()); // 设置value的序列化器 //使用Jackson 2，将对象序列化为JSON Jackson2JsonRedisSerializer jackson2JsonRedisSerializer = new Jackson2JsonRedisSerializer(Object.class); //json转对象类，不设置默认的会将json转成hashmap ObjectMapper om = new ObjectMapper(); om.setVisibility(PropertyAccessor.ALL, JsonAutoDetect.Visibility.ANY); om.enableDefaultTyping(ObjectMapper.DefaultTyping.NON_FINAL); jackson2JsonRedisSerializer.setObjectMapper(om); template.setValueSerializer(jackson2JsonRedisSerializer); return template; } } redis配置spring: # redis相关配置 redis: database: 0 host: localhost port: 6379 password: ****** jedis: pool: # 连接池最大连接数（使用负值表示没有限制） max-active: 8 # 连接池最大阻塞等待时间（使用负值表示没有限制） max-wait: -1ms # 连接池中的最大空闲连接 max-idle: 8 # 连接池中的最小空闲连接 min-idle: 0 # 连接超时时间（毫秒）默认是2000ms timeout: 2000ms cache: redis: ## Entry expiration in milliseconds. By default the entries never expire. time-to-live: 1d #写入redis时是否使用键前缀。 use-key-prefix: true启动类cache相关注解必须在spring所管理的bean容器中，这样才能使缓存生效启动类中要加入@EnableCaching注解支持缓存@SpringBootApplication@EnableCachingpublic class CoreApplication { public static void main(String[] args) { SpringApplication.run(CoreApplication.class, args); }}编写实体类@Data//lombok依赖，可省略get set方法public class User implements Serializable { private int userId; private String userName; private String userPassword; public User(int userId, String userName, String userPassword) { this.userId = userId; this.userName = userName; this.userPassword = userPassword; }}service简单操作@Servicepublic class UserDao { public User getUser(int userId) { System.out.println(&quot;执行此方法，说明没有缓存，如果没有走到这里，就说明缓存成功了&quot;); User user = new User(userId, &quot;没有缓存_&quot;+userId, &quot;password_&quot;+userId); return user; } public User getUser2(int userId) { System.out.println(&quot;执行此方法，说明没有缓存，如果没有走到这里，就说明缓存成功了&quot;); User user = new User(userId, &quot;name_nocache&quot;+userId, &quot;nocache&quot;); return user; }}控制层在方法上添加相应的方法即可操作缓存了，SpringCache 对象可以对redis自行操作，减少了很多工作啊，还是那个开箱即用的Spring@RestControllerpublic class testController { @Resource private UserDao userDao; /** * 查询出一条数据并且添加到缓存 * * @param userId * @return */ @RequestMapping(&quot;/getUser&quot;) @Cacheable(&quot;userCache&quot;) public User getPrud(@RequestParam(required = true) String userId) { System.out.println(&quot;如果没有缓存，就会调用下面方法，如果有缓存，则直接输出，不会输出此段话&quot;); return userDao.getUser(Integer.parseInt(userId)); } /** * 删除一个缓存 * * @param userId * @return */ @RequestMapping(value = &quot;/deleteUser&quot;) @CacheEvict(&quot;userCache&quot;) public String deleteUser(@RequestParam(required = true) String userId) { return &quot;删除成功&quot;; } /** * 添加一条保存的数据到缓存，缓存的key是当前user的id * * @param user * @return */ @RequestMapping(&quot;/saveUser&quot;) @CachePut(value = &quot;userCache&quot;, key = &quot;#result.userId +&#39;&#39;&quot;) public User saveUser(User user) { return user; } /** * 返回结果userPassword中含有nocache字符串就不缓存 * * @param userId * @return */ @RequestMapping(&quot;/getUser2&quot;) @CachePut(value = &quot;userCache&quot;, unless = &quot;#result.userPassword.contains(&#39;nocache&#39;)&quot;) public User getUser2(@RequestParam(required = true) String userId) { System.out.println(&quot;如果走到这里说明，说明缓存没有生效！&quot;); User user = new User(Integer.parseInt(userId), &quot;name_nocache&quot; + userId, &quot;nocache&quot;); return user; } @RequestMapping(&quot;/getUser3&quot;) @Cacheable(value = &quot;userCache&quot;, key = &quot;#root.targetClass.getName() + #root.methodName + #userId&quot;) public User getUser3(@RequestParam(required = true) String userId) { System.out.println(&quot;如果第二次没有走到这里说明缓存被添加了&quot;); return userDao.getUser(Integer.parseInt(userId)); }}Spring Data Redis引入依赖&amp;lt;dependencies&amp;gt; &amp;lt;dependency&amp;gt; &amp;lt;groupId&amp;gt;org.springframework.boot&amp;lt;/groupId&amp;gt; &amp;lt;artifactId&amp;gt;spring-boot-starter-data-redis&amp;lt;/artifactId&amp;gt; &amp;lt;/dependency&amp;gt; &amp;lt;dependency&amp;gt; &amp;lt;groupId&amp;gt;org.springframework.boot&amp;lt;/groupId&amp;gt; &amp;lt;artifactId&amp;gt;spring-boot-starter-web&amp;lt;/artifactId&amp;gt; &amp;lt;/dependency&amp;gt;&amp;lt;/dependencies&amp;gt;&amp;lt;dependency&amp;gt; &amp;lt;groupId&amp;gt;org.apache.commons&amp;lt;/groupId&amp;gt; &amp;lt;artifactId&amp;gt;commons-pool2&amp;lt;/artifactId&amp;gt;&amp;lt;/dependency&amp;gt;这里主要就是引入了 Spring Data Redis + 连接池。配置 Redis 信息spring: # redis相关配置 redis: database: 0 host: localhost port: 6379 password: ****** jedis: pool: # 连接池最大连接数（使用负值表示没有限制） max-active: 8 # 连接池最大阻塞等待时间（使用负值表示没有限制） max-wait: -1ms # 连接池中的最大空闲连接 max-idle: 8 # 连接池中的最小空闲连接 min-idle: 0 # 连接超时时间（毫秒）默认是2000ms timeout: 2000ms自动配置当开发者在项目中引入了 Spring Data Redis ，并且配置了 Redis 的基本信息，此时，自动化配置就会生效。我们从 Spring Boot 中 Redis 的自动化配置类中就可以看出端倪：@Configuration@ConditionalOnClass(RedisOperations.class)@EnableConfigurationProperties(RedisProperties.class)@Import({ LettuceConnectionConfiguration.class, JedisConnectionConfiguration.class })public class RedisAutoConfiguration { @Bean @ConditionalOnMissingBean(name = &quot;redisTemplate&quot;) public RedisTemplate&amp;lt;Object, Object&amp;gt; redisTemplate( RedisConnectionFactory redisConnectionFactory) throws UnknownHostException { RedisTemplate&amp;lt;Object, Object&amp;gt; template = new RedisTemplate&amp;lt;&amp;gt;(); template.setConnectionFactory(redisConnectionFactory); return template; } @Bean @ConditionalOnMissingBean public StringRedisTemplate stringRedisTemplate( RedisConnectionFactory redisConnectionFactory) throws UnknownHostException { StringRedisTemplate template = new StringRedisTemplate(); template.setConnectionFactory(redisConnectionFactory); return template; }}这个自动化配置类很好理解： 首先标记这个是一个配置类，同时该配置在 RedisOperations 存在的情况下才会生效(即项目中引入了 Spring Data Redis) 然后导入在 application.properties 中配置的属性 然后再导入连接池信息（如果存在的话） 最后，提供了两个 Bean ，RedisTemplate 和 StringRedisTemplate ，其中 StringRedisTemplate 是 RedisTemplate 的子类，两个的方法基本一致，不同之处主要体现在操作的数据类型不同，RedisTemplate 中的两个泛型都是 Object ，意味者存储的 key 和 value 都可以是一个对象，而 StringRedisTemplate 的 两个泛型都是 String ，意味者 StringRedisTemplate 的 key 和 value 都只能是字符串。如果开发者没有提供相关的 Bean ，这两个配置就会生效，否则不会生效。使用接下来，可以直接在 Service 中注入 StringRedisTemplate 或者 RedisTemplate 来使用：@Servicepublic class HelloService { @Autowired RedisTemplate redisTemplate; public void hello() { ValueOperations ops = redisTemplate.opsForValue(); ops.set(&quot;k1&quot;, &quot;v1&quot;); Object k1 = ops.get(&quot;k1&quot;); System.out.println(k1); }}Redis 中的数据操作，大体上来说，可以分为两种： 针对 key 的操作，相关的方法就在 RedisTemplate 中 针对具体数据类型的操作，相关的方法需要首先获取对应的数据类型，获取相应数据类型的操作方法是 opsForXXXRedisTemplate 中，key 默认的序列化方案是 JdkSerializationRedisSerializer 。而在 StringRedisTemplate 中，key 默认的序列化方案是 StringRedisSerializer ，因此，如果使用 StringRedisTemplate ，默认情况下 key 前面不会有前缀。不过开发者也可以自行修改 RedisTemplate 中的序列化方案，如下:@Servicepublic class HelloService { @Autowired RedisTemplate redisTemplate; public void hello() { redisTemplate.setKeySerializer(new StringRedisSerializer()); ValueOperations ops = redisTemplate.opsForValue(); ops.set(&quot;k1&quot;, &quot;v1&quot;); Object k1 = ops.get(&quot;k1&quot;); System.out.println(k1); }}当然也可以直接使用 StringRedisTemplate：@Servicepublic class HelloService { @Autowired StringRedisTemplate stringRedisTemplate; public void hello2() { ValueOperations ops = stringRedisTemplate.opsForValue(); ops.set(&quot;k2&quot;, &quot;v2&quot;); Object k1 = ops.get(&quot;k2&quot;); System.out.println(k1); }}另外需要注意 ，Spring Boot 的自动化配置，只能配置单机的 Redis ，如果是 Redis 集群，则所有的东西都需要自己手动配置Spring Session引入依赖pom 需要引入 redis 和 session 的依赖&amp;lt;dependency&amp;gt; &amp;lt;groupId&amp;gt;org.springframework.boot&amp;lt;/groupId&amp;gt; &amp;lt;artifactId&amp;gt;spring-boot-starter-data-redis&amp;lt;/artifactId&amp;gt;&amp;lt;/dependency&amp;gt;&amp;lt;dependency&amp;gt; &amp;lt;groupId&amp;gt;org.springframework.session&amp;lt;/groupId&amp;gt; &amp;lt;artifactId&amp;gt;spring-session-data-redis&amp;lt;/artifactId&amp;gt;&amp;lt;/dependency&amp;gt;&amp;lt;dependency&amp;gt; &amp;lt;groupId&amp;gt;org.springframework.boot&amp;lt;/groupId&amp;gt; &amp;lt;artifactId&amp;gt;spring-boot-starter-web&amp;lt;/artifactId&amp;gt;&amp;lt;/dependency&amp;gt;配置spring.redis.host=localhostspring.redis.port=6379spring.redis.password=Redis.127# session存储类型使用redisspring.session.store-type=redis启动类添加 @EnableRedisHttpSession 注解@SpringBootApplication@EnableRedisHttpSessionpublic class CoreApplication { public static void main(String[] args) { SpringApplication.run(CoreApplication.class, args); }}测试 启动两个或以上服务，端口分别为8080，8081…… 分别调用：http://127.0.0.1:8080/getSessionId,http://127.0.0.1:8081/getSessionId若sessionId是一样的，redis里也存在同样的session信息，以上，说明session共享已完成。直接使用 Redis 客户端Lettuce 集成 Redis 服务依赖和配置 由于 Spring Boot 2.X 默认集成了 Lettuce ，所以无需导入依赖。################ Redis 基础配置 ############### Redis数据库索引（默认为0）spring.redis.database=0 # Redis服务器地址spring.redis.host=127.0.0.1# Redis服务器连接端口spring.redis.port=6379 # Redis服务器连接密码（默认为空）spring.redis.password=*********# 链接超时时间 单位 ms（毫秒）spring.redis.timeout=3000################ Redis 线程池设置 ############### 连接池最大连接数（使用负值表示没有限制） 默认 8spring.redis.lettuce.pool.max-active=8# 连接池最大阻塞等待时间（使用负值表示没有限制） 默认 -1spring.redis.lettuce.pool.max-wait=-1# 连接池中的最大空闲连接 默认 8spring.redis.lettuce.pool.max-idle=8# 连接池中的最小空闲连接 默认 0spring.redis.lettuce.pool.min-idle=0自定义 RedisTemplate默认情况下的模板只能支持 RedisTemplate&amp;lt;String,String&amp;gt;，只能存入字符串，很多时候，我们需要自定义 RedisTemplate ，设置序列化器，这样我们可以很方便的操作实例对象。如下所示：@Configurationpublic class LettuceRedisConfig { @Bean public RedisTemplate&amp;lt;String, Serializable&amp;gt; redisTemplate(LettuceConnectionFactory connectionFactory) { RedisTemplate&amp;lt;String, Serializable&amp;gt; redisTemplate = new RedisTemplate&amp;lt;&amp;gt;(); redisTemplate.setKeySerializer(new StringRedisSerializer()); redisTemplate.setValueSerializer(new GenericJackson2JsonRedisSerializer()); redisTemplate.setConnectionFactory(connectionFactory); return redisTemplate; }}序列化实体类public class UserEntity implements Serializable { private static final long serialVersionUID = 6455431221321343103305078L; private Long id; private String userName; private String userSex; public Long getId() { return id; } public void setId(Long id) { this.id = id; } public String getUserName() { return userName; } public void setUserName(String userName) { this.userName = userName; } public String getUserSex() { return userSex; }}测试@RunWith(SpringRunner.class)@SpringBootTestpublic class SpringBootRedisApplicationTests { @Autowired private RedisTemplate&amp;lt;String, String&amp;gt; strRedisTemplate; @Autowired private RedisTemplate&amp;lt;String, Serializable&amp;gt; serializableRedisTemplate; @Test public void testString() { strRedisTemplate.opsForValue().set(&quot;strKey&quot;, &quot;Opt&quot;); System.out.println(strRedisTemplate.opsForValue().get(&quot;strKey&quot;)); } @Test public void testSerializable() { UserEntity user=new UserEntity(); user.setId(1L); user.setUserName(&quot;Optimus&quot;); user.setUserSex(&quot;男&quot;); serializableRedisTemplate.opsForValue().set(&quot;user&quot;, user); UserEntity user2 = (UserEntity) serializableRedisTemplate.opsForValue().get(&quot;user&quot;); System.out.println(&quot;user:&quot;+user2.getId()+&quot;,&quot;+user2.getUserName()+&quot;,&quot;+user2.getUserSex()); }}Jedis 集成 Redis 服务导入依赖和配置&amp;lt;dependency&amp;gt; &amp;lt;groupId&amp;gt;org.springframework.boot&amp;lt;/groupId&amp;gt; &amp;lt;artifactId&amp;gt;spring-boot-starter-data-redis&amp;lt;/artifactId&amp;gt; &amp;lt;exclusions&amp;gt; &amp;lt;!-- 排除lettuce包 --&amp;gt; &amp;lt;exclusion&amp;gt; &amp;lt;groupId&amp;gt;io.lettuce&amp;lt;/groupId&amp;gt; &amp;lt;artifactId&amp;gt;lettuce-core&amp;lt;/artifactId&amp;gt; &amp;lt;/exclusion&amp;gt; &amp;lt;/exclusions&amp;gt; &amp;lt;/dependency&amp;gt; &amp;lt;!-- 添加jedis客户端 --&amp;gt; &amp;lt;dependency&amp;gt; &amp;lt;groupId&amp;gt;redis.clients&amp;lt;/groupId&amp;gt; &amp;lt;artifactId&amp;gt;jedis&amp;lt;/artifactId&amp;gt; &amp;lt;/dependency&amp;gt;################ Redis 基础配置 ############### Redis数据库索引（默认为0）spring.redis.database=0 # Redis服务器地址spring.redis.host=127.0.0.1# Redis服务器连接端口spring.redis.port=6379 # Redis服务器连接密码（默认为空）spring.redis.password=**********# 链接超时时间 单位 ms（毫秒）spring.redis.timeout=3000################ Redis 线程池设置 ############### 连接池最大连接数（使用负值表示没有限制） 默认 8spring.redis.lettuce.pool.max-active=8# 连接池最大阻塞等待时间（使用负值表示没有限制） 默认 -1spring.redis.lettuce.pool.max-wait=-1# 连接池中的最大空闲连接 默认 8spring.redis.lettuce.pool.max-idle=8# 连接池中的最小空闲连接 默认 0spring.redis.lettuce.pool.min-idle=0JedisRedisConfig@Configurationpublic class JedisRedisConfig { @Value(&quot;${spring.redis.database}&quot;) private int database; @Value(&quot;${spring.redis.host}&quot;) private String host; @Value(&quot;${spring.redis.port}&quot;) private int port; @Value(&quot;${spring.redis.password}&quot;) private String password; @Value(&quot;${spring.redis.timeout}&quot;) private int timeout; @Value(&quot;${spring.redis.jedis.pool.max-active}&quot;) private int maxActive; @Value(&quot;${spring.redis.jedis.pool.max-wait}&quot;) private long maxWaitMillis; @Value(&quot;${spring.redis.jedis.pool.max-idle}&quot;) private int maxIdle; @Value(&quot;${spring.redis.jedis.pool.min-idle}&quot;) private int minIdle; /** * 连接池配置信息 */ @Bean public JedisPoolConfig jedisPoolConfig() { JedisPoolConfig jedisPoolConfig = new JedisPoolConfig(); // 最大连接数 jedisPoolConfig.setMaxTotal(maxActive); // 当池内没有可用连接时，最大等待时间 jedisPoolConfig.setMaxWaitMillis(maxWaitMillis); // 最大空闲连接数 jedisPoolConfig.setMinIdle(maxIdle); // 最小空闲连接数 jedisPoolConfig.setMinIdle(minIdle); // 其他属性可以自行添加 return jedisPoolConfig; } /** * Jedis 连接 * * @param jedisPoolConfig * @return */ @Bean public JedisConnectionFactory jedisConnectionFactory(JedisPoolConfig jedisPoolConfig) { JedisClientConfiguration jedisClientConfiguration = JedisClientConfiguration.builder().usePooling() .poolConfig(jedisPoolConfig).and().readTimeout(Duration.ofMillis(timeout)).build(); RedisStandaloneConfiguration redisStandaloneConfiguration = new RedisStandaloneConfiguration(); redisStandaloneConfiguration.setHostName(host); redisStandaloneConfiguration.setPort(port); redisStandaloneConfiguration.setPassword(RedisPassword.of(password)); return new JedisConnectionFactory(redisStandaloneConfiguration, jedisClientConfiguration); } /** * 缓存管理器 * * @param connectionFactory * @return */ @Bean public RedisCacheManager cacheManager(RedisConnectionFactory connectionFactory) { return RedisCacheManager.create(connectionFactory); } @Bean public RedisTemplate&amp;lt;String, Serializable&amp;gt; redisTemplate(JedisConnectionFactory connectionFactory) { RedisTemplate&amp;lt;String, Serializable&amp;gt; redisTemplate = new RedisTemplate&amp;lt;&amp;gt;(); redisTemplate.setKeySerializer(new StringRedisSerializer()); redisTemplate.setValueSerializer(new GenericJackson2JsonRedisSerializer()); redisTemplate.setConnectionFactory(jedisConnectionFactory(jedisPoolConfig())); return redisTemplate; }}测试@RunWith(SpringRunner.class)@SpringBootTestpublic class SpringBootRedisApplicationTests { @Autowired private RedisTemplate&amp;lt;String, String&amp;gt; strRedisTemplate; @Autowired private RedisTemplate&amp;lt;String, Serializable&amp;gt; serializableRedisTemplate; @Test public void testString() { strRedisTemplate.opsForValue().set(&quot;strKey&quot;, &quot;Opt&quot;); System.out.println(strRedisTemplate.opsForValue().get(&quot;strKey&quot;)); } @Test public void testSerializable() { UserEntity user=new UserEntity(); user.setId(1L); user.setUserName(&quot;Optimus&quot;); user.setUserSex(&quot;男&quot;); serializableRedisTemplate.opsForValue().set(&quot;user&quot;, user); UserEntity user2 = (UserEntity) serializableRedisTemplate.opsForValue().get(&quot;user&quot;); System.out.println(&quot;user:&quot;+user2.getId()+&quot;,&quot;+user2.getUserName()+&quot;,&quot;+user2.getUserSex()); }}" }, { "title": "同源策略和实现跨域访问的方法", "url": "/posts/same-origin-policy-and-how-to-achieve-corss-origin-access/", "categories": "Software Development", "tags": "Internet Security", "date": "2021-04-07 14:25:00 +0800", "snippet": "同源策略同源策略定义1995年，同源政策由 Netscape 公司引入浏览器。目前，所有浏览器都实行这个政策。最初，它的含义是指，A网页设置的 Cookie，B网页不能打开，除非这两个网页”同源”如果两个 URL 的 protocol、port (en-US) (如果有指定的话)和 host 都相同的话，则这两个 URL 是同源。这个方案也被称为“协议/主机/端口元组”，或者直接是 “元组”。（“元组” 是指一组项目构成的整体，双重/三重/四重/五重/等的通用形式）。所谓同源是指：域名、协议、端口相同。同源策略（Same origin policy）是一种约定，它是浏览器最核心也最基本的安全功能，如果缺少了同源策略，则浏览器的正常功能可能都会受到影响。可以说 Web 是构建在同源策略基础之上的，浏览器只是针对同源策略的一种实现。它的核心就在于它认为自任何站点装载的信赖内容是不安全的。当被浏览器半信半疑的脚本运行在沙箱时，它们应该只被允许访问来自同一站点的资源，而不是那些来自其它站点可能怀有恶意的资源。下表给出了与 URL http://example.company.com/dir/page.html 的源进行对比的示例: URL 结果 原因 http://example.company.com/dir2/other.html 同源 只有路径不同 http://example.company.com/dir/inner/another.html 同源 只有路径不同 https://example.company.com/secure.html 失败 协议不同 http://example.company.com:81/dir/etc.html 失败 端口不同 ( http:// 默认端口是80) http://news.company.com/dir/other.html 失败 主机不同 随着互联网的发展，”同源政策”越来越严格。目前，如果非同源，共有三种行为受到限制。 Cookie、LocalStorage 和 IndexDB 无法读取。 DOM 无法获得。 AJAX 请求不能发送。为什么使用同源策略因为存在浏览器同源策略，所以才会有跨域问题。那么浏览器是出于何种原因会有跨域的限制呢。其实不难想到，跨域限制主要的目的就是为了用户的上网安全。如果浏览器没有同源策略，会存在什么样的安全问题呢。下面从 DOM 同源策略和 XMLHttpRequest 同源策略来举例说明：如果没有 DOM 同源策略，也就是说不同域的 iframe 之间可以相互访问，那么黑客可以这样进行攻击： 做一个假网站，里面用 iframe 嵌套一个银行网站 http://mybank.com。 把 iframe 宽高啥的调整到页面全部，这样用户进来除了域名，别的部分和银行的网站没有任何差别。 这时如果用户输入账号密码，我们的主网站可以跨域访问到 http://mybank.com 的 dom 节点，就可以拿到用户的账户密码了。如果没有 XMLHttpRequest 同源策略，那么黑客可以进行 CSRF（跨站请求伪造） 攻击： 用户登录了自己的银行页面 http://mybank.com，http://mybank.com 向用户的 cookie 中添加用户标识。 用户浏览了恶意页面 http://evil.com，执行了页面中的恶意 AJAX 请求代码。 http://evil.com 向 http://mybank.com 发起 AJAX HTTP 请求，请求会默认把 http://mybank.com 对应 cookie 也同时发送过去。 银行页面从发送的 cookie 中提取用户标识，验证用户无误，response 中返回请求数据。此时数据就泄露了。 而且由于 Ajax 在后台执行，用户无法感知这一过程。因此，有了浏览器同源策略，我们才能更安全的上网。跨域访问实现CORSCORS的全称是 Cross-Origin Resource Sharing 跨域资源共享。是浏览器为 AJAX 请求设置的一种跨域机制，让其可以在服务端允许的情况下进行跨域访问。主要通过 HTTP 响应头来告诉浏览器服务端是否允许当前域的脚本进行跨域访问。跨域资源共享将 AJAX 请求分成了两类： 简单请求 非简单请求简单请求简单请求需要符合以下特征 请求方法为 GET、POST、HEAD 请求头只能使用下面的字段： Accept 浏览器能够接受的响应内容类型。 Accept-Language浏览器能够接受的自然语言列表。 Content-Type 请求对应的类型，只限于 text/plain、multipart/form-data、application/x-www-form-urlencoded。 Content-Language浏览器希望采用的自然语言。 Save-Data浏览器是否希望减少数据传输量。 简单请求流程如下:浏览器发出简单请求的时候，会在请求头部增加一个 Origin 字段，对应的值为当前请求的源信息。当服务端收到请求后，会根据请求头字段 Origin 做出判断后返回相应的内容。浏览器收到响应报文后会根据响应头部字段 Access-Control-Allow-Origin 进行判断，这个字段值为服务端允许跨域请求的源，其中通配符 * 表示允许所有跨域请求。如果头部信息没有包含 Access-Control-Allow-Origin 字段或者响应的头部字段 Access-Control-Allow-Origin 不允许当前源的请求，则会抛出错误。非简单请求只要不符合上述简单请求的特征，会变成非简单请求，浏览器在处理非简单的请求时，浏览器会先发出一个预检请求（Preflight）。这个预检请求为 OPTIONS 方法，并会添加了 1 个请求头部字段 Access-Control-Request-Method，值为跨域请求所使用的请求方法。在服务端收到预检请求后，除了在响应头部添加 Access-Control-Allow-Origin 字段之外，至少还会添加 Access-Control-Allow-Methods 字段来告诉浏览器服务端允许的请求方法，并返回 204 状态码。服务端还根据浏览器的 Access-Control-Request-Headers 字段回应了一个 Access-Control-Allow-Headers 字段，来告诉浏览器服务端允许的请求头部字段。浏览器得到预检请求响应的头部字段之后，会判断当前请求服务端是否在服务端许可范围之内，如果在则继续发送跨域请求，反之则直接报错。CORS常用头部字段 origin请求首部字段, Origin 指示了请求来自于哪个站点, 包括协议、域名、端口、不包括路径部分在不携带凭证的情况下，可以使是一个*，表示接受任意域名的请求 Access-Control-Allow-Origin响应头，用来标识允许哪个域的请求 Access-Control-Allow-Methods响应头，用来标识允许哪些请求方法被允许 access-control-allow-headers响应首部， 用于预检请求中，列出了将会在正式请求的允许携带的请求头信息。 Access-Control-Expose-Headers响应头，用来告诉浏览器，服务器可以自定义哪些字段暴露给浏览器 Access-Control-Allow-Credentials是否允许携带Credentials,Credentials可以是 cookies, authorization headers 或 TLS client certificates。 Access-Control-Max-Age预检请求的缓存时长CORS 示例CORS 示例参考：SpringBoot 配置 CORS 跨域请求的三种方法CORS 优点: CORS 通信与同源的 AJAX 通信没有差别，代码完全一样，容易维护。 支持所有类型的 HTTP 请求。CORS 缺点: 存在兼容性问题，特别是 IE10 以下的浏览器。 第一次发送非简单请求时会多一次请求。JSONPJSONP（JSON with Padding）的意思就是用 JSON 数据来填充。怎么填充呢？结合它的实现方式可以知道，就是把 JSON 数填充到一个回调函数中。是利用 script 标签跨域引用 js 文件不会受到浏览器同源策略的限制,具有天然跨域性。假设我们要在 http://www.a.com 中向 http://www.b.com 请求数据。 全局声明一个用来处理返回值的函数 fn，该函数参数为请求的返回结果。 function fn(result) { console.log(result)} 将函数名与其他参数一并写入 URL 中 let url = &#39;http://www.b.com?callback=fn&amp;amp;params=...&#39;; 动态创建一个 script 标签，把 URL 赋值给 script 的 src属性。 let script = document.createElement(&#39;script&#39;);script.setAttribute(&quot;type&quot;,&quot;text/javascript&quot;);script.src = url;document.body.appendChild(script); 当服务器接收到请求后，解析 URL 参数并进行对应的逻辑处理，得到结果后将其写成回调函数的形式并返回给浏览器。 fn({ list: [], ...}) 在浏览器收到请求返回的 js 脚本之后会立即执行文件内容，即可获取到服务端返回的数据。JSONP 虽然实现了跨域请求，但也存在以下的几个问题： 只能发送 GET 请求，限制了参数大小和类型。 请求过程无法终止，导致弱网络下处理超时请求比较麻烦。 无法捕获服务端返回的异常信息。WebsocketWebsocket 是 HTML5 规范提出的一个应用层的全双工协议，适用于浏览器与服务器进行实时通信场景。全双工通信传输的一个术语，这里的“工”指的是通信方向。“双工”是指从客户端到服务端，以及从服务端到客户端两个方向都可以通信，“全”指的是通信双方可以同时向对方发送数据。与之相对应的还有半双工和单工，半双工指的是双方可以互相向对方发送数据，但双方不能同时发送，单工则指的是数据只能从一方发送到另一方。下面是一段简单的示例代码。在 a 网站直接创建一个 WebSocket 连接，连接到 b 网站即可，然后调用 WebScoket 实例 ws 的 send() 函数向服务端发送消息，监听实例 ws 的 onmessage 事件得到响应内容。let ws = new WebSocket(&quot;ws://b.com&quot;);ws.onopen = function(){  // ws.send(...);}ws.onmessage = function(e){  // console.log(e.data);}请求代理我们知道浏览器有同源策略的安全限制，但是服务器没有限制，所以我们可以利用服务器进行请求转发。以 webpack 为例，利用 webpack-dev-server 配置代理, 当浏览器发起前缀为 /api 的请求时都会被转发到 http://localhost:3000 服务器，代理服务器将获取到响应返回给浏览器。对于浏览器而言还是请求当前网站，但实际上已经被服务端转发。// webpack.config.jsmodule.exports = { //... devServer: { proxy: { &#39;/api&#39;: &#39;http://localhost:3000&#39; } }};// 使用 Nginx 作为代理服务器location /api {    proxy_pass   http://localhost:3000;}图像 Ping 跨域由于 img 标签不受浏览器同源策略的影响，允许跨域引用资源。因此可以通过 img 标签的 src 属性进行跨域，这也就是图像 Ping 跨域的基本原理。直接通过下面的例子来说明图像 Ping 实现跨域的流程：var img = new Image();// 通过 onload 及 onerror 事件可以知道响应是什么时候接收到的，但是不能获取响应文本img.onload = img.onerror = function() { console.log(&quot;Done!&quot;);}// 请求数据通过查询字符串形式发送img.src = &#39;http://www.example.com/test?name=testscript&#39;;img标签跨域优点: 用于实现跟踪用户点击页面或动态广告曝光次数有较大的优势。img标签跨域缺点: 只支持 GET 请求。 只能浏览器与服务器的单向通信，因为浏览器不能访问服务器的响应文本。页面跨域解决方案请求跨域之外，页面之间也会有跨域需求，例如使用 iframe 时父子页面之间进行通信。常用方案如下： postMessage document.domain window.name(不常用) location.hash + iframe(不常用)postMessagewindow.postMessage 是 HTML5 推出一个新的函数，用来实现父子页面之间通信，而且不论这两个页面是否同源。以 https://test.com 和 https://a.test.com 为例子:// https://test.comlet child = window.open(&#39;https://a.test.com&#39;);child.postMessage(&#39;hello&#39;, &#39;https://a.test.com&#39;);上面的代码通过 window.open() 函数打开了子页面，然后调用 child.postMessage() 函数发送了字符串数据hello给子页面。在子页面中，只需要监听message事件即可得到父页面的数据。代码如下：// https://a.test.comwindow.addEventListener(&#39;message&#39;, function(e) {  console.log(e.data); // hello},false);子页面发送数据时则要通过 window.opener 对象来调用 postMessage() 函数.// https://a.test.comwindow.opener.postMessage(&#39;hello&#39;, &#39;https://test.com&#39;);document.domaindomain 属性可返回下载当前文档的服务器域名。通过修改 document.domain 的值来进行跨域, 这种情况适合主域名相同，子域名不同的页面。我们以 https://www.test.com/parent.html，在这个页面里面有一个 iframe，其 src 是 http://a.test.com/child.html。这时只要把 https://www.test.com/parent.html 和 http://a.test.com/child.html 这两个页面的 document.domain 都设成相同的域名，那么父子页面之间就可以进行跨域通信了，同时还可以共享 cookie。但要注意的是，只能把 document.domain 设置成更高级的父域才有效果，例如在 ·http://a.test.com/child.html 中可以将 document.domain 设置成 test.comwindow.namename 属性可设置或返回存放窗口的名称的一个字符串，name值在不同的页面（包括域名改变）加载后依旧存在。我们准备三个页面： https://localhost:3000/a.html https://localhost:3000/b.html https://localhost:4000/c.htmla页面和 b 页面在相同域下，c页面在另一个域下。我们想a和 c进行通讯，必然涉及到跨域, 通过下面的代码，改变window.name的值来实现跨域。整体实现思路， b.html其实只是个中间代理页面。 a.html的 iframe先加载c.html页面，此时c.html设置了 window.name = ‘test’。 在c.html加载完毕，设置iframe的src为b.html, 由于a.html和b.html在同域，且window.name在域名改变页面从新加载后值不变，实现跨域。&amp;lt;!-- https://localhost:3000/a.html --&amp;gt;&amp;lt;!DOCTYPE html&amp;gt;&amp;lt;html lang=&quot;en&quot;&amp;gt;&amp;lt;head&amp;gt;&amp;lt;/head&amp;gt;&amp;lt;body&amp;gt; &amp;lt;iframe src=&#39;https://localhost:4000/c.html&#39; onload=&quot;onload()&quot; id=&quot;iframe&quot;&amp;gt;&amp;lt;/iframe&amp;gt; &amp;lt;script&amp;gt; // iframe 加载完会调用 iframe， 防止src 改变出现死循环。 let first = true function onload() { if (first) { let iframe = document.getElementById(&#39;iframe&#39;) iframe.src = &#39;https://localhost:3000/b.html&#39; first = false } else { console.log(iframe.contentWindow.name) // &#39;test&#39; } } &amp;lt;/script&amp;gt;&amp;lt;/body&amp;gt;&amp;lt;/html&amp;gt;&amp;lt;!-- https://localhost:4000/c.html --&amp;gt;&amp;lt;!DOCTYPE html&amp;gt;&amp;lt;html lang=&quot;en&quot;&amp;gt;&amp;lt;head&amp;gt;&amp;lt;/head&amp;gt;&amp;lt;body&amp;gt; &amp;lt;script&amp;gt; window.name = &#39;test&#39; &amp;lt;/script&amp;gt;&amp;lt;/body&amp;gt;location.hashhash 属性是一个可读可写的字符串，该字符串是 URL 的锚部分（从 # 号开始的部分）。我们准备三个页面： https://localhost:3000/a.html https://localhost:3000/b.html https://localhost:4000/c.htmla页面和 b 页面在相同域下，c页面在另一个域下。我们想a和 c进行通讯，必然涉及到跨域, 通过下面的代码，改变window.location.hash的值来实现跨域。&amp;lt;!DOCTYPE html&amp;gt;&amp;lt;html lang=&quot;en&quot;&amp;gt;&amp;lt;head&amp;gt;&amp;lt;/head&amp;gt;&amp;lt;body&amp;gt; &amp;lt;!-- 通过 hash 给 c.html 传值 --&amp;gt; &amp;lt;iframe src=&#39;https://localhost:4000/c.html#test&#39; id=&quot;iframe&quot;&amp;gt;&amp;lt;/iframe&amp;gt; &amp;lt;script&amp;gt; // 监听 hash 变化 window.addEventListener(&#39;hashchange&#39;,()=&amp;gt;{ console.log(location.hash) }) &amp;lt;/script&amp;gt;&amp;lt;/body&amp;gt;&amp;lt;/html&amp;gt;&amp;lt;!DOCTYPE html&amp;gt;&amp;lt;html lang=&quot;en&quot;&amp;gt;&amp;lt;head&amp;gt;&amp;lt;/head&amp;gt;&amp;lt;body&amp;gt; &amp;lt;script&amp;gt; // 由于 c 加载的 b 页面，所以，window.parent 是 c 页面 // c 页面的 parent 是 a 页面，然后设置a页面的 hash 值 window.parent.parent.location.hash = location.hash &amp;lt;/script&amp;gt;&amp;lt;/body&amp;gt;&amp;lt;/html&amp;gt;&amp;lt;!DOCTYPE html&amp;gt;&amp;lt;html lang=&quot;en&quot;&amp;gt;&amp;lt;head&amp;gt;&amp;lt;/head&amp;gt;&amp;lt;body&amp;gt; &amp;lt;script&amp;gt; console.log(location.hash) let iframe = document.createElement(&#39;iframe&#39;) iframe.src = &#39;https://localhost:3000/b.html#test_one&#39; document.append(iframe) &amp;lt;/script&amp;gt;&amp;lt;/body&amp;gt;&amp;lt;/html&amp;gt;总结在请求资源进行跨域是，推荐使用 CORS 和 JSONP。在页面资源跨域时推荐使用postMessage 和 document.domain。" }, { "title": "SpringBoot 配置 CORS 跨域请求的三种方法", "url": "/posts/springboot-cors-config/", "categories": "Software Development", "tags": "Java, Spring, DevDairy", "date": "2021-04-07 13:56:00 +0800", "snippet": "前言Springboot跨域问题，是当前主流web开发人员都绕不开的难题。但我们首先要明确以下几点 跨域只存在于浏览器端，不存在于安卓/ios/Node.js/python/ java等其它环境 跨域请求能发出去，服务端能收到请求并正常返回结果，只是结果被浏览器拦截了。 之所以会跨域，是因为受到了同源策略的限制，同源策略要求源相同才能正常进行通信，即协议、域名、端口号都完全一致。浏览器出于安全的考虑，使用 XMLHttpRequest对象发起 HTTP请求时必须遵守同源策略，否则就是跨域的HTTP请求，默认情况下是被禁止的。换句话说，浏览器安全的基石是同源策略。同源策略限制了从同一个源加载的文档或脚本如何与来自另一个源的资源进行交互。这是一个用于隔离潜在恶意文件的重要安全机制。一、什么是CORS？先给出一个熟悉的报错信息，让你找到家的感觉~ Access to XMLHttpRequest at ‘http://192.168.1.1:8080/app/easypoi/importExcelFile’ from origin ‘http://localhost:8080’ has been blocked by CORS policy: No ‘Access-Control-Allow-Origin’ header is present on the requested resource.CORS是一个W3C标准，全称是”跨域资源共享”（Cross-origin resource sharing），允许浏览器向跨源服务器，发出XMLHttpRequest请求，从而克服了AJAX只能同源使用的限制。它通过服务器增加一个特殊的Header[Access-Control-Allow-Origin]来告诉客户端跨域的限制，如果浏览器支持CORS、并且判断Origin通过的话，就会允许XMLHttpRequest发起跨域请求。CORS Header Access-Control-Allow-Origin: http://www.xxx.com Access-Control-Max-Age：86400 Access-Control-Allow-Methods：GET, POST, OPTIONS, PUT, DELETE Access-Control-Allow-Headers: content-type Access-Control-Allow-Credentials: true CORS Header属性 解释 Access-Control-Allow-Origin 允许http://www.xxx.com域（自行设置，这里只做示例）发起跨域请求 Access-Control-Max-Age 设置在86400秒不需要再发送预校验请求 Access-Control-Allow-Methods 设置允许跨域请求的方法 Access-Control-Allow-Headers 允许跨域请求包含content-type Access-Control-Allow-Credentials 设置允许Cookie 二、SpringBoot跨域请求处理方式方法一、直接采用SpringBoot的注解@CrossOrigin（也支持SpringMVC）简单粗暴的方式，Controller层在需要跨域的类或者方法上加上该注解即可@RestController@CrossOrigin@RequestMapping(&quot;/situation&quot;)public class SituationController extends PublicUtilController { @Autowired private SituationService situationService; // log日志信息 private static Logger LOGGER = Logger.getLogger(SituationController.class);} 但每个Controller都得加，太麻烦了，怎么办呢，加在Controller公共父类（PublicUtilController）中，所有Controller继承即可。@CrossOriginpublic class PublicUtilController { /** * 公共分页参数整理接口 * * @param currentPage * @param pageSize * @return */ public PageInfoUtil proccedPageInfo(String currentPage, String pageSize) { /* 分页 */ PageInfoUtil pageInfoUtil = new PageInfoUtil(); try { /* * 将字符串转换成整数,有风险, 字符串为a,转换不成整数 */ pageInfoUtil.setCurrentPage(Integer.valueOf(currentPage)); pageInfoUtil.setPageSize(Integer.valueOf(pageSize)); } catch (NumberFormatException e) { } return pageInfoUtil; }}当然，这里虽然指SpringBoot，SpringMVC也是同样的，但要求在Spring4.2及以上的版本 SpringMVC使用@CrossOrigin使用场景要求 jdk1.8+ Spring4.2+ 方法二、处理跨域请求的Configuration增加一个配置类，CrossOriginConfig.java。继承WebMvcConfigurerAdapter或者实现WebMvcConfigurer接口，其他都不用管，项目启动时，会自动读取配置。@Configurationpublic class CorsConfig extends WebMvcConfigurerAdapter { static final String ORIGINS[] = new String[] { &quot;GET&quot;, &quot;POST&quot;, &quot;PUT&quot;, &quot;DELETE&quot; }; @Override public void addCorsMappings(CorsRegistry registry) { registry.addMapping(&quot;/**&quot;).allowedOrigins(&quot;*&quot;).allowCredentials(true).allowedMethods(ORIGINS).maxAge(3600); }方法三、采用过滤器（filter）的方式同方法二加配置类，增加一个CORSFilter 类，并实现Filter接口即可，其他都不用管，接口调用时，会过滤跨域的拦截。@Component@Order(Integer.MIN_VALUE)@WebFilter(urlPatterns = &quot;/**&quot;, filterName = &quot;CorsConfigFilter&quot;)public class CorsConfigFilter implements Filter { static final String METHODS = &quot;GET, POST, PUT, DELETE, OPTIONS&quot;; static final String HEADERS = &quot;Content-Type,X-CAF-Authorization-Token,sessionToken,Authorization&quot;; private CustomApplicationConfig customApplicationConfig; @Autowired public CorsConfigFilter(CustomApplicationConfig customApplicationConfig) { this.customApplicationConfig = customApplicationConfig; } @Override public void doFilter(ServletRequest request, ServletResponse response, FilterChain chain) throws IOException, ServletException { String ORIGINS = customApplicationConfig.getCorsAllowed(); request.setCharacterEncoding(&quot;utf-8&quot;); response.setCharacterEncoding(&quot;utf-8&quot;); HttpServletResponse res = (HttpServletResponse) response; res.addHeader(&quot;Access-Control-Allow-Credentials&quot;, &quot;false&quot;); res.addHeader(&quot;Access-Control-Allow-Origin&quot;, ORIGINS); res.addHeader(&quot;Access-Control-Allow-Methods&quot;, METHODS); res.addHeader(&quot;Access-Control-Allow-Headers&quot;, HEADERS); res.addHeader(&quot;Access-Control-Expose-Headers&quot;, &quot;Content-Disposition&quot;); if (((HttpServletRequest) request).getMethod().equals(&quot;OPTIONS&quot;)) { response.getWriter().println(&quot;Preflight Done&quot;); return; } chain.doFilter(request, response); }}" }, { "title": "Java 文件 IO 使用方法", "url": "/posts/java-file-io-usage/", "categories": "Software Development", "tags": "Java, IO", "date": "2021-03-30 22:49:00 +0800", "snippet": "创建并写文件的五种方式java中创建文件的五种方法 Files.newBufferedWriter Files.write(Java 7 推荐) PrintWriter File.createNewFile FileOutputStream.write(byte[] b) 管道流try(管道, 流连接等实现了Closeable接口的类){ //这里使用类对象操作} 用try()包含起来，就不用在finally里面自己手动的去 Object.close()了，会自动的关闭Java 8 Files.newBufferedWriterjava8 提供的newBufferedWriter可以创建文件，并向文件内写入数据。可以通过追加写模式，向文件内追加内容。@Testvoid testCreateFile1() throws IOException { String fileName = &quot;D:\\data\\test\\newFile.txt&quot;; Path path = Paths.get(fileName); // 使用newBufferedWriter创建文件并写文件 // 这里使用了try-with-resources方法来关闭流，不用手动关闭 try (BufferedWriter writer = Files.newBufferedWriter(path, StandardCharsets.UTF_8)) { writer.write(&quot;Hello World -创建文件!!&quot;); } //追加写模式 try (BufferedWriter writer = Files.newBufferedWriter(path, StandardCharsets.UTF_8, StandardOpenOption.APPEND)){ writer.write(&quot;Hello World -字母哥!!&quot;); }}Java 7 Files.write下面的这种方式Files.write，是推荐的方式，语法简单，而且底层是使用Java NIO实现的。同样提供追加写模式向已经存在的文件种追加数据。这种方式是实现文本文件简单读写最方便快捷的方式。@Testvoid testCreateFile2() throws IOException { String fileName = &quot;D:\\data\\test\\newFile2.txt&quot;; // 从JDK1.7开始提供的方法 // 使用Files.write创建一个文件并写入 Files.write(Paths.get(fileName), &quot;Hello World -创建文件!!&quot;.getBytes(StandardCharsets.UTF_8)); // 追加写模式 Files.write( Paths.get(fileName), &quot;Hello World -字母哥!!&quot;.getBytes(StandardCharsets.UTF_8), StandardOpenOption.APPEND);}PrintWriterPrintWriter是一个比较古老的文件创建及写入方式，从JDK1.5就已经存在了，比较有特点的是：PrintWriter的println方法，可以实现一行一行的写文件。@Testvoid testCreateFile3() throws IOException { String fileName = &quot;D:\\data\\test\\newFile3.txt&quot;; // JSD 1.5开始就已经存在的方法 try (PrintWriter writer = new PrintWriter(fileName, &quot;UTF-8&quot;)) { writer.println(&quot;Hello World -创建文件!!&quot;); writer.println(&quot;Hello World -字母哥!!&quot;); } // Java 10进行了改进，支持使用StandardCharsets指定字符集 /*try (PrintWriter writer = new PrintWriter(fileName, StandardCharsets.UTF_8)) { writer.println(&quot;first line!&quot;); writer.println(&quot;second line!&quot;); } */}File.createNewFile()createNewFile()方法的功能相对就比较纯粹，只是创建文件不做文件写入操作。 返回true表示文件成功，返回 false表示文件已经存在.可以配合FileWriter 来完成文件的写操作@Testvoid testCreateFile4() throws IOException { String fileName = &quot;D:\\data\\test\\newFile4.txt&quot;; File file = new File(fileName); // 返回true表示文件成功 // false 表示文件已经存在 if (file.createNewFile()) { System.out.println(&quot;创建文件成功！&quot;); } else { System.out.println(&quot;文件已经存在不需要重复创建&quot;); } // 使用FileWriter写文件 try (FileWriter writer = new FileWriter(file)) { writer.write(&quot;Hello World -创建文件!!&quot;); }}最原始的管道流方法最原始的方式就是使用管道流嵌套的方法，使用起来非常灵活。你想去加上Buffer缓冲，你就嵌套一个BufferedWriter，你想去向文件中写java对象你就嵌套一个ObjectOutputStream。但归根结底要用到FileOutputStream@Testvoid testCreateFile5() throws IOException { String fileName = &quot;D:\\data\\test\\newFile5.txt&quot;; try(FileOutputStream fos = new FileOutputStream(fileName); OutputStreamWriter osw = new OutputStreamWriter(fos); BufferedWriter bw = new BufferedWriter(osw);){ bw.write(&quot;Hello World -创建文件!!&quot;); bw.flush(); }}从文件中读取数据的6种方法6种从文件中读取数据的方法： Scanner(Java 1.5) 按行读数据及String、Int类型等按分隔符读数据。 Files.lines, 返回Stream(Java 流式数据处理，按行读取) Files.readAllLines, 返回List&amp;lt;String&amp;gt; Files.readString, 读取String(Java 11), 文件最大 2G. Files.readAllBytes, 读取byte[](Java 7), 文件最大 2G. BufferedReader, 经典方式 (Java 1.1 -&amp;gt; forever)Scanner第一种方式是Scanner，从JDK1.5开始提供的API，特点是可以按行读取、按分割符去读取文件数据，既可以读取String类型，也可以读取Int类型、Long类型等基础数据类型的数据。@Testvoid testReadFile1() throws IOException { //文件内容：Hello World|Hello Zimug String fileName = &quot;D:\\data\\test\\newFile4.txt&quot;; try (Scanner sc = new Scanner(new FileReader(fileName))) { while (sc.hasNextLine()) { //按行读取字符串 String line = sc.nextLine(); System.out.println(line); } } try (Scanner sc = new Scanner(new FileReader(fileName))) { sc.useDelimiter(&quot;\\|&quot;); //分隔符 while (sc.hasNext()) { //按分隔符读取字符串 String str = sc.next(); System.out.println(str); } } //sc.hasNextInt() 、hasNextFloat() 、基础数据类型等等等等。 //文件内容：1|2 fileName = &quot;D:\\data\\test\\newFile5.txt&quot;; try (Scanner sc = new Scanner(new FileReader(fileName))) { sc.useDelimiter(&quot;\\|&quot;); //分隔符 while (sc.hasNextInt()) { //按分隔符读取Int int intValue = sc.nextInt(); System.out.println(intValue); } }}上面的方法输出结果如下：Hello World|Hello ZimugHello WorldHello Zimug12Files.lines (Java 8)如果是需要按行去处理数据文件的内容，这种方式是推荐使用的一种方式，代码简洁，使用java 8的Stream流将文件读取与文件处理有机融合。@Testvoid testReadFile2() throws IOException { String fileName = &quot;D:\\data\\test\\newFile.txt&quot;; // 读取文件内容到Stream流中，按行读取 Stream&amp;lt;String&amp;gt; lines = Files.lines(Paths.get(fileName)); // 随机行顺序进行数据处理 lines.forEach(ele -&amp;gt; { System.out.println(ele); });}forEach获取Stream流中的行数据不能保证顺序，但速度快。如果你想按顺序去处理文件中的行数据，可以使用forEachOrdered，但处理效率会下降。// 按文件行顺序进行处理lines.forEachOrdered(System.out::println);或者利用CPU多和的能力，进行数据的并行处理parallel()，适合比较大的文件。// 按文件行顺序进行处理lines.parallel().forEachOrdered(System.out::println);也可以把Stream&amp;lt;String&amp;gt;转换成List&amp;lt;String&amp;gt;,但是要注意这意味着你要将所有的数据一次性加载到内存，要注意java.lang.OutOfMemoryError// 转换成List&amp;lt;String&amp;gt;, 要注意java.lang.OutOfMemoryError: Java heap spaceList&amp;lt;String&amp;gt; collect = lines.collect(Collectors.toList());Files.readAllLines这种方法仍然是java8 为我们提供的，如果我们不需要Stream,我们想直接按行读取文件获取到一个List，就采用下面的方法。同样的问题：这意味着你要将所有的数据一次性加载到内存，要注意java.lang.OutOfMemoryError@Testvoid testReadFile3() throws IOException { String fileName = &quot;D:\\data\\test\\newFile3.txt&quot;; // 转换成List&amp;lt;String&amp;gt;, 要注意java.lang.OutOfMemoryError: Java heap space List&amp;lt;String&amp;gt; lines = Files.readAllLines(Paths.get(fileName), StandardCharsets.UTF_8); lines.forEach(System.out::println);}Files.readString(JDK 11)从 java11开始，为我们提供了一次性读取一个文件的方法。文件不能超过2G，同时要注意你的服务器及JVM内存。这种方法适合快速读取小文本文件。@Testvoid testReadFile4() throws IOException { String fileName = &quot;D:\\data\\test\\newFile3.txt&quot;; // java 11 开始提供的方法，读取文件不能超过2G，与你的内存息息相关 //String s = Files.readString(Paths.get(fileName));}Files.readAllBytes如果你没有JDK11（readAllBytes()始于JDK7）,仍然想一次性的快速读取一个文件的内容转为String，该怎么办？先将数据读取为二进制数组，然后转换成String内容。这种方法适合在没有JDK11的请开给你下，快速读取小文本文件@Testvoid testReadFile5() throws IOException { String fileName = &quot;D:\\data\\test\\newFile3.txt&quot;; //如果是JDK11用上面的方法，如果不是用这个方法也很容易 byte[] bytes = Files.readAllBytes(Paths.get(fileName)); String content = new String(bytes, StandardCharsets.UTF_8); System.out.println(content);}经典管道流的方式最后一种就是经典的管道流的方式@Testvoid testReadFile6() throws IOException { String fileName = &quot;D:\\data\\test\\newFile3.txt&quot;; // 带缓冲的流读取，默认缓冲区8k try (BufferedReader br = new BufferedReader(new FileReader(fileName))){ String line; while ((line = br.readLine()) != null) { System.out.println(line); } } //java 8中这样写也可以 try (BufferedReader br = Files.newBufferedReader(Paths.get(fileName))){ String line; while ((line = br.readLine()) != null) { System.out.println(line); } }} 这种方式可以通过管道流嵌套的方式，组合使用，比较灵活。比如我们 想从文件中读取java Object就可以使用下面的代码，前提是文件中的数据是ObjectOutputStream写入的数据，才可以用ObjectInputStream来读取。try (FileInputStream fis = new FileInputStream(fileName); ObjectInputStream ois = new ObjectInputStream(fis)){ ois.readObject();} 创建文件夹的4种方法及其优缺点传统API创建文件夹方式Java传统的IO API种使用java.io.File类中的file.mkdir()和file.mkdirs()方法创建文件夹 file.mkdir()创建文件夹成功返回true，失败返回false。如果被创建文件夹的父文件夹不存在也返回false.没有异常抛出。 file.mkdirs()创建文件夹连同该文件夹的父文件夹，如果创建成功返回true，创建失败返回false。创建失败同样没有异常抛出。@Testvoid testCreateDir1() { //“D:\\data111”目录现在不存在 String dirStr = &quot;D:\\data111\\test&quot;; File directory = new File(dirStr); //mkdir boolean hasSucceeded = directory.mkdir(); System.out.println(&quot;创建文件夹结果（不含父文件夹）：&quot; + hasSucceeded); //mkdirs hasSucceeded = directory.mkdirs(); System.out.println(&quot;创建文件夹结果（包含父文件夹）：&quot; + hasSucceeded);}输出结果如下：使用mkdir创建失败，使用mkdirs创建成功。创建文件夹结果（不含父文件夹）：false创建文件夹结果（包含父文件夹）：true大家可以看到，mkdir和mkdirs虽然可以创建文件，但是它们在异常处理的环节做的非常不友好。创建失败之后统一返回false，创建失败的原因没有说明。是父文件夹不存在所以创建失败？还是文件夹已经存在所以创建失败？还是因为磁盘IO原因导致创建文件夹失败？Java NIO创建文件夹为了解决传统IO创建文件夹中异常失败处理问题不明确的问题，在Java的NIO中进行了改进。Files.createDirectory创建文件夹Files.createDirectory创建文件夹 如果被创建文件夹的父文件夹不存在，则抛出NoSuchFileException. 如果被创建的文件夹已经存在，则抛出FileAlreadyExistsException. 如果因为磁盘IO出现异常，则抛出IOException.Path path = Paths.get(&quot;D:\\data222\\test&quot;);Path pathCreate = Files.createDirectory(path);Files.createDirectories创建文件夹及其父文件夹Files.createDirectories创建文件夹及其父文件夹 如果被创建文件夹的父文件夹不存在，就创建它 如果被创建的文件夹已经存在，就是用已经存在的文件夹，不会重复创建，没有异常抛出 如果因为磁盘IO出现异常，则抛出IOException.Path path = Paths.get(&quot;D:\\data222\\test&quot;);Path pathCreate = Files.createDirectorys(path); 另外要注意：NIO的API创建的文件夹返回值是Path，这样方便我们在创建完成文件夹之后继续向文件夹里面写入文件数据等操作。比传统IO只返回一个boolean值要好得多。删除文件或文件夹的7种方法删除文件或文件夹的四种基础方法下面的四个方法都可以删除文件或文件夹，它们的共同点是：当文件夹中包含子文件的时候都会删除失败，也就是说这四个方法只能删除空文件夹。 需要注意的是：传统IO中的File类和NIO中的Path类既可以代表文件，也可以代表文件夹。 File类的delete() File类的deleteOnExit() Files.delete(Path path) Files.deleteIfExists(Path path);它们之间的差异： 成功的返回值 是否能判别文件夹不存在导致失败 是否能判别文件夹不为空导致失败 备注   File类的delete() true 不能(返回false) 不能(返回false) 传统IO File类的deleteOnExit() void 不能，但不存在就不会去执行删除 不能(返回void) 传统IO，这是个坑，避免使用 Files.delete(Path path) void NoSuchFileException DirectoryNotEmptyException NIO，笔者推荐使用 Files.deleteIfExists(Path path) true false DirectoryNotEmptyException NIO 由上面的对比可以看出，传统IO方法删除文件或文件夹，再删除失败的时候，最多返回一个false。通过这个false无法发掘删除失败的具体原因，是因为文件本身不存在删除失败？还是文件夹不为空导致的删除失败？ NIO 的方法在这一点上，就做的比较好，删除成功或失败都有具体的返回值或者异常信息，这样有利于我们在删除文件或文件夹的时候更好的做程序的异常处理 需要注意的是传统IO中的deleteOnExit方法，笔者觉得应该避免使用它。它永远只返回void，删除失败也不会有任何的Exception抛出，所以我建议不要用，以免在你删除失败的时候没有任何的响应，而你可能误以为删除成功了//false只能告诉你失败了 ，但是没有给出任何失败的原因@Testvoid testDeleteFileDir1() { File file = new File(&quot;D:\\data\\test&quot;); boolean deleted = file.delete(); System.out.println(deleted);}//void ,删除失败没有任何提示，应避免使用这个方法，就是个坑@Testvoid testDeleteFileDir2() { File file = new File(&quot;D:\\data\\test1&quot;); file.deleteOnExit();}//如果文件不存在，抛出NoSuchFileException//如果文件夹里面包含文件，抛出DirectoryNotEmptyException@Testvoid testDeleteFileDir3() throws IOException { Path path = Paths.get(&quot;D:\\data\\test1&quot;); Files.delete(path); //返回值void}//如果文件不存在，返回false，表示删除失败(文件不存在)//如果文件夹里面包含文件，抛出DirectoryNotEmptyException@Testvoid testDeleteFileDir4() throws IOException { Path path = Paths.get(&quot;D:\\data\\test1&quot;); boolean result = Files.deleteIfExists(path); System.out.println(result);}归根结底，建议使用java NIO的Files.delete(Path path)和Files.deleteIfExists(Path path);进行文件或文件夹的删除。如何删除整个目录或者目录中的部分文件上文已经说了，那四个API删除文件夹的时候，如果文件夹包含子文件，就会删除失败。那么，如果我们确实想删除整个文件夹，该怎么办？前提准备为了方便我们后面进行测试，先去创建这样一个目录结构，“.log”结尾的是数据文件，其他的是文件夹data |--test1 |--test2 |== test2.log |-- test3 |== test3. log |-- test4 |-- test5 可以使用下面的代码进行创建private void createMoreFiles() throws IOException { Files.createDirectories(Paths.get(&quot;D:\\data\\test1\\test2\\test3\\test4\\test5\\&quot;)); Files.write(Paths.get(&quot;D:\\data\\test1\\test2\\test2.log&quot;), &quot;hello&quot;.getBytes()); Files.write(Paths.get(&quot;D:\\data\\test1\\test2\\test3\\test3.log&quot;), &quot;hello&quot;.getBytes());}walkFileTree与FileVisitor 使用walkFileTree方法遍历整个文件目录树，使用FileVisitor处理遍历出来的每一项文件或文件夹 FileVisitor的visitFile方法用来处理遍历结果中的“文件”，所以我们可以在这个方法里面删除文件 FileVisitor的postVisitDirectory方法，注意方法中的“post”表示“后去做……”的意思，所以用来文件都处理完成之后再去处理文件夹，所以使用这个方法删除文件夹就可以有效避免文件夹内容不为空的异常，因为在去删除文件夹之前，该文件夹里面的文件已经被删除了。@Testvoid testDeleteFileDir5() throws IOException { createMoreFiles(); Path path = Paths.get(&quot;D:\\data\\test1\\test2&quot;); Files.walkFileTree(path, new SimpleFileVisitor&amp;lt;Path&amp;gt;() { // 先去遍历删除文件 @Override public FileVisitResult visitFile(Path file, BasicFileAttributes attrs) throws IOException { Files.delete(file); System.out.printf(&quot;文件被删除 : %s%n&quot;, file); return FileVisitResult.CONTINUE; } // 再去遍历删除目录 @Override public FileVisitResult postVisitDirectory(Path dir, IOException exc) throws IOException { Files.delete(dir); System.out.printf(&quot;文件夹被删除: %s%n&quot;, dir); return FileVisitResult.CONTINUE; } } );}下面的输出体现了文件的删除顺序文件被删除 : D:\\data\\test1\\test2\\test2.log文件被删除 : D:\\data\\test1\\test2\\test3\\test3.log文件夹被删除 : D:\\data\\test1\\test2\\test3\\test4\\test5文件夹被删除 : D:\\data\\test1\\test2\\test3\\test4文件夹被删除 : D:\\data\\test1\\test2\\test3文件夹被删除 : D:\\data\\test1\\test2我们既然可以遍历出文件夹或者文件，我们就可以在处理的过程中进行过滤。比如： 按文件名删除文件或文件夹，参数Path里面含有文件或文件夹名称 按文件创建时间、修改时间、文件大小等信息去删除文件，参数BasicFileAttributes 里面包含了这些文件信息。Files.walk如果你对Stream流语法不太熟悉的话，这种方法稍微难理解一点，但是说实话也非常简单。 使用Files.walk遍历文件夹（包含子文件夹及子其文件），遍历结果是一个Stream&amp;lt;Path&amp;gt; 对每一个遍历出来的结果进行处理，调用Files.delete就可以了。@Testvoid testDeleteFileDir6() throws IOException { createMoreFiles(); Path path = Paths.get(&quot;D:\\data\\test1\\test2&quot;); try (Stream&amp;lt;Path&amp;gt; walk = Files.walk(path)) { walk.sorted(Comparator.reverseOrder()) .forEach(DeleteFileDir::deleteDirectoryStream); }}private static void deleteDirectoryStream(Path path) { try { Files.delete(path); System.out.printf(&quot;删除文件成功：%s%n&quot;,path.toString()); } catch (IOException e) { System.err.printf(&quot;无法删除的路径 %s%n%s&quot;, path, e); }}问题：怎么能做到先去删除文件，再去删除文件夹？ 。 利用的是字符串的排序规则，从字符串排序规则上讲，“D:\\data\\test1\\test2”一定排在“D:\\data\\test1\\test2\\test2.log”的前面。所以我们使用“sorted(Comparator.reverseOrder())”把Stream顺序颠倒一下，就达到了先删除文件，再删除文件夹的目的。下面的输出，是最终执行结果的删除顺序。删除文件成功：D:\\data\\test1\\test2\\test3\\test4\\test5删除文件成功：D:\\data\\test1\\test2\\test3\\test4删除文件成功：D:\\data\\test1\\test2\\test3\\test3.log删除文件成功：D:\\data\\test1\\test2\\test3删除文件成功：D:\\data\\test1\\test2\\test2.log删除文件成功：D:\\data\\test1\\test2传统IO-递归遍历删除文件夹传统的通过递归去删除文件或文件夹的方法就比较经典了//传统IO递归删除@Testvoid testDeleteFileDir7() throws IOException { createMoreFiles(); File file = new File(&quot;D:\\data\\test1\\test2&quot;); deleteDirectoryLegacyIO(file);}private void deleteDirectoryLegacyIO(File file) { File[] list = file.listFiles(); //无法做到list多层文件夹数据 if (list != null) { for (File temp : list) { //先去递归删除子文件夹及子文件 deleteDirectoryLegacyIO(temp); //注意这里是递归调用 } } if (file.delete()) { //再删除自己本身的文件夹 System.out.printf(&quot;删除成功 : %s%n&quot;, file); } else { System.err.printf(&quot;删除失败 : %s%n&quot;, file); }} listFiles()方法只能列出文件夹下面的一层文件或文件夹，不能列出子文件夹及其子文件。 先去递归删除子文件夹，再去删除文件夹自己本身文件拷贝剪切的5种方式 文件拷贝：将文件从一个文件夹复制到另一个文件夹 文件剪切：将文件从当前文件夹，移动到另一个文件夹 文件重命名：将文件在当前文件夹下面改名（也可以理解为将文件剪切为当前文件夹下面的另一个文件）文件拷贝传统IO中的文件copy的方法，使用输入输出流，实际上就是重新创建并写入一个文件。如果目标文件已经存在，就覆盖掉它，重新创建一个文件并写入数据。这种方式不够友好，覆盖掉原有文件没有给出任何提示，有可能导致原有数据的丢失。@Testvoid testCopyFile1() throws IOException { File fromFile = new File(&quot;D:\\data\\test\\newFile.txt&quot;); File toFile = new File(&quot;D:\\data\\test2\\copyedFile.txt&quot;); try(InputStream inStream = new FileInputStream(fromFile); OutputStream outStream = new FileOutputStream(toFile);) { byte[] buffer = new byte[1024]; int length; while ((length = inStream.read(buffer)) &amp;gt; 0) { outStream.write(buffer, 0, length); outStream.flush(); } }}Java NIO中文件copy的方法，使用方式简单。当目标文件已经存在的时候会抛出FileAlreadyExistsException ，当源文件不存在的时候抛出NoSuchFileException，针对不同的异常场景给出不同的Exception，更有利于我们写出健壮性更好的程序。@Testvoid testCopyFile2() throws IOException { Path fromFile = Paths.get(&quot;D:\\data\\test\\newFile.txt&quot;); Path toFile = Paths.get(&quot;D:\\data\\test2\\copyedFile.txt&quot;); Files.copy(fromFile, toFile);}如果在目标文件已经存在的情况下，你不想抛出FileAlreadyExistsException ，而是去覆盖它，也可以灵活的选择使用下面的选项StandardCopyOption.REPLACE_EXISTING 来忽略文件已经存在的异常，如果存在就去覆盖掉它//如果目标文件存在就替换它Files.copy(fromFile, toFile, StandardCopyOption.REPLACE_EXISTING);StandardCopyOption.COPY_ATTRIBUTES copy文件的属性，最近修改时间，最近访问时间等信息，不仅copy文件的内容，连文件附带的属性一并复制CopyOption[] options = { StandardCopyOption.REPLACE_EXISTING, StandardCopyOption.COPY_ATTRIBUTES //copy文件的属性，最近修改时间，最近访问时间等};Files.copy(fromFile, toFile, options);文件重命名NIO中可以使用Files.move方法在同一个文件夹内移动文件，并更换名字。当目标文件已经存在的时候，同样会有FileAlreadyExistsException，也同样可以使用StandardCopyOption去处理该异常。@Testvoid testRenameFile() throws IOException { Path source = Paths.get(&quot;D:\\data\\test\\newFile.txt&quot;); Path target = Paths.get(&quot;D:\\data\\test\\renameFile.txt&quot;); //REPLACE_EXISTING文件存在就替换它 Files.move(source, target,StandardCopyOption.REPLACE_EXISTING);}下文中的实现方法和上面代码的效果是一样的，resolveSibling作用是将source文件的父路径与参数文件名合并为一个新的文件路径。 resolve系列函数在windows和linux等各种系统处理路径分隔符号、路径与文件名合并等，比自己手写代码去处理不同操作系统的路径分隔符号、路径与文件名合并有更好的操作系统兼容性@Testvoid testRenameFile2() throws IOException { Path source = Paths.get(&quot;D:\\data\\test\\newFile.txt&quot;); //这种写法就更加简单，兼容性更好 Files.move(source, source.resolveSibling(&quot;renameFile.txt&quot;));}传统IO中使用File类的renameTo方法重命名，失败了就返回false，没有任何异常抛出。你不会知道你失败的原因是什么，是因为源文件不存在导致失败？还是因为目标文件已经存在导致失败？所以这种方法不建议使用。@Testvoid testRenameFile3() throws IOException { File source = new File(&quot;D:\\data\\test\\newFile.txt&quot;); boolean succeeded = source.renameTo(new File(&quot;D:\\data\\test\\renameFile.txt&quot;)); System.out.println(succeeded); //失败了false，没有异常}文件剪切文件剪切实际上仍然是Files.move，如果move的目标文件夹不存在或源文件不存在，都会抛出NoSuchFileException@Testvoid testMoveFile() throws IOException { Path fromFile = Paths.get(&quot;D:\\data\\test\\newFile.txt&quot;); //文件 Path anotherDir = Paths.get(&quot;D:\\data\\test\\anotherDir&quot;); //目标文件夹 Files.createDirectories(anotherDir); Files.move(fromFile, anotherDir.resolve(fromFile.getFileName()), StandardCopyOption.REPLACE_EXISTING);}resolve函数是解析anotherDir路径与参数文件名进行合并为一个新的文件路径。" }, { "title": "使用 Java 压缩和解压文件与文件夹", "url": "/posts/zip-and-unzip-file-and-folder-use-java/", "categories": "Software Development", "tags": "Java, IO, DevDairy", "date": "2021-03-25 22:42:00 +0800", "snippet": "压缩文件将一个名为test1.txt的文件压缩到一个名为Compressed.zip的zip文件中。public class ZipFile { public static void main(String[] args) throws IOException { //输出压缩包 FileOutputStream fos = new FileOutputStream(&quot;src/main/resources/compressed.zip&quot;); ZipOutputStream zipOut = new ZipOutputStream(fos); //被压缩文件 File fileToZip = new File(&quot;src/main/resources/test1.txt&quot;); FileInputStream fis = new FileInputStream(fileToZip); //向压缩包中添加文件 ZipEntry zipEntry = new ZipEntry(fileToZip.getName()); zipOut.putNextEntry(zipEntry); byte[] bytes = new byte[1024]; int length; while((length = fis.read(bytes)) &amp;gt;= 0) { zipOut.write(bytes, 0, length); } zipOut.close(); fis.close(); fos.close(); }}压缩多个文件将把test1.txt和test2.txt压缩成multiCompressed.zippublic class ZipMultipleFiles { public static void main(String[] args) throws IOException { List&amp;lt;String&amp;gt; srcFiles = Arrays.asList(&quot;src/main/resources/test1.txt&quot;, &quot;src/main/resources/test2.txt&quot;); FileOutputStream fos = new FileOutputStream(&quot;src/main/resources/multiCompressed.zip&quot;); ZipOutputStream zipOut = new ZipOutputStream(fos); //向压缩包中添加多个文件 for (String srcFile : srcFiles) { File fileToZip = new File(srcFile); FileInputStream fis = new FileInputStream(fileToZip); ZipEntry zipEntry = new ZipEntry(fileToZip.getName()); zipOut.putNextEntry(zipEntry); byte[] bytes = new byte[1024]; int length; while((length = fis.read(bytes)) &amp;gt;= 0) { zipOut.write(bytes, 0, length); } fis.close(); } zipOut.close(); fos.close(); }}压缩目录将zipTest目录及该目录下的递归子目录文件，全都压缩到dirCompressed.zip中public class ZipDirectory { public static void main(String[] args) throws IOException, FileNotFoundException { //被压缩的文件夹 String sourceFile = &quot;src/main/resources/zipTest&quot;; //压缩结果输出，即压缩包 FileOutputStream fos = new FileOutputStream(&quot;src/main/resources/dirCompressed.zip&quot;); ZipOutputStream zipOut = new ZipOutputStream(fos); File fileToZip = new File(sourceFile); //递归压缩文件夹 zipFile(fileToZip, fileToZip.getName(), zipOut); //关闭输出流 zipOut.close(); fos.close(); } /** * 将fileToZip文件夹及其子目录文件递归压缩到zip文件中 * @param fileToZip 递归当前处理对象，可能是文件夹，也可能是文件 * @param fileName fileToZip文件或文件夹名称 * @param zipOut 压缩文件输出流 * @throws IOException */ private static void zipFile(File fileToZip, String fileName, ZipOutputStream zipOut) throws IOException { //不压缩隐藏文件夹 if (fileToZip.isHidden()) { return; } //判断压缩对象如果是一个文件夹 if (fileToZip.isDirectory()) { if (fileName.endsWith(&quot;/&quot;)) { //如果文件夹是以“/”结尾，将文件夹作为压缩箱放入zipOut压缩输出流 zipOut.putNextEntry(new ZipEntry(fileName)); zipOut.closeEntry(); } else { //如果文件夹不是以“/”结尾，将文件夹结尾加上“/”之后作为压缩箱放入zipOut压缩输出流 zipOut.putNextEntry(new ZipEntry(fileName + &quot;/&quot;)); zipOut.closeEntry(); } //遍历文件夹子目录，进行递归的zipFile File[] children = fileToZip.listFiles(); for (File childFile : children) { zipFile(childFile, fileName + &quot;/&quot; + childFile.getName(), zipOut); } //如果当前递归对象是文件夹，加入ZipEntry之后就返回 return; } //如果当前的fileToZip不是一个文件夹，是一个文件，将其以字节码形式压缩到压缩包里面 FileInputStream fis = new FileInputStream(fileToZip); ZipEntry zipEntry = new ZipEntry(fileName); zipOut.putNextEntry(zipEntry); byte[] bytes = new byte[1024]; int length; while ((length = fis.read(bytes)) &amp;gt;= 0) { zipOut.write(bytes, 0, length); } fis.close(); }} 要压缩子目录及其子目录文件，所以需要递归遍历 每次遍历找到的是目录时，我们都将其名称附加“/”,并将其以ZipEntry保存到压缩包中，从而保持压缩的目录结构。 每次遍历找到的是文件时，将其以字节码形式压缩到压缩包里面解压缩zip压缩包我们将compressed.zip解压缩到名为unzipTest的新文件夹中public class UnzipFile { public static void main(String[] args) throws IOException { //被解压的压缩文件 String fileZip = &quot;src/main/resources/unzipTest/compressed.zip&quot;; //解压的目标目录 File destDir = new File(&quot;src/main/resources/unzipTest&quot;); byte[] buffer = new byte[1024]; ZipInputStream zis = new ZipInputStream(new FileInputStream(fileZip)); //获取压缩包中的entry，并将其解压 ZipEntry zipEntry = zis.getNextEntry(); while (zipEntry != null) { File newFile = newFile(destDir, zipEntry); FileOutputStream fos = new FileOutputStream(newFile); int len; while ((len = zis.read(buffer)) &amp;gt; 0) { fos.write(buffer, 0, len); } fos.close(); //解压完成一个entry，再解压下一个 zipEntry = zis.getNextEntry(); } zis.closeEntry(); zis.close(); } //在解压目标文件夹，新建一个文件 public static File newFile(File destinationDir, ZipEntry zipEntry) throws IOException { File destFile = new File(destinationDir, zipEntry.getName()); String destDirPath = destinationDir.getCanonicalPath(); String destFilePath = destFile.getCanonicalPath(); if (!destFilePath.startsWith(destDirPath + File.separator)) { throw new IOException(&quot;该解压项在目标文件夹之外: &quot; + zipEntry.getName()); } return destFile; }}" }, { "title": "SpringSecurity 实现方法级别的权限验证", "url": "/posts/spring-security-method-level-auth/", "categories": "Software Development", "tags": "Java, Spring, SpringSecurity, DevDairy", "date": "2021-03-10 15:23:00 +0800", "snippet": "背景在前文SpringSecurity 使用方法中实通过SpringSecurity配置实现了请求路径得用户权限验证，但是只实现了已登录得用户有权限可以访问被保护的资源，但是不同的资源对不同用户的访问权限不一致，例如某个资源是A用户的私有资源，而B应该无权访问，或者R为A共享的资源，B可以访问但不能修改。而且由于使用Restful风格，对统一资源的CURD操作请求路径一致，而是通过HTTP方法区分，基于路径hasAuthority和hasRole表达式都无法满足需求，因为它们只能判断一个硬编码的权限或者角色字符串。所以我们需要用到自定义表达式来高度自定义权限判断以满足需求。SpringSecurity 方法级的安全管控配置默认情况下, Spring Security 并不启用方法级的安全管控. 启用方法级的管控后, 可以针对不同的方法通过注解设置不同的访问条件.Spring Security 支持三种方法级注解, 分别是 JSR-205 注解/@Secured 注解/prePostEnabled注解. 这些注解不仅可以直接加 controller 方法上, 也可以注解 Service 或 DAO 类中的方法.开启@EnableGlobalMethodSecurity(prePostEnabled = true)注解, 在继承 WebSecurityConfigurerAdapter 这个类的类上面贴上这个注解.并且prePostEnabled设置为true,@PreAuthorize这个注解才能生效,SpringSecurity默认是关闭注解功能的.@Configuration@EnableWebSecurity@EnableGlobalMethodSecurity(prePostEnabled=true)public class SecurityConfig extends WebSecurityConfigurerAdapter {}让后就可以在Controller里面添加方法验证注解了 @PreAuthorize(&quot;@ValidService.isUserHasOwnership(#userId, #repoId)&quot;) @GetMapping(&quot;/api/{userId}/{repoId}/notes&quot;) public List&amp;lt;Note&amp;gt; getNotes(@PathVariable int userId, @PathVariable int repoId) { return noteService.getAllNoteOfARepo(repoId); }这里主要@PreAuthorize, @PostAuthorize, @Secured这三个注解可以使用。@PreAuthorizeSpring的 @PreAuthorize/@PostAuthorize 注解更适合方法级的安全,也支持Spring 表达式语言，提供了基于表达式的访问控制。当@EnableGlobalMethodSecurity(prePostEnabled=true)的时候，@PreAuthorize可以使用：@GetMapping(&quot;/helloUser&quot;)@PreAuthorize(&quot;hasAnyRole(&#39;normal&#39;,&#39;admin&#39;)&quot;)public String helloUser() { return &quot;hello,user&quot;;}说明：拥有normal或者admin角色的用户都可以方法helloUser()方法。此时如果我们要求用户必须同时拥有normal和admin的话，那么可以这么编码：@GetMapping(&quot;/helloUser&quot;)@PreAuthorize(&quot;hasRole(&#39;normal&#39;) AND hasRole(&#39;admin&#39;)&quot;) public String helloUser() { return &quot;hello,user&quot;;}此时如果使用user/123登录的话，就无法访问helloUser()的方法了。@PostAuthorize@PostAuthorize 注解使用并不多，在方法执行后再进行权限验证，适合验证带有返回值的权限，Spring EL 提供 返回对象能够在表达式语言中获取返回的对象returnObject。当@EnableGlobalMethodSecurity(prePostEnabled=true)的时候，@PostAuthorize可以使用：@GetMapping(&quot;/helloUser&quot;)@PostAuthorize(&quot; returnObject!=null &amp;amp;&amp;amp; returnObject.username == authentication.name&quot;)public User helloUser() { Object pricipal = SecurityContextHolder.getContext().getAuthentication().getPrincipal(); User user; if(&quot;anonymousUser&quot;.equals(pricipal)) { user = null; }else { user = (User) pricipal; } return user;}@Secured当@EnableGlobalMethodSecurity(securedEnabled=true)的时候，@Secured可以使用：@GetMapping(&quot;/helloUser&quot;)@Secured({&quot;ROLE_normal&quot;,&quot;ROLE_admin&quot;})public String helloUser() { return &quot;hello,user&quot;;}说明：拥有normal或者admin角色的用户都可以方法helloUser()方法。另外需要注意的是这里匹配的字符串需要添加前缀“ROLE_“。如果我们要求，只有同时拥有admin &amp;amp; noremal的用户才能方法helloUser()方法，这时候@Secured就无能为力了。SpringSecurity 内置表达式 Expression Description hasRole([role]) 如果当前主体具有指定角色，则返回true。默认情况下，如果提供的角色不是以“ ROLE_”开头，则会添加该角色。可以通过修改DefaultWebSecurityExpressionHandler上的defaultRolePrefix进行自定义。 hasAnyRole([role1,role2]) 如果当前主体具有提供的任何角色(以逗号分隔的字符串列表形式)，则返回true。默认情况下，如果提供的角色不是以“ ROLE_”开头，则会添加该角色。可以通过修改DefaultWebSecurityExpressionHandler上的defaultRolePrefix进行自定义。 hasAuthority([authority]) 如果当前主体具有指定的权限，则返回true。 hasAnyAuthority([authority1,authority2]) 如果当前委托人具有提供的任何角色(以逗号分隔的字符串列表形式)，则返回true principal 允许直接访问代表当前用户的主体对象 authentication 允许直接访问从SecurityContext获取的当前Authentication对象 permitAll 始终计算为true denyAll 始终计算为false isAnonymous() 如果当前主体是匿名用户，则返回true isRememberMe() 如果当前主体是“记住我”用户，则返回true isAuthenticated() 如果用户不是匿名用户，则返回true isFullyAuthenticated() 如果用户不是匿名用户或“记住我”用户，则返回true hasPermission(Object target, Object permission) 如果用户有权访问给定目标的给定权限，则返回true。例如hasPermission(domainObject, ‘read’) hasPermission(Object targetId, String targetType, Object permission) 如果用户有权访问给定目标的给定权限，则返回true。例如hasPermission(1, ‘com.example.domain.Message’, ‘read’) 自定义验证逻辑当然 除了内建的表达式外，我们也可以自己实现验证逻辑@Service(&quot;ValidService&quot;)public class userOwnershipCheck { final UserInfoTool userInfoTool; final RepoService repoService; final NoteService noteService; @Autowired public userOwnershipCheck(UserInfoTool userInfoTool, RepoService repoService, NoteService noteService) { this.userInfoTool = userInfoTool; this.repoService = repoService; this.noteService = noteService; } /*requestUserPath为用户ID*/ public boolean isUserHasOwnership(int userId) { return userInfoTool.currentUser().getId() == userId; } /*requestUserPath为用户ID*/ public boolean isUserHasOwnership(int userId, int repoId) { Repo repo = repoService.getRepoById(repoId); if (repo == null) { Asserts.fail(CustomStatusEnum.USER_REPO_NOT_EXIST); } return userInfoTool.currentUser().getId() == userId &amp;amp;&amp;amp; userInfoTool.currentUser().getId() == repo.getUser().getId(); }只需要将实习逻辑注册为服务，然后在@PreAuthorize(), @PostAuthorize(), @Secured()调用即可 @PreAuthorize(&quot;@ValidService.isUserHasOwnership(#userId, #repoId)&quot;) @GetMapping(&quot;/api/{userId}/{repoId}/notes&quot;) public List&amp;lt;Note&amp;gt; getNotes(@PathVariable int userId, @PathVariable int repoId) { return noteService.getAllNoteOfARepo(repoId); }这样在用户以Get方法访问 /api/{userId}/{repoId}/notes 时 @PreAuthorize 会根据自定义验证逻辑中用户是否对此资源拥有读取权限来确定是否放行请求" }, { "title": "SpringBoot 实现全局异常处理", "url": "/posts/global-exception-handle-in-springboot/", "categories": "Software Development", "tags": "Java, Spring, DevDairy", "date": "2021-03-08 12:43:00 +0800", "snippet": "将返回值统一封装时我们没有考虑当接口抛出异常的情况。当接口抛出异常时让用户直接看到服务端的异常肯定是不够友好的，而我们也不可能每一个接口都去try/catch进行处理，此时只需要使用@ExceptionHandler注解即可无感知的全局统一处理异常。前言实现思路使用全局异常处理来处理校验逻辑的思路很简单，首先我们需要通过@ControllerAdvice注解定义一个全局异常的处理类，然后自定义一个校验异常，当我们在Controller中校验失败时，直接抛出该异常，这样就可以达到校验失败返回错误信息的目的了。使用到的注解 @ControllerAdvice：类似于@Component注解，可以指定一个组件，这个组件主要用于增强@Controller注解修饰的类的功能，比如说进行全局异常处理。 @ExceptionHandler：用来修饰全局异常处理的方法，可以指定异常的类型。实现示例代码ApiException首先我们需要自定义一个异常类ApiException，当我们校验失败时抛出该异常public class ApiException extends RuntimeException { private int status; public ApiException(int status) { this.status = status; } public ApiException(String message) { super(message); } public ApiException(int status, String message) { super(message); this.status = status; } public ApiException(String message, Throwable cause) { super(message, cause); } public int getStatus() { return status; }}Asserts然后创建一个断言处理类Asserts，用于抛出各种ApiExceptionpublic class Asserts { public static void fail(CustomStatusEnum customStatusEnum){ throw new ApiException(customStatusEnum.getStatus(), customStatusEnum.getMessage()); } public static void fail(String message) { throw new ApiException(message); } public static void success(CustomStatusEnum customStatusEnum){ throw new ApiException(customStatusEnum.getStatus(), customStatusEnum.getMessage()); }}GlobalExceptionHandler然后再创建我们的全局异常处理类GlobalExceptionHandler，用于处理全局异常（包括自定义的APIException、SpringVaildtion 和其他组件抛出的异常），并返回封装好的CommonResult对象@ControllerAdvicepublic class GlobalExceptionHandler { @ResponseBody @ExceptionHandler(value = ApiException.class) public CommonResult&amp;lt;?&amp;gt; handleApiException(ApiException e) { return new CommonResult&amp;lt;&amp;gt;(e.getStatus(), e.getMessage(), null); } @ResponseBody @ExceptionHandler(value = DataAccessException.class) public CommonResult&amp;lt;?&amp;gt; handleException(DataAccessException e) { return new CommonResult&amp;lt;&amp;gt;(CustomStatusEnum.DATA_ACCESS_ERROR); } @ResponseBody @ExceptionHandler(value = AccessDeniedException.class) public CommonResult&amp;lt;?&amp;gt; handleException(AccessDeniedException e) { return new CommonResult&amp;lt;&amp;gt;(CustomStatusEnum.NOT_ALLOWED_TO_ACCESS_OTHER_USER_PATH); } /* @valid处理 form data方式调用接口校验失败抛出的异常*/ @ResponseBody @ExceptionHandler(BindException.class) public CommonResult&amp;lt;?&amp;gt; handleBindException(BindException e) { List&amp;lt;FieldError&amp;gt; fieldErrors = e.getBindingResult().getFieldErrors(); List&amp;lt;String&amp;gt; collect = fieldErrors.stream().map(o -&amp;gt; o.getDefaultMessage()).collect(Collectors.toList()); List&amp;lt;Map&amp;lt;?,?&amp;gt;&amp;gt; wrappedMessage = wrapParamValidationMessage(collect); return new CommonResult&amp;lt;&amp;gt;(CustomStatusEnum.PARAM_VALIDATE_ERROR.getStatus(), CustomStatusEnum.PARAM_VALIDATE_ERROR.getMessage(), wrappedMessage); } // @valid处理 json 请求体调用接口校验失败抛出的异常 @ResponseBody @ExceptionHandler(MethodArgumentNotValidException.class) public CommonResult&amp;lt;?&amp;gt; methodArgumentNotValidExceptionHandler(MethodArgumentNotValidException e) { return handleBindException(e); } // @valid处理单个参数校验失败抛出的异常 @ResponseBody @ExceptionHandler(ConstraintViolationException.class) public CommonResult&amp;lt;?&amp;gt; constraintViolationExceptionHandler(ConstraintViolationException e) { Set&amp;lt;ConstraintViolation&amp;lt;?&amp;gt;&amp;gt; constraintViolations = e.getConstraintViolations(); List&amp;lt;String&amp;gt; collect = constraintViolations.stream().map(o -&amp;gt; o.getMessage()).collect(Collectors.toList()); List&amp;lt;Map&amp;lt;?,?&amp;gt;&amp;gt; wrappedMessage = wrapParamValidationMessage(collect); return new CommonResult&amp;lt;&amp;gt;(CustomStatusEnum.PARAM_VALIDATE_ERROR.getStatus(), CustomStatusEnum.PARAM_VALIDATE_ERROR.getMessage(), wrappedMessage); } /*git相关异常*/ @ResponseBody @ExceptionHandler(GitAPIException.class) public CommonResult&amp;lt;?&amp;gt; GitAPIExceptionHandler(GitAPIException e) { return new CommonResult&amp;lt;&amp;gt;(CustomStatusEnum.GIT_ERROR); } /*文件读写异常*/ @ResponseBody @ExceptionHandler(IOException.class) public CommonResult&amp;lt;?&amp;gt; IOExceptionHandler(IOException e) { return new CommonResult&amp;lt;&amp;gt;(CustomStatusEnum.IO_ERROR); } /*JWT过期异常*/ @ResponseBody @ExceptionHandler(ExpiredJwtException.class) public CommonResult&amp;lt;?&amp;gt; ExpiredJwtExceptionHandler(ExpiredJwtException e) { return new CommonResult&amp;lt;&amp;gt;(CustomStatusEnum.JWT_EXPIRED); } /*JWT过期异常*/ @ResponseBody @ExceptionHandler(IllegalArgumentException.class) public CommonResult&amp;lt;?&amp;gt; IllegalArgumentExceptionHandler(IllegalArgumentException e) { return new CommonResult&amp;lt;&amp;gt;(CustomStatusEnum.JWT_EXPIRED); } //其他的异常 @ResponseBody @ExceptionHandler(value = Exception.class) public CommonResult&amp;lt;?&amp;gt; handleException(Exception e) { return new CommonResult&amp;lt;&amp;gt;(CustomStatusEnum.INTERNAL_ERROR.getStatus(), CustomStatusEnum.INTERNAL_ERROR.getMessage()+e.getClass()+e.getMessage()+e.getCause(), null); } private List&amp;lt;Map&amp;lt;?,?&amp;gt;&amp;gt; wrapParamValidationMessage(List&amp;lt;String&amp;gt; collect){ List&amp;lt;Map&amp;lt;?,?&amp;gt;&amp;gt; wrappedMessage = new ArrayList&amp;lt;&amp;gt;(); for (String s : collect) { Map&amp;lt;String, String&amp;gt; Messages = new HashMap&amp;lt;&amp;gt;(); Messages.put(&quot;validateMessage&quot;, s); wrappedMessage.add(Messages); } return wrappedMessage; }}CustomStatusEnum为了抛出异常的代码简洁性和接口状态的解耦，我们还可以使用Java枚举类来定义整个系统中所有的业务异常同时确定接口状态码的含义public enum CustomStatusEnum { //请求正常 REQUEST_DONE(1000, &quot;请求完成&quot;), LOGIN_SUCCESS(1001, &quot;登录成功&quot;), SIGN_UP_SUCCESS(1002,&quot;注册成功&quot;), // 底层异常 INTERNAL_ERROR(9999,&quot;内部错误:&quot;), DATA_ACCESS_ERROR(10001,&quot;数据访问错误&quot;), NO_AUTH_FOR_STORAGE(10002,&quot;文件存取路径无权限访问&quot;), IO_ERROR(10003,&quot;文件存取服务异常&quot;), GIT_ERROR(10004,&quot;版本控制服务异常&quot;), ARGUMENT_ERROR(10005,&quot;请求参数有误&quot;), //用户相关异常 USERNAME_EXIST(20001,&quot;注册失败，用户名已被使用&quot;), EMAIL_EXIST(20002,&quot;注册失败，邮箱已被使用&quot;), PASSWORD_TO_SIMPLE(20003,&quot;注册失败，密码长度小于8位&quot;), LOGIN_FAIL(20010,&quot;登录失败，密码或用户名错误&quot;), NOT_LOGIN(20011,&quot;未登录情况下无法访问或访问方法错误&quot;), NO_PERMISSION(20012,&quot;当前登录用户无权访问此内容或访问方法错误&quot;), NOT_ALLOWED_TO_ACCESS_OTHER_USER_PATH(20013,&quot;无权访问其他用户的内容&quot;), JWT_EXPIRED(20014, &quot;登录状态过期&quot;), //JWT登录过期 WX_NOT_BIND(20015,&quot;微信OpenID未绑定&quot;), WX_OPENID_UNREACHABLE(20016,&quot;微信OpenID无法获取&quot;), WX_OPENID_ALREADY_BIND(20017,&quot;微信OpenID已有绑定账户，无法绑定多个&quot;), //实体属性校验 PARAM_VALIDATE_ERROR(20020,&quot;参数格式不符合&quot;), //仓库相关异常 REPO_EXIST(30001,&quot;笔记夹已存在&quot;), //仓库已存在 CHANGE_REPO_NAME_EXIST(30002,&quot;修改的笔记本夹名已被使用&quot;),//要修改仓库名已被使用 CHANGE_REPO_NAME_NOT_BLANK(30003,&quot;修改的笔记本夹名不能为空白&quot;), USER_REPO_NOT_EXIST(30004,&quot;当前用户空间下无此笔记本夹&quot;), No_COMMIT_IN_THIS_BRANCH(30004, &quot;当前尚未有文件提交记录&quot;), //文档相关异常 NOTE_NOT_EXIST(40001,&quot;文档不存在&quot;), NOTE_EXISTED_IN_REPO(40002,&quot;此文件夹内已有同名笔记&quot;), NOTE_RENAME_FAIL(40003,&quot;笔记重命名失败，请稍后再试&quot;) ; private final Integer status; private final String message; CustomStatusEnum(Integer status, String message) { this.status = status; this.message = message; } public Integer getStatus() { return status; } public String getMessage() { return message; }}异常抛出示例一下即为验证一个Note资源是否存在的验证方法，当有用户或Note不存在时直接调用 Asserts.fail()方法抛出异常，异常会被自动捕获封装消息后通过API返回 public boolean isUserHasOwnership(int userId, int repoId, int noteId) throws IOException { Repo repo = repoService.getRepoById(repoId); Note note = noteService.getANote(noteId); if (repo == null) { Asserts.fail(CustomStatusEnum.USER_REPO_NOT_EXIST); } if (note == null) { Asserts.fail(CustomStatusEnum.NOTE_NOT_EXIST); } return userInfoTool.currentUser().getId() == userId &amp;amp;&amp;amp; userInfoTool.currentUser().getId() == repo.getUser().getId() &amp;amp;&amp;amp; userInfoTool.currentUser().getId() == note.getUser().getId(); }若请求Note不存在，这结果如下{ &quot;status&quot;: 30004, &quot;message&quot;: &quot;当前用户空间下无此笔记本夹&quot;, &quot;resultBody&quot;: null}" }, { "title": "在 SpringBoot 中实现统一API返回格式", "url": "/posts/common-api-result-in-springboot/", "categories": "Software Development", "tags": "Java, Spring, DevDairy", "date": "2021-03-07 12:42:00 +0800", "snippet": "实现思路在前后端分离大行其道的今天，有一个统一的返回值格式不仅能使我们的接口看起来更漂亮，而且还可以使前端可以统一处理很多东西，避免很多问题的产生。具体的实现思路为设计设计一个封装类用其一个泛型成员变量对原本返回的数据进行封装，同时提供API对请求的执行状况和消息示例代码CommonResult返回格式封装类public final class CommonResult&amp;lt;T&amp;gt; { private int status; private String message; private T resultBody; public CommonResult() { } public CommonResult(T resultBody) { this.status = CustomStatusEnum.REQUEST_DONE.getStatus(); this.message = CustomStatusEnum.REQUEST_DONE.getMessage(); this.resultBody = resultBody; } public CommonResult(int status, String message, T resultBody) { this.status = status; this.message = message; this.resultBody = resultBody; } public CommonResult(CustomStatusEnum customStatusEnum) { this.status = customStatusEnum.getStatus(); this.message = customStatusEnum.getMessage(); } //... getters &amp;amp; setters}假设最原始的接口如下： @GetMapping(&quot;/test&quot;) public User test() { return new User(); }当我们需要统一返回值时，可能会使用这样一个办法： @GetMapping(&quot;/test&quot;) public Result test() { return Result.success(new User()); }这个方法确实达到了统一接口返回值的目的，但是却有几个新问题诞生了： 接口返回值不明显，不能一眼看出来该接口的返回值。 每一个接口都需要增加额外的代码量。UnifiedReturnConfig所幸Spring Boot已经为我们提供了更好的解决办法，只需要在项目中加上以下代码，就可以无感知的为我们统一全局返回值。@EnableWebMvc@Configurationpublic class UnifiedReturnConfig { @RestControllerAdvice static class ResultResponseAdvice implements ResponseBodyAdvice&amp;lt;Object&amp;gt; { @Override public boolean supports(MethodParameter methodParameter, Class&amp;lt;? extends HttpMessageConverter&amp;lt;?&amp;gt;&amp;gt; aClass) { return true; } @Override public Object beforeBodyWrite(Object body, MethodParameter methodParameter, MediaType mediaType, Class&amp;lt;? extends HttpMessageConverter&amp;lt;?&amp;gt;&amp;gt; aClass, ServerHttpRequest serverHttpRequest, ServerHttpResponse serverHttpResponse) { /*文件下载不使用统一Json返回格式*/ if (serverHttpResponse.getHeaders().get(&quot;Content-Disposition&quot;) != null){ return body; } if (body instanceof CommonResult) { return body; } return new CommonResult&amp;lt;&amp;gt;(body); } }}而我们的接口只需要写成最原始的样子就行了。" }, { "title": "Spring AOP 的切点表达式", "url": "/posts/spring-aop-pointcut-designators/", "categories": "Software Development", "tags": "Java, Spring", "date": "2021-03-05 19:46:00 +0800", "snippet": "PCD(pointcut designators) 就是SpringAOP的切点表达式。SpringAOP的PCD是完全兼容AspectJ的，一共有10种。SpringAOP 是基于动态代理实现的，以下以目标对象表示被代理bean，代理对象表示AOP构建出来的bean。目标方法表示被代理的方法。executionexecution是最常用的PCD。它的匹配式模板如下展示:execution(modifiers-pattern? ret-type-pattern declaring-type-pattern? name-pattern(param-pattern) throws-pattern?)execution(修饰符匹配式? 返回类型匹配式 类名匹配式? 方法名匹配式(参数匹配式) 异常匹配式?)代码块中带?符号的匹配式都是可选的，对于execution PCD必不可少的只有三个: 返回值匹配值 方法名匹配式 参数匹配式举例分析: execution(public * ServiceDemo.(..)) 匹配public修饰符，返回值是,即任意返回值类型都行，ServiceDemo是类名匹配式不一定要全路径，只要全局依可见性唯一就行，.*是方法名匹配式，匹配所有方法，..是参数匹配式，匹配任意数量、任意类型参数的方法。再举一些其他例子: execution(* com.xyz.service...(..)): 匹配com.xyz.service及其子包下的任意方法。 execution(* joke(Object+))):匹配任意名字为joke的方法，且其动态入参是是Object类型或该类的子类。 execution(* joke(String,..)):匹配任意名字为joke的方法，该方法 一个入参为String(不可以为子类)，后面可以有任意个入参且入参类型不限 execution(* com...Dao.find*(..)): 匹配指定包下find开头的方法 execution(* com.baobaotao.Waiter+.*(..)) : 匹配com.baobaotao包下Waiter及其子类的所有方法。within筛选出某包下的所有类，注意要带有*。 within(com.xyz.service.*)com.xyz.service包下的类，不包括子包 within(com.xyz.service..*)com.xyz.service包下及其子包下的类this常用于命名绑定模式。对由代理对象的类型进行过滤筛选。如果目标类是基于接口实现的，则this()中可以填该接口的全路径名，否则非接口实现由于是基于CGLIB实现的，this中可以填写目标类的全路径名。this(com.xyz.service.AccountService): 代理类是com.xyz.service.AccountService或其子类。使用@EnableAspectJAutoProxy(proxyTargetClass = true)可以强制使用CGLIB。否则默认首先使用jdk动态代理，jdk代理不了才会用CGLIB。targetthis作用于代理对象，target作用于目标对象。target(com.xyz.service.AccountService): 被代理类(目标对象)是com.xyz.service.AccountService或其子类args常用于对目标方法的参数匹配。一般不单独使用，而是配合其他PCD来使用。args可以使用命名绑定模式，如下举例:@Aspect // 切面声明@Component // 注入IOC@Slf4jclass AspectDemo { @Around(&quot;within(per.aop.*) &amp;amp;&amp;amp; args(str)&quot;) // 在per.aop包下，且被代理方法的只有一个参数，参数类型是String或者其子类 @SneakyThrows public Object logAspect(ProceedingJoinPoint pjp, String str) { String signature = pjp.getSignature().toString(); log.info(&quot;{} start,param={}&quot;, signature, pjp.getArgs()); Object res = pjp.proceed(); log.info(&quot;{} end&quot;, signature); return res; }} 如果args中是参数名，则配合切面(advice)方法的使用来确定要匹配的方法参数类型。 如果args中是类型，例如@Around(“within(per.aop.*) &amp;amp;&amp;amp; args(String)”)，则可以不必使用切面方法来确定类型，但此时也不能使用参数绑定了见下文了。 虽然args()支持+符号，但本省args()就支持子类通配。和带参数匹配execution区别举个例子: args(com.xgj.Waiter)等价于 execution(* *(com.xgj.Waiter+))。而且execution不能支持带参数的advice。@target使用场景举例: 当一个Service有多个子类时, 某些子类需要打日志，某些子类不需要打日志时可以如下处理(配合java多态):筛选出具有给定注解的被代理对象是对象不是类，@target是动态的。如下自定义一个注解LogAble://全限定名: annotation.LogAble@Target({ElementType.TYPE,ElementType.PARAMETER}) // 支持在方法参数、类上注@Retention(RetentionPolicy.RUNTIME)public @interface LogAble {}假如需要“注上了这个注解的所有类的的public方法“都打日志的话日志逻辑要自定义，可以如下这么写PCD，当然对应方法的bean要注入到SpringIOC容器中:@Around(&quot;@target(annotation.LogAble) &amp;amp;&amp;amp; execution(public * *.*(..))&quot;)// 自定义日志逻辑@args对于目标方法参数的运行时类型要有@args指定的注解。是方法参数的类型上有指定注解，不是方法参数上带注解。使用场景: 假如参数类型有多个子类，只有某个子类才可以匹配该PCD。 @args(com.ms.aop.jargs.demo1.Anno1): 匹配1个参数，且第1个参数运行时需要有Anno1注解 @args(com.ms.aop.jargs.demo1.Anno1,..)匹配一个或多个参数，第一个参数运行时需要带上Anno1注解。 @args(com.ms.aop.jargs.demo1.Anno1,com.ms.aop.jargs.demo1.Anno2): 一参匹配Anno1，二参匹配Annno2 。@within非运行时类型的的@target。@target关注的是被调用的对象，@within关注的是调用的方法所在的类。@target 和 @within 的不同点: @target(注解A)：判断被调用的目标对象中是否声明了注解A，如果有，会被拦截 @within(注解A)： 判断被调用的方法所属的类中是否声明了注解A，如果有，会被拦截@annotation匹配有指定注解的方法（注解作用在方法上面）bean根据beanNam来匹配。支持*通配符。bean(*Service) // 匹配所有Service结尾的Service组合使用PCD之间支持，&amp;amp;&amp;amp; || !三种运算符。上文示例中就使用了&amp;amp;&amp;amp; 运算符。||表示或(不是短路或)。!表示非。命名绑定模式上文中的@Around(“within(per.aop.*) &amp;amp;&amp;amp; args(str)”)示例就是使用了命名绑定模式，在PCD中写上变量名，在方法上对变量名的类型进行限定。@Around(&quot;within(per.aop.*) &amp;amp;&amp;amp; args(str)&quot;)public Object logAspect(ProceedingJoinPoint pjp, String str) { ...}如上举例，str要是String类型或其子类，且方法入参只能有一个。 命名绑定模式只支持target、this、args三种PCD。argNames观察源码可以发现，所有的Advice注解都带有argNames字段，例如@Around:@Retention(RetentionPolicy.RUNTIME)@Target({ElementType.METHOD})public @interface Around { String value(); String argNames() default &quot;&quot;;}什么情况下会使用这个属性呢，如下举例解释:@Around(value = &quot;execution(* TestBean.paramArgs(..)) &amp;amp;&amp;amp; args(decimal,str,..)&amp;amp;&amp;amp; target(bean)&quot;, argNames = &quot;pjp,str,decimal,bean&quot;)@SneakyThrows // proceed会抛受检异常Object aroundArgs(ProceedingJoinPoint pjp,/*使用命名绑定模式*/ String str, BigDecimal decimal, Object bean) { // 在方法执行前做一些操作 return pjp.proceed();}argnames 必须要和args、target、this标签一起使用。虽然实际操作中可以不带，但官方建议所有带参数的都带，原因如下:因此如果‘ argernames’属性没有指定，那么 Spring AOP 将查看类的调试信息，并尝试从局部变量表中确定参数名。只要使用调试信息(至少是‘-g: vars’)编译了类，就会出现此信息。使用这个标志编译的结果是: 你的代码将会更容易被反向工程 类文件大小将会非常大(通常是无关紧要的) 删除未使用的局部变量的优化将不会被编译器应用。此外，如果编译的代码没有必要的调试信息，那么 Spring AOP 将尝试推断绑定变量与参数的配对。如果变量的绑定在可用信息下是不明确的，那么一个 AmbiguousBindingException 就会被抛出。如果上面的策略都失败了，那么就会抛出一个 IllegalArgumentException。 建议所有的advice注解里都带argNames，反正idea也会提醒。" }, { "title": "Spring AOP 的使用方法", "url": "/posts/spring-aop-usage/", "categories": "Software Development", "tags": "Java, Spring, DevDairy", "date": "2021-03-05 18:19:00 +0800", "snippet": "Spring AOP 注解概述Spring 的 AOP 功能除了在配置文件中配置一大堆的配置，比如切入点、表达式、通知等等以外，使用注解的方式更为方便快捷，特别是 Spring boot 出现以后，基本不再使用原先的 beans.xml 等配置文件了，而都推荐注解编程。 注解 功能 @Aspect 切面声明，标注在类、接口（包括注解类型）或枚举上。 @Pointcut 切入点声明，即切入到哪些目标类的目标方法。value 属性指定切入点表达式，默认为 ““，用于被通知注解引用，样通知注解只需要关联此切入点声明即可，无需再重复写切入点表达式 @Before 前置通知, 在目标方法(切入点)执行之前执行。value 属性绑定通知的切入点表达式，可以关联切入点声明，也可以直接设置切入点表达式注意：如果在此回调方法中抛出异常，则目标方法不会再执行，会继续执行后置通知 -&amp;gt; 异常通知。 @After 后置通知, 在目标方法(切入点)执行之后执行 @AfterReturning 返回通知, 在目标方法(切入点)返回结果之后执行，在 @After 的后面执行pointcut 属性绑定通知的切入点表达式，优先级高于 value，默认为 “” @AfterThrowing 异常通知, 在方法抛出异常之后执行, 意味着跳过返回通知pointcut 属性绑定通知的切入点表达式，优先级高于 value，默认为 ““注意：如果目标方法自己 try-catch 了异常，而没有继续往外抛，则不会进入此回调函数 @Around 环绕通知：目标方法执行前后分别执行一些代码，类似拦截器，可以控制目标方法是否继续执行。通常用于统计方法耗时，参数校验等等操作。环绕通知早于前置通知，晚于返回通知。 对于习惯了 Spring 全家桶编程的人来说，并不是需要直接引入 aspectjweaver 依赖，因为 spring-boot-starter-aop 组件默认已经引用了 aspectjweaver 来实现 AOP 功能。换句话说 Spring 的 AOP 功能就是依赖的 aspectjweaver ！&amp;lt;!-- https://mvnrepository.com/artifact/org.springframework.boot/spring-boot-starter-aop --&amp;gt;&amp;lt;dependency&amp;gt; &amp;lt;groupId&amp;gt;org.springframework.boot&amp;lt;/groupId&amp;gt; &amp;lt;artifactId&amp;gt;spring-boot-starter-aop&amp;lt;/artifactId&amp;gt; &amp;lt;version&amp;gt;2.1.4.RELEASE&amp;lt;/version&amp;gt;&amp;lt;/dependency&amp;gt;@Aspect 快速入门@Aspect 常见用于记录日志、异常集中处理、权限验证、Web 参数校验、事务处理等等要想把一个类变成切面类，只需3步： 在类上使用 @Aspect 注解使之成为切面类 切面类需要交由 Sprign 容器管理，所以类上还需要有 @Service、@Repository、@Controller、@Component 等注解 在切面类中自定义方法接收通知/** * 1、@Aspect：声明本类为切面类 * 2、@Component：将本类交由 Spring 容器管理 * 3、@Order：指定切入执行顺序，数值越小，切面执行顺序越靠前，默认为 Integer.MAX_VALUE */@Aspect@Order(value = 999)@Componentpublic class AspectHelloWorld { private static final Logger LOG = LoggerFactory.getLogger(AspectHelloWorld.class); /** * @Pointcut ：切入点声明，即切入到哪些目标方法。value 属性指定切入点表达式，默认为 &quot;&quot;。 * 用于被下面的通知注解引用，这样通知注解只需要关联此切入点声明即可，无需再重复写切入点表达式 * &amp;lt;p&amp;gt; * 切入点表达式常用格式举例如下： * - * com.wmx.aspect.EmpService.*(..))：表示 com.wmx.aspect.EmpService 类中的任意方法 * - * com.wmx.aspect.*.*(..))：表示 com.wmx.aspect 包(不含子包)下任意类中的任意方法 * - * com.wmx.aspect..*.*(..))：表示 com.wmx.aspect 包及其子包下任意类中的任意方法 * &amp;lt;/p&amp;gt; * value 的 execution 可以有多个，使用 || 隔开. */ @Pointcut(value = &quot;execution(* com.wmx.hb.controller.DeptController.*(..)) &quot; + &quot;|| execution(* com.wmx.hb.controller.EmpController.*(..))&quot;) private void aspectPointcut() { } /** * 前置通知：目标方法执行之前执行以下方法体的内容。 * value：绑定通知的切入点表达式。可以关联切入点声明，也可以直接设置切入点表达式 * &amp;lt;br/&amp;gt; * * @param joinPoint：提供对连接点处可用状态和有关它的静态信息的反射访问&amp;lt;br/&amp;gt; &amp;lt;p&amp;gt; * * * Object[] getArgs()：返回此连接点处（目标方法）的参数，目标方法无参数时，返回空数组 * * * Signature getSignature()：返回连接点处的签名。 * * * Object getTarget()：返回目标对象 * * * Object getThis()：返回当前正在执行的对象 * * * StaticPart getStaticPart()：返回一个封装此连接点的静态部分的对象。 * * * SourceLocation getSourceLocation()：返回与连接点对应的源位置 * * * String toLongString()：返回连接点的扩展字符串表示形式。 * * * String toShortString()：返回连接点的缩写字符串表示形式。 * * * String getKind()：返回表示连接点类型的字符串 * * * &amp;lt;/p&amp;gt; */ @Before(value = &quot;aspectPointcut()&quot;) public void aspectBefore(JoinPoint joinPoint) { Object[] args = joinPoint.getArgs(); Signature signature = joinPoint.getSignature(); Object target = joinPoint.getTarget(); Object aThis = joinPoint.getThis(); JoinPoint.StaticPart staticPart = joinPoint.getStaticPart(); SourceLocation sourceLocation = joinPoint.getSourceLocation(); String longString = joinPoint.toLongString(); String shortString = joinPoint.toShortString(); LOG.debug(&quot;【前置通知】&quot; + &quot;args={},signature={},target={},aThis={},staticPart={},&quot; + &quot;sourceLocation={},longString={},shortString={}&quot; , Arrays.asList(args), signature, target, aThis, staticPart, sourceLocation, longString, shortString); } /** * 后置通知：目标方法执行之后执行以下方法体的内容，不管目标方法是否发生异常。 * value：绑定通知的切入点表达式。可以关联切入点声明，也可以直接设置切入点表达式 */ @After(value = &quot;aspectPointcut()&quot;) public void aspectAfter(JoinPoint joinPoint) { LOG.debug(&quot;【后置通知】kind={}&quot;, joinPoint.getKind()); } /** * 返回通知：目标方法返回后执行以下代码 * value 属性：绑定通知的切入点表达式。可以关联切入点声明，也可以直接设置切入点表达式 * pointcut 属性：绑定通知的切入点表达式，优先级高于 value，默认为 &quot;&quot; * returning 属性：通知签名中要将返回值绑定到的参数的名称，默认为 &quot;&quot; * * @param joinPoint ：提供对连接点处可用状态和有关它的静态信息的反射访问 * @param result ：目标方法返回的值，参数名称与 returning 属性值一致。无返回值时，这里 result 会为 null. */ @AfterReturning(pointcut = &quot;aspectPointcut()&quot;, returning = &quot;result&quot;) public void aspectAfterReturning(JoinPoint joinPoint, Object result) { LOG.debug(&quot;【返回通知】,shortString={},result=&quot;, joinPoint.toShortString(), result); } /** * 异常通知：目标方法发生异常的时候执行以下代码，此时返回通知不会再触发 * value 属性：绑定通知的切入点表达式。可以关联切入点声明，也可以直接设置切入点表达式 * pointcut 属性：绑定通知的切入点表达式，优先级高于 value，默认为 &quot;&quot; * throwing 属性：与方法中的异常参数名称一致， * * @param ex：捕获的异常对象，名称与 throwing 属性值一致 */ @AfterThrowing(pointcut = &quot;aspectPointcut()&quot;, throwing = &quot;ex&quot;) public void aspectAfterThrowing(JoinPoint jp, Exception ex) { String methodName = jp.getSignature().getName(); if (ex instanceof ArithmeticException) { LOG.error(&quot;【异常通知】&quot; + methodName + &quot;方法算术异常（ArithmeticException）：&quot; + ex.getMessage()); } else { LOG.error(&quot;【异常通知】&quot; + methodName + &quot;方法异常：&quot; + ex.getMessage()); } } /** * 环绕通知 * 1、@Around 的 value 属性：绑定通知的切入点表达式。可以关联切入点声明，也可以直接设置切入点表达式 * 2、Object ProceedingJoinPoint.proceed(Object[] args) 方法：继续下一个通知或目标方法调用，返回处理结果，如果目标方法发生异常，则 proceed 会抛异常. * 3、假如目标方法是控制层接口，则本方法的异常捕获与否都不会影响目标方法的事务回滚 * 4、假如目标方法是控制层接口，本方法 try-catch 了异常后没有继续往外抛，则全局异常处理 @RestControllerAdvice 中不会再触发 * * @param joinPoint * @return * @throws Throwable */ @Around(value = &quot;aspectPointcut()&quot;) public Object handleControllerMethod(ProceedingJoinPoint joinPoint) throws Throwable { this.checkRequestParam(joinPoint); StopWatch stopWatch = StopWatch.createStarted(); LOG.debug(&quot;【环绕通知】执行接口开始，方法={}，参数={} &quot;, joinPoint.getSignature(), Arrays.asList(joinPoint.getArgs()).toString()); //继续下一个通知或目标方法调用，返回处理结果，如果目标方法发生异常，则 proceed 会抛异常. //如果在调用目标方法或者下一个切面通知前抛出异常，则不会再继续往后走. Object proceed = joinPoint.proceed(joinPoint.getArgs()); stopWatch.stop(); long watchTime = stopWatch.getTime(); LOG.debug(&quot;【环绕通知】执行接口结束，方法={}, 返回值={},耗时={} (毫秒)&quot;, joinPoint.getSignature(), proceed, watchTime); return proceed; } /** * 参数校验，防止 SQL 注入 * * @param joinPoint */ private void checkRequestParam(ProceedingJoinPoint joinPoint) { Object[] args = joinPoint.getArgs(); if (args == null || args.length &amp;lt;= 0) { return; } String params = Arrays.toString(joinPoint.getArgs()).toUpperCase(); String[] keywords = {&quot;DELETE &quot;, &quot;UPDATE &quot;, &quot;SELECT &quot;, &quot;INSERT &quot;, &quot;SET &quot;, &quot;SUBSTR(&quot;, &quot;COUNT(&quot;, &quot;DROP &quot;, &quot;TRUNCATE &quot;, &quot;INTO &quot;, &quot;DECLARE &quot;, &quot;EXEC &quot;, &quot;EXECUTE &quot;, &quot; AND &quot;, &quot; OR &quot;, &quot;--&quot;}; for (String keyword : keywords) { if (params.contains(keyword)) { LOG.warn(&quot;参数存在SQL注入风险，其中包含非法字符 {}.&quot;, keyword); throw new RuntimeException(&quot;参数存在SQL注入风险：params=&quot; + params); } } }}execution 切点表达式@Pointcut 切入点声明注解，以及所有的通知注解都可以通过 value 属性或者 pointcut 属性指定切入点表达式。2、切入点表达式通过 execution 函数匹配连接点，语法：execution([方法修饰符] 返回类型 包名.类名.方法名(参数类型) [异常类型]) 访问修饰符可以省略； 返回值类型、包名、类名、方法名可以使用星号*代表任意； 包名与类名之间一个点.代表当前包下的类，两个点..表示当前包及其子包下的类; 参数列表可以使用两个点..表示任意个数，任意类型的参数列表;3、切入点表达式的写法比较灵活，比如：* 号表示任意一个，.. 表示任意多个，还可以使用 &amp;amp;&amp;amp;、||、! 进行逻辑运算，不过实际开发中通常用不到那么多花里胡哨的，掌握以下几种就基本够用了。切入点表达式常用举例 execution(* com.wmx.aspect.EmpServiceImpl.findEmpById(Integer)) 匹配 com.wmx.aspect.EmpService 类中的 findEmpById 方法，且带有一个 Integer 类型参数。 execution(* com.wmx.aspect.EmpServiceImpl.findEmpById(*)) 匹配 com.wmx.aspect.EmpService 类中的 findEmpById 方法，且带有一个任意类型参数。 execution(* com.wmx.aspect.EmpServiceImpl.findEmpById(..)) 匹配 com.wmx.aspect.EmpService 类中的 findEmpById 方法，参数不限。 execution(* grp.basic3.se.service.SEBasAgencyService3.editAgencyInfo(..)) || execution(* grp.basic3.se.service.SEBasAgencyService3.adjustAgencyInfo(..)) 匹配 editAgencyInfo 方法或者 adjustAgencyInfo 方法 execution(* com.wmx.aspect.EmpService.*(..)) 匹配 com.wmx.aspect.EmpService 类中的任意方法 execution(* com.wmx.aspect.*.*(..)) 匹配 com.wmx.aspect 包(不含子包)下任意类中的任意方法 execution(* com.wmx.aspect..*.*(..)) 匹配 com.wmx.aspect 包及其子包下任意类中的任意方法 execution(* grp.pm..*Controller.*(..)) 匹配 grp.pm 包下任意子孙包中以 “Controller” 结尾的类中的所有方法 完整 Spring AOP 切点表达式：Spring AOP 的切点表达式" }, { "title": "优雅的使用Spring Validation实现业务参数校验", "url": "/posts/spring-validation-usage/", "categories": "Software Development", "tags": "Java, Spring, DevDairy", "date": "2021-03-03 17:11:00 +0800", "snippet": "前言在平时写controller时候，都需要对请求参数进行后端校验，一般写法如下：public String add(user user) { if(user.getAge() == null){ return &quot;年龄不能为空&quot;; } if(user.getAge() &amp;gt; 120){ return &quot;年龄不能超过120&quot;; } if(user.getName().isEmpty()){ return &quot;用户名不能为空&quot;; } // 省略一堆参数校验... return &quot;Done&quot;;}业务代码还没开始写呢，光参数校验就写了一堆判断。这样写虽然没什么错，但是给人的感觉就是：不优雅😅,其实SpringBoot提供整合了参数校验解决方案spring-boot-starter-validation依赖配置第一步就很简单了，直接在 pom.xml 中引入依赖就行：&amp;lt;!--校验组件--&amp;gt;&amp;lt;dependency&amp;gt; &amp;lt;groupId&amp;gt;org.springframework.boot&amp;lt;/groupId&amp;gt; &amp;lt;artifactId&amp;gt;spring-boot-starter-validation&amp;lt;/artifactId&amp;gt;&amp;lt;/dependency&amp;gt;&amp;lt;!--web组件--&amp;gt;&amp;lt;dependency&amp;gt; &amp;lt;groupId&amp;gt;org.springframework.boot&amp;lt;/groupId&amp;gt; &amp;lt;artifactId&amp;gt;spring-boot-starter-web&amp;lt;/artifactId&amp;gt;&amp;lt;/dependency&amp;gt; 其中 Springboot-2.3 之前的版本只需要引入 web 依赖就可以了。Vildation的简单使用Spring Validation 内置校验注解 注解 校验功能 @AssertFalse 必须是false @AssertTrue 必须是true @DecimalMax 小于等于给定的值 @DecimalMin 大于等于给定的值 @Digits 可设定最大整数位数和最大小数位数 @Email 校验是否符合Email格式 @Future 必须是将来的时间 @FutureOrPresent 当前或将来时间 @Max 最大值 @Min 最小值 @Negative 负数（不包括0） @NegativeOrZero 负数或0 @NotBlank 不为null并且包含至少一个非空白字符 @NotEmpty 不为null并且不为空 @NotNull 不为null @Null 为null @Past 必须是过去的时间 @PastOrPresent 必须是过去的时间，包含现在 @Pattern 必须满足正则表达式 @PositiveOrZero 正数或0 @Size 校验容器的元素个数 单个参数校验在上面的基础上只需要在对象参数前面加上@Validated注解，然后在需要校验的对象参数的属性上面加上@NotNull，@NotEmpty之类参数校验注解就行了@Validated@GetMapping(&quot;/home&quot;)public class ProductController { public Result index(@NotBlank String name, @Email @NotBlank String email) { return ResultResponse.success(); }} 对象参数校验在上面的基础上只需要在对象参数前面加上@Validated注解，然后在需要校验的对象参数的属性上面加上@NotNull，@NotEmpty之类参数校验注解就行了public class user { @NotNull(message = &quot;age 不能为空&quot;) //校验提示信息 private Integer age;}验证消息返回直接获取验证结果然后在 Controller 方法中添加 @Validated 和用于接收错误信息的 BindingResult 就可以了，于是有了Ver1：public String add1(@Validated user user, BindingResult result) { List&amp;lt;FieldError&amp;gt; fieldErrors = result.getFieldErrors(); if(!fieldErrors.isEmpty()){ return fieldErrors.get(0).getDefaultMessage(); } return &quot;OK&quot;;}通过工具(Postman 或者 IDEA 插件 RestfulToolKit )去请求接口，如果参数不符合规则，会将相应的 message 信息返回age 不能为空规范返回值待校验参数多了之后我们希望一次返回所有校验失败信息，方便接口调用方进行调整，这就需要统一返回格式，常见的就是封装一个结果类public class ResultInfo&amp;lt;T&amp;gt;{ private Integer status; private String message; private T response; // 省略其他代码...}改造一下 Controller 方法，Ver2public ResultInfo add2(@Validated user user, BindingResult result) { List&amp;lt;FieldError&amp;gt; fieldErrors = result.getFieldErrors(); List&amp;lt;String&amp;gt; collect = fieldErrors.stream() .map(o -&amp;gt; o.getDefaultMessage()) .collect(Collectors.toList()); return new ResultInfo&amp;lt;&amp;gt;().success(400,&quot;请求参数错误&quot;,collect);}请求该方法时，所有的错误参数就都返回了：{ &quot;status&quot;: 400, &quot;message&quot;: &quot;请求参数错误&quot;, &quot;response&quot;: [ &quot;年龄必须在[1,120]之间&quot;, &quot;bg 字段的整数位最多为3位，小数位最多为1位&quot;, &quot;name 不能为空&quot;, &quot;email 格式错误&quot; ]}全局异常处理每个 Controller 方法中如果都写一遍 BindingResult 信息的处理，使用起来还是很繁琐。可以通过全局异常处理的方式统一处理校验异常。当我们写了 @validated 注解，不写 BindingResult 的时候，Spring 就会抛出异常。由此，可以写一个全局异常处理类来统一处理这种校验异常，从而免去重复组织异常信息的代码。全局异常处理类只需要在类上标注 @RestControllerAdvice，并在处理相应异常的方法上使用 @ExceptionHandler 注解，写明处理哪个异常即可@RestControllerAdvicepublic class GlobalControllerAdvice { private static final String BAD_REQUEST_MSG = &quot;客户端请求参数错误&quot;; // &amp;lt;1&amp;gt; 处理 form data方式调用接口校验失败抛出的异常 @ExceptionHandler(BindException.class) public ResultInfo bindExceptionHandler(BindException e) { List&amp;lt;FieldError&amp;gt; fieldErrors = e.getBindingResult().getFieldErrors(); List&amp;lt;String&amp;gt; collect = fieldErrors.stream() .map(o -&amp;gt; o.getDefaultMessage()) .collect(Collectors.toList()); return new ResultInfo().success(HttpStatus.BAD_REQUEST.value(), BAD_REQUEST_MSG, collect); } // &amp;lt;2&amp;gt; 处理 json 请求体调用接口校验失败抛出的异常 @ExceptionHandler(MethodArgumentNotValidException.class) public ResultInfo methodArgumentNotValidExceptionHandler(MethodArgumentNotValidException e) { List&amp;lt;FieldError&amp;gt; fieldErrors = e.getBindingResult().getFieldErrors(); List&amp;lt;String&amp;gt; collect = fieldErrors.stream() .map(o -&amp;gt; o.getDefaultMessage()) .collect(Collectors.toList()); return new ResultInfo().success(HttpStatus.BAD_REQUEST.value(), BAD_REQUEST_MSG, collect); } // &amp;lt;3&amp;gt; 处理单个参数校验失败抛出的异常 @ExceptionHandler(ConstraintViolationException.class) public ResultInfo constraintViolationExceptionHandler(ConstraintViolationException e) { Set&amp;lt;ConstraintViolation&amp;lt;?&amp;gt;&amp;gt; constraintViolations = e.getConstraintViolations(); List&amp;lt;String&amp;gt; collect = constraintViolations.stream() .map(o -&amp;gt; o.getMessage()) .collect(Collectors.toList()); return new ResultInfo().success(HttpStatus.BAD_REQUEST.value(), BAD_REQUEST_MSG, collect); }}事实上，在全局异常处理类中，我们可以写多个异常处理方法，这里总结了三种参数校验时可能引发的异常： 使用 form data 方式调用接口，校验异常抛出 BindException 使用 json 请求体调用接口，校验异常抛出 MethodArgumentNotValidException 单个参数校验异常抛出 ConstraintViolationException 注：单个参数校验需要在参数上增加校验注解，并在类上标注@Validated全局异常处理类可以添加各种需要处理的异常，比如添加一个对 Exception.class 的异常处理，当所有 ExceptionHandler 都无法处理时，由其记录异常信息，并返回友好提示分组校验如果同一个参数，需要在不同场景下应用不同的校验规则，就需要用到分组校验了。比如：新注册用户还没起名字，我们允许 name 字段为空，但是不允许将名字更新为空字符。分组校验有三个步骤： 定义一个分组类（或接口） 在校验注解上添加groups属性指定分组 Controller 方法的 @Validated 注解添加分组类public interface Update extends Default{}public class user { @NotBlank(message = &quot;name 不能为空&quot;,groups = Update.class) private String name; // 省略其他代码...}@PostMapping(&quot;update&quot;)public ResultInfo update(@Validated({Update.class}) user user) { return new ResultInfo().success(user);}细心的小伙伴可能已经注意到，自定义的 Update 分组接口继承了 Default 接口。校验注解(如：@NotBlank)和 @Validated 默认都属于 Default.class 分组，这一点在 javax.validation.groups.Default 注释中有说明/** * Default Jakarta Bean Validation group. * &amp;lt;p&amp;gt; * Unless a list of groups is explicitly defined: * &amp;lt;ul&amp;gt; * &amp;lt;li&amp;gt;constraints belong to the {@code Default} group&amp;lt;/li&amp;gt; * &amp;lt;li&amp;gt;validation applies to the {@code Default} group&amp;lt;/li&amp;gt; * &amp;lt;/ul&amp;gt; * Most structural constraints should belong to the default group. * * @author Emmanuel Bernard */public interface Default {}在编写 Update 分组接口时，如果继承了 Default，下面两个写法就是等效的： @Validated() @Validated({Update.class,Default.class})请求一下 /update 接口可以看到，不仅校验了 name 字段，也校验了其他默认属于 Default.class 分组的字段{ &quot;status&quot;: 400, &quot;message&quot;: &quot;客户端请求参数错误&quot;, &quot;response&quot;: [ &quot;name 不能为空&quot;, &quot;age 不能为空&quot;, &quot;email 不能为空&quot; ]}如果 Update 不继承 Default，@Validated({Update.class}) 就只会校验属于 Update.class 分组的参数字段，修改后再次请求该接口得到如下结果，可以看到， 其他字段没有参与校验{ &quot;status&quot;: 400, &quot;message&quot;: &quot;客户端请求参数错误&quot;, &quot;response&quot;: [ &quot;name 不能为空&quot; ]}递归校验如果 user 类中增加一个 OrderVO 类的属性，而 OrderVO 中的属性也需要校验，就用到递归校验了，只要在相应属性上增加 @Valid 注解即可实现（对于集合同样适用）OrderVO 类如下public class OrderVO { @NotNull private Long id; @NotBlank(message = &quot;itemName 不能为空&quot;) private String itemName; // 省略其他代码...}在 user 类中增加一个 OrderVO 类型的属性public class user { @NotBlank(message = &quot;name 不能为空&quot;,groups = Update.class) private String name; //需要递归校验的OrderVO @Valid private OrderVO orderVO; // 省略其他代码...} http://localhost:8080/user/addorderV0.id=1 &amp;amp;orderVO.itemName&amp;amp;age=1 &amp;amp;email=1@1{ &quot;status&quot;: 400, &quot;message&quot;: &quot;客户端请求参数错误&quot;, &quot;response&quot;: [ &quot;itemName 不能为空&quot; ]}自定义校验Spring 的 Validation 为我们提供了这么多特性，几乎可以满足日常开发中绝大多数参数校验场景了。但是，一个好的框架一定是方便扩展的。有了扩展能力，就能应对更多复杂的业务场景，毕竟在开发过程中，如果需求没变那一定是需求变了。Spring Validation 允许用户自定义校验，实现很简单，分两步： 自定义校验注解 编写校验者类 @Target({METHOD, FIELD, ANNOTATION_TYPE, CONSTRUCTOR, PARAMETER})@Retention(RUNTIME)@Documented@Constraint(validatedBy = {HaveNoBlankValidator.class})// 标明由哪个类执行校验逻辑public @interface HaveNoBlank { // 校验出错时默认返回的消息 String message() default &quot;字符串中不能含有空格&quot;; Class&amp;lt;?&amp;gt;[] groups() default { }; Class&amp;lt;? extends Payload&amp;gt;[] payload() default { }; /** * 同一个元素上指定多个该注解时使用 */ @Target({ METHOD, FIELD, ANNOTATION_TYPE, CONSTRUCTOR, PARAMETER, TYPE_USE }) @Retention(RUNTIME) @Documented public @interface List { NotBlank[] value(); }} public class HaveNoBlankValidator implements ConstraintValidator&amp;lt;HaveNoBlank, String&amp;gt; { @Override public boolean isValid(String value, ConstraintValidatorContext context) { // null 不做检验 if (value == null) { return true; } if (value.contains(&quot; &quot;)) { // 校验失败 return false; } // 校验成功 return true; }} 自定义校验注解使用起来和内置注解无异，在需要的字段上添加相应注解即可 " }, { "title": "SpringSecurity 集成JWT权限验证", "url": "/posts/spring-integrate-jwt-auth/", "categories": "Software Development", "tags": "Java, Spring, SpringSecurity, DevDairy", "date": "2021-03-01 22:46:00 +0800", "snippet": "一般来讲，对于RESTful API都会有认证(Authentication)和授权(Authorization)过程，保证API的安全性。Authentication指的是确定这个用户的身份，Authorization是确定该用户拥有什么操作权限。认证方式一般有三种 Basic Authentication这种方式是直接将用户名和密码放到Header中，使用Authorization: Basic ，使用最简单但是最不安全。 TOKEN认证这种方式也是再HTTP头中，使用Authorization: Bearer ，使用最广泛的TOKEN是JWT，通过签名过的TOKEN。 OAuth2.0这种方式安全等级最高，但是也是最复杂的。如果不是大型API平台或者需要给第三方APP使用的，没必要整这么复杂。一般项目中的RESTful API使用JWT来做认证就足够了。简要的说明下为什么用JWT，因为要实现完全的前后端分离以及多客户端平台的认证，所以不可能使用session，cookie的方式进行鉴权， 所以JWT就被派上了用场，可以通过一个加密密钥来进行前后端的鉴权。程序逻辑: 我们POST用户名与密码到/login进行登入，如果成功返回一个加密token，失败的话直接返回401错误。 之后用户访问每一个需要权限的网址请求必须在header中添加Authorization字段，例如Authorization: token，token为密钥。 后端对每个请求会进行token的校验，如果不通过直接返回401。SecurityConfigSpring Security 配置文件, 设置需要被保护的API，同时添加JWTFilter到Spring Security的认证链@Configuration@EnableWebSecuritypublic class SecurityConfig extends WebSecurityConfigurerAdapter { @Resource CustomEntryPoint customEntryPoint; @Resource private CustomAccessDeniedHandler customAccessDeniedHandler; @Override protected void configure(HttpSecurity http) throws Exception { http .csrf().disable() .authorizeRequests() .antMatchers(HttpMethod.POST, &quot;/api/login&quot;,&quot;/api/signUp&quot;,&quot;/&quot;).permitAll() .antMatchers(HttpMethod.GET, &quot;/&quot;).permitAll() .anyRequest().hasAuthority(&quot;ROLE_USER&quot;) .and() // 添加一个过滤器 所有访问 /login 的请求交给 JWTLoginFilter 来处理 这个类处理所有的JWT相关内容 .addFilterBefore(new JWTLoginFilter(&quot;/api/login&quot;, authenticationManager()), UsernamePasswordAuthenticationFilter.class) // 添加一个过滤器验证其他请求的Token是否合法 .addFilterBefore(new JWTAuthenticationFilter(), UsernamePasswordAuthenticationFilter.class) .exceptionHandling() .authenticationEntryPoint(customEntryPoint) .accessDeniedHandler(customAccessDeniedHandler); } @Override protected void configure(AuthenticationManagerBuilder auth) throws Exception { // 使用自定义身份验证组件 auth.authenticationProvider(new CustomAuthenticationProvider()); } @Bean public static PasswordEncoder passwordEncoder() { return NoOpPasswordEncoder.getInstance(); }}JWTLoginFilter验证登录请求并发放JWT Tokenclass JWTLoginFilter extends AbstractAuthenticationProcessingFilter { public JWTLoginFilter(String url, AuthenticationManager authManager) { super(new AntPathRequestMatcher(url)); setAuthenticationManager(authManager); } @Override public Authentication attemptAuthentication(HttpServletRequest req, HttpServletResponse res) throws AuthenticationException, IOException, ServletException { // JSON反序列化成 User User user = new ObjectMapper().readValue(req.getInputStream(), User.class); // 返回一个验证令牌 return getAuthenticationManager().authenticate( new UsernamePasswordAuthenticationToken( user.getUsername(), user.getPassword() ) ); } @Override protected void successfulAuthentication( HttpServletRequest req, HttpServletResponse res, FilterChain chain, Authentication auth) throws IOException, ServletException { TokenAuthenticationService.addAuthentication(res, auth.getName()); } @Override protected void unsuccessfulAuthentication(HttpServletRequest request, HttpServletResponse response, AuthenticationException failed) throws IOException, ServletException { response.setContentType(MediaType.APPLICATION_JSON_VALUE); response.setStatus(HttpStatus.OK.value()); response.setCharacterEncoding(&quot;UTF-8&quot;); response.getWriter().write(new ObjectMapper().writeValueAsString(new CommonResult&amp;lt;&amp;gt;(CustomStatusEnum.LOGIN_FAIL))); }}JWTAuthenticationFilter拦截分发所有和使用JWT认证的请求，同时调用TokenAuthenticationService.getAuthentication()方法进行认证public class JWTAuthenticationFilter extends GenericFilterBean { @Override public void doFilter(ServletRequest request, ServletResponse response, FilterChain filterChain) throws IOException, ServletException { Authentication authentication = TokenAuthenticationService .getAuthentication((HttpServletRequest) request); SecurityContextHolder.getContext() .setAuthentication(authentication); filterChain.doFilter(request, response); }}TokenAuthenticationService用于生成和验证JWT，为两个Filter提供服务class TokenAuthenticationService { static final long EXPIRATION_TIME = 432_000_000; // 5天 static final String SECRET = &quot;*****&quot;; // JWT密码 static final String TOKEN_PREFIX = &quot;Bearer&quot;; // Token前缀 static final String HEADER_STRING = &quot;Authorization&quot;;// 存放Token的Header Key // JWT生成方法 static void addAuthentication(HttpServletResponse response, String username) { // 生成JWT String JWT = Jwts.builder() // 保存权限（角色） .claim(&quot;authorities&quot;, &quot;ROLE_USER,AUTH_WRITE&quot;) // 用户名写入标题 .setSubject(username) // 有效期设置 .setExpiration(new Date(System.currentTimeMillis() + EXPIRATION_TIME)) // 签名设置 .signWith(SignatureAlgorithm.HS512, SECRET) .compact(); // 将 JWT 写入 body try { response.setContentType(MediaType.APPLICATION_JSON_VALUE); response.setStatus(HttpStatus.OK.value()); response.setCharacterEncoding(&quot;UTF-8&quot;); response.getWriter().write(new ObjectMapper().writeValueAsString(new CommonResult&amp;lt;&amp;gt;(CustomStatusEnum.LOGIN_SUCCESS.getStatus(), CustomStatusEnum.LOGIN_SUCCESS.getMessage(), JWT))); } catch (IOException e) { e.printStackTrace(); } } // JWT验证方法 static Authentication getAuthentication(HttpServletRequest request) { // 从Header中拿到token String token = request.getHeader(HEADER_STRING); if (token != null) { // 解析 Token Claims claims = Jwts.parser() // 验签 .setSigningKey(SECRET) // 去掉 Bearer .parseClaimsJws(token.replace(TOKEN_PREFIX, &quot;&quot;)) .getBody(); // 拿用户名 String user = claims.getSubject(); // 得到 权限（角色） List&amp;lt;GrantedAuthority&amp;gt; authorities = AuthorityUtils.commaSeparatedStringToAuthorityList((String) claims.get(&quot;authorities&quot;)); // 返回验证令牌 return user != null ? new UsernamePasswordAuthenticationToken(user, null, authorities) : null; } return null; }}" }, { "title": "SpringSecurity 使用方法", "url": "/posts/spring-security-usage/", "categories": "Software Development", "tags": "Java, Spring, SpringSecurity, DevDairy", "date": "2021-02-27 14:41:00 +0800", "snippet": "简介Spring Security 是一个相对复杂的安全管理框架，功能比 Shiro 更加强大，权限控制细粒度更高，对 OAuth 2 的支持也更友好。由于 Spring Security 源自 Spring 家族，因此可以和 Spring 框架无缝整合，特别是 Spring Boot 中提供的自动化配置方案，可以让 Spring Security 的使用更加便捷。依赖配置&amp;lt;dependency&amp;gt; &amp;lt;groupId&amp;gt;org.springframework.boot&amp;lt;/groupId&amp;gt; &amp;lt;artifactId&amp;gt;spring-boot-starter-security&amp;lt;/artifactId&amp;gt;&amp;lt;/dependency&amp;gt;基础用法首先在项目添加一个简单的API接口：@RestControllerpublic class HelloController { @GetMapping(&quot;/hello&quot;) public String hello() { return &quot;Welcome to Optimus-Xs.github.io&quot;; }}接着启动项目直接访问 /hello 接口则会自动跳转到登录页面，这时所有的API接口都被Spring Security保护了默认用户名是 user，而登录密码则在每次启动项目时随机生成，我们可以在项目启动日志中找到Spring Security 配置文件SecurityConfigSpring Security的配置类可以继承 WebSecurityConfigurerAdapter 来实现@Configuration@EnableWebSecurity@EnableGlobalMethodSecurity(prePostEnabled=true)public class SecurityConfig extends WebSecurityConfigurerAdapter { @Resource CustomEntryPoint customEntryPoint; @Resource private CustomAccessDeniedHandler customAccessDeniedHandler; private UserRepository userRepository; @Autowired public SecurityConfig( UserRepository userRepository) { this.userRepository = userRepository; } @Override protected void configure(HttpSecurity http) throws Exception { http .csrf().disable() .authorizeRequests() .antMatchers(HttpMethod.POST, &quot;/api/login&quot;,&quot;/api/signUp&quot;,&quot;/&quot;,&quot;/api/wxLogin&quot;).permitAll() .antMatchers(HttpMethod.GET, &quot;/&quot;).permitAll() .antMatchers(HttpMethod.OPTIONS, &quot;/**&quot;).permitAll() .anyRequest().hasAuthority(&quot;ROLE_USER&quot;) .and() // 添加一个过滤器 所有访问 /login 的请求交给 JWTLoginFilter 来处理 这个类处理所有的JWT相关内容 .addFilterBefore(new JWTLoginFilter(&quot;/api/login&quot;, authenticationManager(),userRepository), UsernamePasswordAuthenticationFilter.class) // 添加一个过滤器验证其他请求的Token是否合法 .addFilterBefore(new JWTAuthenticationFilter(), UsernamePasswordAuthenticationFilter.class) .exceptionHandling() .authenticationEntryPoint(customEntryPoint) .accessDeniedHandler(customAccessDeniedHandler); } @Override protected void configure(AuthenticationManagerBuilder auth) { // 使用自定义身份验证组件 auth.authenticationProvider(new CustomAuthenticationProvider()); } @Bean public static PasswordEncoder passwordEncoder() { return new BCryptPasswordEncoder(); }}此配置文件中包含选型： 除/api/login、/api/signUp、/api/wxLogin 所有登录注册相关API开放 Get访问主页根目录开放 所有Option请求开放，保证CORS的预请求能正常访问 使用自定义的身份认证组件，不使用SpringSecurity自动生成的简单认证，而让我们可以从数据库读取用户信息认证 添加两个Filter JWTLoginFilter 和 JWTAuthenticationFilter来处理JWT的颁发和验证 配置用户密码使用BCrypt单向加密算法 配置 CustomAccessDeniedHandler 自定义拦截器统一已通过身份验证但无权限的403返回格式（一个用户试图访问其他用户私有资源时） 配置 CustomEntryPoint 自定义拦截器统一未登录的403返回格式从数据库读取用户信息登录CustomAuthenticationProviderCustomAuthenticationProvider 是自定义身份认证验证组件，使SpringSecurity通过读取数据库的用户信息验证@Componentpublic class CustomAuthenticationProvider implements AuthenticationProvider { private NoteHubUserDetailsService noteHubUserDetailsService; private BCryptPasswordEncoder bCryptPasswordEncoder; private static CustomAuthenticationProvider customAuthenticationProvider; @PostConstruct //通过@PostConstruct实现初始化bean之前进行的操作 public void init() { customAuthenticationProvider = this; // 初使化时将已静态化的testService实例化 } @Autowired public void setNoteHubUserDetailsService(NoteHubUserDetailsService noteHubUserDetailsService, BCryptPasswordEncoder bCryptPasswordEncoder) { this.noteHubUserDetailsService = noteHubUserDetailsService; this.bCryptPasswordEncoder = bCryptPasswordEncoder; } @Override public Authentication authenticate(Authentication authentication) throws AuthenticationException { // 获取认证的用户名 &amp;amp; 密码 String name = authentication.getName(); String password = authentication.getCredentials().toString(); UserDetails userDetails = customAuthenticationProvider.noteHubUserDetailsService.loadUserByUsername(name); // 认证逻辑 if (customAuthenticationProvider.bCryptPasswordEncoder.matches(password,userDetails.getPassword())) { // 这里设置权限和角色 ArrayList&amp;lt;GrantedAuthority&amp;gt; authorities = new ArrayList&amp;lt;&amp;gt;(); authorities.add(new GrantedAuthorityImpl(&quot;ROLE_USER&quot;)); authorities.add(new GrantedAuthorityImpl(&quot;AUTH_WRITE&quot;)); // 生成令牌 return new UsernamePasswordAuthenticationToken(name, password, authorities); } else { throw new BadCredentialsException(&quot;密码错误~&quot;); } } // 是否可以提供输入类型的认证服务 @Override public boolean supports(Class&amp;lt;?&amp;gt; authentication) { return authentication.equals(UsernamePasswordAuthenticationToken.class); }}NoteHubUserDetailsServiceNoteHubUserDetailsService 用于从调用Service层的接口从数据库读取用户数据供CustomAuthenticationProvider使用@Service@Configurationpublic class NoteHubUserDetailsService implements UserDetailsService { private final UserService userService; @Autowired public NoteHubUserDetailsService(UserService userService) { this.userService = userService; } @Override public UserDetails loadUserByUsername(String username) throws UsernameNotFoundException { ml.notehub.core.model.entity.User user = userService.getUserByUsername(username); if (user == null) { throw new UsernameNotFoundException(&quot;用户不存在&quot;); } List&amp;lt;SimpleGrantedAuthority&amp;gt; authorities = new ArrayList&amp;lt;&amp;gt;(); authorities.add(new SimpleGrantedAuthority(&quot;ROLE_USER&quot; )); return new User(user.getUsername(), user.getPassword(),authorities); }}无权限的返回拦截器CustomAccessDeniedHandler设置自定义拦截器统一已通过身份验证但无权限的403返回格式@Componentpublic class CustomAccessDeniedHandler implements AccessDeniedHandler { @Override public void handle(HttpServletRequest request, HttpServletResponse response, AccessDeniedException accessDeniedException) throws IOException { request.setCharacterEncoding(&quot;utf-8&quot;); response.setCharacterEncoding(&quot;utf-8&quot;); response.setContentType(MediaType.APPLICATION_JSON_VALUE); response.setStatus(HttpStatus.FORBIDDEN.value()); response.getWriter().write(new ObjectMapper().writeValueAsString(new CommonResult&amp;lt;&amp;gt;(CustomStatusEnum.NO_PERMISSION))); }}CustomEntryPoint设置自定义拦截器统一未登录的403返回格式@Componentpublic class CustomEntryPoint implements AuthenticationEntryPoint { @Override public void commence(HttpServletRequest request, HttpServletResponse response, AuthenticationException authException) throws IOException { response.setStatus(HttpServletResponse.SC_FORBIDDEN); response.setCharacterEncoding(&quot;UTF-8&quot;); response.setContentType(&quot;application/json; charset=utf-8&quot;); PrintWriter out = response.getWriter(); ObjectMapper objectMapper = new ObjectMapper(); String errorMsg = objectMapper.writeValueAsString(new CommonResult&amp;lt;&amp;gt;(CustomStatusEnum.NOT_LOGIN)); out.write(errorMsg); out.flush(); out.close(); }}JWT 相关处理JWT 认证实现主要通过 JWTLoginFilter 实现读取 /login 请求中的用户信息进行验证，通过后发放JWT JWTAuthenticationFilter 拦截所有使用JWT认证的请求，同时获取请求头中的JWT并解析验证，根据结果放行请求 TokenAuthenticationService 为以上两个Filter提供服务具体实现参考: SpringSecurity 集成JWT权限验证" }, { "title": "Java 并发集合概览", "url": "/posts/java-concurrent-collection-overview/", "categories": "", "tags": "", "date": "2020-12-12 22:43:00 +0800", "snippet": "这篇主要简单介绍 Java 集合库包含哪些常用的容器类，它们可以简单区分为: 非同步集合 同步集合 并发集合Java 集合框架Java 集合工具包在 Java.util 包下，它包含了常用的数据结构，比如数组、链表、栈、队列、集合、哈希表等等。这里先放一张 Java 集合类的框架图：Collection 接口是集合类的根接口，Java 中没有提供这个接口的直接的实现类。但是让其被继承产生了两个接口，就是 Set 和 List。Set中不能包含重复的元素。List是一个有序的集合，可以包含重复的元素，提供了按索引访问的方式。Map 是 Java.util 包中的另一个接口，它和 Collection 接口没有关系，是相互独立的，但是都属于集合类的一部分。Map 包含了 key-value 对。Map 不能包含重复的 key，但是可以包含相同的 value。其中还有一个 Iterator&amp;lt;E&amp;gt; 接口，Collection 继承了它，也就是说所有的集合类，都实现了Iterator接口，这是一个用于遍历集合中元素的接口，主要包含以下三种方法：hasNext()是否还有下一个元素。next()返回下一个元素。remove()删除当前元素。对于 Java 集合框架，这里不再做过多的说明，如果要完全剖析，那估计得再开一个专栏来讲。下面对具体容器类分类，我们直接来看他们分别属于哪些类型。Java 集合详细内容：Java 集合类概览非同步集合非同步集合，在并发访问的时候，是非线程安全的；但是由于它们没有同步策略(加锁机制)，它们的效率更高。常用的非同步集合它们包括下面几个： ArrayList HashSet HashMap LinkedList TreeSet TreeMap PriorityQueue同步集合(容器)什么是同步容器Java的集合容器框架中，主要有四大类别：List、Set、Queue、Map，大家熟知的这些集合类ArrayList、LinkedList、HashMap这些容器都是非线程安全的。如果有多个线程并发地访问这些容器时，就会出现问题。因此，在编写程序时，在多线程环境下必须要求程序员手动地在任何访问到这些容器的地方进行同步处理，这样导致在使用这些容器的时候非常地不方便。所以，Java先提供了同步容器供用户使用。同步容器可以简单地理解为通过synchronized来实现同步的容器，通过对每个方法都进行同步加锁，保证线程安全。 HashTable Vector Stack 同步包装器 : [ Collections.synchronizedMap(), Collections.synchronizedList() ]Java 集合类中非线程安全的集合可以用同步包装器使集合变成线程安全，其实实现原理就是相当于对每个方法加多一层同步锁而已，比如： HashMap –&amp;gt; Collections.synchronizedMap(new HashMap()) ArrayList –&amp;gt; Collections.synchronizedList(new ArrayList&amp;lt;&amp;gt;())同步容器面临的问题 同步容器类在单个方法被使用时可以保证线程安全。复合操作则需要额外的客户端加锁来保护。 使用Iterator迭代容器或使用使用for-each遍历容器，在迭代过程中修改容器会抛出ConcurrentModificationException异常。想要避免出现ConcurrentModificationException，就必须在迭代过程持有容器的锁。但是若容器较大，则迭代的时间也会较长。那么需要访问该容器的其他线程将会长时间等待。从而会极大降低性能。 若不希望在迭代期间对容器加锁，可以使用”克隆”容器的方式。使用线程封闭，由于其他线程不会对容器进行修改，可以避免ConcurrentModificationException。但是在创建副本的时候，存在较大性能开销。 隐式迭代 toString，hashCode，equalse，containsAll，removeAll，retainAll等方法都会隐式的Iterate，也即可能抛出ConcurrentModificationException。 通过查看Vector，Hashtable等这些同步容器的实现代码，可以看到这些容器实现线程安全的方式就是将它们的状态封装起来，并在需要同步的方法上加上关键字synchronized。 这样做的代价是削弱了并发性，当多个线程共同竞争容器级的锁时，吞吐量就会降低。 例如： HashTable只要有一条线程获取了容器的锁之后，其他所有的线程访问同步函数都会被阻塞，因此同一时刻只能有一条线程访问同步函数。 因此为了解决同步容器的性能问题，所以才有了并发容器。并发集合(容器)什么是并发容器java.util.concurrent包中提供了多种并发类容器。并发类容器是专门针对多线程并发设计的，使用了锁分段技术，只对操作的位置进行同步操作，但是其他没有操作的位置其他线程仍然可以访问，提高了程序的吞吐量。采用了CAS算法和部分代码使用synchronized锁保证线程安全。并发容器包注重以下特性： 根据具体场景进行设计，尽量避免使用锁，提高容器的并发访问性。 并发容器定义了一些线程安全的复合操作。 并发容器在迭代时，可以不封闭在synchronized中。但是未必每次看到的都是”最新的、当前的”数据。如果说将迭代操作包装在synchronized中，可以达到”串行”的并发安全性，那么并发容器的迭代达到了”脏读”。CopyOnWriteArrayList和CopyOnWriteArraySet分别代替List和Set，主要是在遍历操作为主的情况下来代替同步的List和同步的Set，这也就是上面所述的思路：迭代过程要保证不出错，除了加锁，另外一种方法就是”克隆”容器对象。ConcurrentLinkedQuerue是Query实现，是一个先进先出的队列。一般的Queue实现中操作不会阻塞，如果队列为空，那么取元素的操作将返回空。Queue一般用LinkedList实现的，因为去掉了List的随机访问需求，因此并发性更好。BlockingQueue扩展了Queue，增加了可阻塞的插入和获取操作，如果队列为空，那么获取操作将阻塞，直到队列中有一个可用的元素。如果队列已满，那么插入操作就阻塞，直到队列中出现可用的空间。1.ConcurrentHashMap并发版HashMap最常见的并发容器之一，可以用作并发场景下的缓存。底层依然是哈希表，但在JAVA 8中有了不小的改变，而JAVA 7和JAVA 8都是用的比较多的版本，因此经常会将这两个版本的实现方式做一些比较（比如面试中）。一个比较大的差异就是，JAVA 7中采用分段锁来减少锁的竞争，JAVA 8中放弃了分段锁，采用CAS（一种乐观锁），同时为了防止哈希冲突严重时退化成链表（冲突时会在该位置生成一个链表，哈希值相同的对象就链在一起），会在链表长度达到阈值（8）后转换成红黑树（比起链表，树的查询效率更稳定）。2.CopyOnWriteArrayList并发版ArrayList底层结构也是数组，和ArrayList不同之处在于：当新增和删除元素时会创建一个新的数组，在新的数组中增加或者排除指定对象，最后用新增数组替换原来的数组。适用场景：由于读操作不加锁，写（增、删、改）操作加锁，因此适用于读多写少的场景。局限：由于读的时候不会加锁（读的效率高，就和普通ArrayList一样），读取的当前副本，因此可能读取到脏数据。如果介意，建议不用。看看源码感受下：public class CopyOnWriteArrayList&amp;lt;E&amp;gt; implements List&amp;lt;E&amp;gt;, RandomAccess, Cloneable, java.io.Serializable { final transient ReentrantLock lock = new ReentrantLock(); private transient volatile Object[] array; // 添加元素，有锁 public boolean add(E e) { final ReentrantLock lock = this.lock; lock.lock(); // 修改时加锁，保证并发安全 try { Object[] elements = getArray(); // 当前数组 int len = elements.length; Object[] newElements = Arrays.copyOf(elements, len + 1); // 创建一个新数组，比老的大一个空间 newElements[len] = e; // 要添加的元素放进新数组 setArray(newElements); // 用新数组替换原来的数组 return true; } finally { lock.unlock(); // 解锁 } } // 读元素，不加锁，因此可能读取到旧数据 public E get(int index) { return get(getArray(), index); }}原理：利用高并发往往是读多写少的特性，对读操作不加锁，对写操作，先复制一份新的集合，在新的集合上面修改，然后将新集合赋值给旧的引用，并通过volatile 保证其可见性，当然写操作的锁是必不可少的了。3.CopyOnWriteArraySet并发Set基于CopyOnWriteArrayList实现（内含一个CopyOnWriteArrayList成员变量），也就是说底层是一个数组，意味着每次add都要遍历整个集合才能知道是否存在，不存在时需要插入（加锁）。适用场景：在CopyOnWriteArrayList适用场景下加一个，集合别太大（全部遍历伤不起）。4.ConcurrentLinkedQueue并发队列(基于链表)基于链表实现的并发队列, LinkedList的并发版本，使用乐观锁(CAS)保证线程安全。因为数据结构是链表，所以理论上是没有队列大小限制的，也就是说添加数据一定能成功。5.ConcurrentLinkedDeque并发队列(基于双向链表)基于双向链表实现的并发队列，可以分别对头尾进行操作，因此除了先进先出(FIFO)，也可以先进后出（FILO），当然先进后出的话应该叫它栈了。6.ConcurrentSkipListMap基于跳表的并发MapSkipList即跳表，跳表是一种空间换时间的数据结构，通过冗余数据，将链表一层一层索引，达到类似二分查找的效果7.ConcurrentSkipListSet基于跳表的并发Set类似HashSet和HashMap的关系，ConcurrentSkipListSet里面就是一个ConcurrentSkipListMap，就不细说了。8.ArrayBlockingQueue阻塞队列(基于数组)基于数组实现的可阻塞队列，构造时必须制定数组大小，往里面放东西时如果数组满了便会阻塞直到有位置（也支持直接返回和超时等待），通过一个锁ReentrantLock保证线程安全。举个例子:public class ArrayBlockingQueue&amp;lt;E&amp;gt; extends AbstractQueue&amp;lt;E&amp;gt; implements BlockingQueue&amp;lt;E&amp;gt;, java.io.Serializable { /** * 读写共用此锁，线程间通过下面两个Condition通信 * 这两个Condition和lock有紧密联系（就是lock的方法生成的） * 类似Object的wait/notify */ final ReentrantLock lock; /** 队列不为空的信号，取数据的线程需要关注 */ private final Condition notEmpty; /** 队列没满的信号，写数据的线程需要关注 */ private final Condition notFull; // 一直阻塞直到有东西可以拿出来 public E take() throws InterruptedException { final ReentrantLock lock = this.lock; lock.lockInterruptibly(); try { while (count == 0) notEmpty.await(); return dequeue(); } finally { lock.unlock(); } } // 在尾部插入一个元素，队列已满时等待指定时间，如果还是不能插入则返回 public boolean offer(E e, long timeout, TimeUnit unit) throws InterruptedException { checkNotNull(e); long nanos = unit.toNanos(timeout); final ReentrantLock lock = this.lock; lock.lockInterruptibly(); // 锁住 try { // 循环等待直到队列有空闲 while (count == items.length) { if (nanos &amp;lt;= 0) return false;// 等待超时，返回 // 暂时放出锁，等待一段时间（可能被提前唤醒并抢到锁，所以需要循环判断条件） // 这段时间可能其他线程取走了元素，这样就有机会插入了 nanos = notFull.awaitNanos(nanos); } enqueue(e);//插入一个元素 return true; } finally { lock.unlock(); //解锁 } }乍一看会有点疑惑，读和写都是同一个锁，那要是空的时候正好一个读线程来了不会一直阻塞吗？答案就在notEmpty、notFull里，这两个出自lock的小东西让锁有了类似synchronized + wait + notify的功能。9.LinkedBlockingQueue阻塞队列(基于链表)基于链表实现的阻塞队列，想比与不阻塞的ConcurrentLinkedQueue，它多了一个容量限制，如果不设置默认为int最大值10.LinkedBlockingDeque阻塞队列(基于双向链表)类似LinkedBlockingQueue，但提供了双向链表特有的操作。11.PriorityBlockingQueue线程安全的优先队列构造时可以传入一个比较器，可以看做放进去的元素会被排序，然后读取的时候按顺序消费。某些低优先级的元素可能长期无法被消费，因为不断有更高优先级的元素进来。12.SynchronousQueue数据同步交换的队列一个虚假的队列，因为它实际上没有真正用于存储元素的空间，每个插入操作都必须有对应的取出操作，没取出时无法继续放入。一个简单的例子import java.util.concurrent.*;public class Main { public static void main(String[] args) { SynchronousQueue&amp;lt;Integer&amp;gt; queue = new SynchronousQueue&amp;lt;&amp;gt;(); new Thread(() -&amp;gt; { try { // 没有休息，疯狂写入 for (int i = 0; ; i++) { System.out.println(&quot;放入: &quot; + i); queue.put(i); } } catch (InterruptedException e) { e.printStackTrace(); } }).start(); new Thread(() -&amp;gt; { try { // 咸鱼模式取数据 while (true) { System.out.println(&quot;取出: &quot; + queue.take()); Thread.sleep((long) (Math.random() * 2000)); } } catch (InterruptedException e) { e.printStackTrace(); } }).start(); }}输出:放入: 0取出: 0放入: 1取出: 1放入: 2取出: 2放入: 3取出: 3*/可以看到，写入的线程没有任何sleep，可以说是全力往队列放东西，而读取的线程又很不积极，读一个又sleep一会。输出的结果却是读写操作成对出现。JAVA中一个使用场景就是Executors.newCachedThreadPool()，创建一个缓存线程池。public static ExecutorService newCachedThreadPool() { return new ThreadPoolExecutor( 0, // 核心线程为0，没用的线程都被无情抛弃 Integer.MAX_VALUE, // 最大线程数理论上是无限了，还没到这个值机器资源就被掏空了 60L, TimeUnit.SECONDS, // 闲置线程60秒后销毁 new SynchronousQueue&amp;lt;Runnable&amp;gt;()); // offer时如果没有空闲线程取出任务，则会失败，线程池就会新建一个线程}13.LinkedTransferQueue基于链表的数据交换队列实现了接口TransferQueue，通过transfer方法放入元素时，如果发现有线程在阻塞在取元素，会直接把这个元素给等待线程。如果没有人等着消费，那么会把这个元素放到队列尾部，并且此方法阻塞直到有人读取这个元素。和SynchronousQueue有点像，但比它更强大。14.DelayQueue延时队列可以使放入队列的元素在指定的延时后才被消费者取出，元素需要实现Delayed接口。同步集合类和并发集合类的区别不管是同步集合还是并发集合他们都支持线程安全，他们之间主要的区别体现在性能和可扩展性，还有他们如何实现的线程安全。同步集合类，Hashtable 和 Vector 还有同步集合包装类，Collections.synchronizedMap()和Collections.synchronizedList()，相比并发的实现（比如：ConcurrentHashMap, CopyOnWriteArrayList, CopyOnWriteHashSet）会慢得多。造成如此慢的主要原因是锁， 同步集合会把整个Map或List锁起来，每个操作都是串行的操作，同一时刻只有一个线程能操作。而并发集合不会，并发集合实现线程安全是通过使用先进的和成熟的技术把锁剥离。比如ConcurrentHashMap 会把整个Map 划分成几个片段，只对相关的几个片段上锁，同时允许多线程访问其他未上锁的片段。CopyOnWriteArrayList 允许多个线程以非同步的方式读，当有线程写的时候它会将整个List复制一个副本给它。如果在读多写少这种对并发集合有利的条件下使用并发集合，这会比使用同步集合更具有可伸缩性。" }, { "title": "Java 多线程概览", "url": "/posts/java-multithreading-overview/", "categories": "Software Development", "tags": "Java", "date": "2020-11-27 16:43:00 +0800", "snippet": "前言用多线程只有一个目的，那就是更好的利用cpu的资源，因为所有的多线程代码都可以用单线程来实现。说这个话其实只有一半对，因为反应“多角色”的程序代码，最起码每个角色要给他一个线程吧，否则连实际场景都无法模拟，当然也没法说能用单线程来实现：比如最常见的“生产者，消费者模型”。其中的一些概念不够明确，如同步、并发等等，让我们先建立一个数据字典，以免产生误会。 多线程：指的是这个程序（一个进程）运行时产生了不止一个线程 并行：多个cpu实例或者多台机器同时执行一段处理逻辑，是真正的同时。 并发：通过cpu调度算法，让用户看上去同时执行，实际上从cpu操作层面不是真正的同时。并发往往在场景中有公用的资源，那么针对这个公用的资源往往产生瓶颈，我们会用TPS或者QPS来反应这个系统的处理能力。 线程安全：经常用来描绘一段代码。指在并发的情况之下，该代码经过多线程使用，线程的调度顺序不影响任何结果。这个时候使用多线程，我们只需要关注系统的内存，cpu是不是够用即可。反过来，线程不安全就意味着线程的调度顺序会影响最终结果，如不加事务的转账代码 void transferMoney(User from, User to, float amount){to.setMoney(to.getBalance() + amount);from.setMoney(from.getBalance() - amount);} 同步：Java中的同步指的是通过人为的控制和调度，保证共享资源的多线程访问成为线程安全，来保证结果的准确。如上面的代码简单加入@synchronized关键字。在保证结果准确的同时，提高性能，才是优秀的程序。线程安全的优先级高于性能。什么是Java多线程?进程与线程进程 当一个程序被运行，就开启了一个进程， 比如启动了qq，word 程序由指令和数据组成，指令要运行，数据要加载，指令被cpu加载运行，数据被加载到内存，指令运行时可由cpu调度硬盘、网络等设备线程 一个进程内可分为多个线程 一个线程就是一个指令流，cpu调度的最小单位，由cpu一条一条执行指令并行与并发并发：单核cpu运行多线程时，时间片进行很快的切换。线程轮流执行cpu并行：多核cpu运行 多线程时，真正的在同一时刻运行Java提供了丰富的api来支持多线程。为什么用多线程?多线程能实现的都可以用单线程来完成，那单线程运行的好好的，为什么Java要引入多线程的概念呢？多线程的好处： 程序运行的更快！快！快！ 充分利用cpu资源，目前几乎没有线上的cpu是单核的，发挥多核cpu强大的能力多线程难在哪里？单线程只有一条执行线，过程容易理解，可以在大脑中清晰的勾勒出代码的执行流程多线程却是多条线，而且一般多条线之间有交互，多条线之间需要通信，一般难点有以下几点 多线程的执行结果不确定,受到cpu调度的影响 多线程的安全问题 线程资源宝贵，依赖线程池操作线程，线程池的参数设置问题 多线程执行是动态的，同时的,难以追踪过程 多线程的底层是操作系统层面的，源码难度大Java多线程的基本使用定义任务、创建和运行线程任务： 线程的执行体。也就是我们的核心代码逻辑定义任务 继承Thread类 （可以说是 将任务和线程合并在一起） 实现Runnable接口 （可以说是 将任务和线程分开了） 实现Callable接口 (利用FutureTask执行任务)Thread实现任务的局限性 任务逻辑写在Thread类的run方法中，有单继承的局限性 创建多线程时，每个任务有成员变量时不共享，必须加static才能做到共享Runnable和Callable解决了Thread的局限性但是Runbale相比Callable有以下的局限性 任务没有返回值 任务无法抛异常给调用方如下代码 几种定义线程的方式@Slf4jclass T extends Thread { @Override public void run() { log.info(&quot;我是继承Thread的任务&quot;); }}@Slf4jclass R implements Runnable { @Override public void run() { log.info(&quot;我是实现Runnable的任务&quot;); }}@Slf4jclass C implements Callable&amp;lt;String&amp;gt; { @Override public String call() throws Exception { log.info(&quot;我是实现Callable的任务&quot;); return &quot;success&quot;; }}创建线程的方式 通过Thread类直接创建线程 利用线程池内部创建线程启动线程的方式调用线程的start()方法// 启动继承Thread类的任务new T().start();// 启动继承Thread匿名内部类的任务 可用lambda优化Thread t = new Thread(){ @Override public void run() { log.info(&quot;我是Thread匿名内部类的任务&quot;); }};// 启动实现Runnable接口的任务new Thread(new R()).start();// 启动实现Runnable匿名实现类的任务new Thread(new Runnable() { @Override public void run() { log.info(&quot;我是Runnable匿名内部类的任务&quot;); }}).start();// 启动实现Runnable的lambda简化后的任务new Thread(() -&amp;gt; log.info(&quot;我是Runnable的lambda简化后的任务&quot;)).start();// 启动实现了Callable接口的任务 结合FutureTask 可以获取线程执行的结果FutureTask&amp;lt;String&amp;gt; target = new FutureTask&amp;lt;&amp;gt;(new C());new Thread(target).start();log.info(target.get());以上各个线程相关的类的类图如下上下文切换多核cpu下，多线程是并行工作的，如果线程数多，单个核又会并发的调度线程,运行时会有上下文切换的概念cpu执行线程的任务时，会为线程分配时间片，以下几种情况会发生上下文切换。 线程的cpu时间片用完 垃圾回收 线程自己调用了 sleep、yield、wait、join、park、synchronized、lock 等方法当发生上下文切换时，操作系统会保存当前线程的状态，并恢复另一个线程的状态,jvm中有块内存地址叫程序计数器，用于记录线程执行到哪一行代码,是线程私有的。线程的礼让-yield()&amp;amp;线程的优先级yield()方法会让运行中的线程切换到就绪状态，重新争抢cpu的时间片，争抢时是否获取到时间片看cpu的分配。public static native void yield();Runnable r1 = () -&amp;gt; { int count = 0; for (;;){ log.info(&quot;---- 1&amp;gt;&quot; + count++); }};Runnable r2 = () -&amp;gt; { int count = 0; for (;;){ Thread.yield(); log.info(&quot; ---- 2&amp;gt;&quot; + count++); }};Thread t1 = new Thread(r1,&quot;t1&quot;);Thread t2 = new Thread(r2,&quot;t2&quot;);t1.start();t2.start();运行结果11:49:15.796 [t1] INFO thread.TestYield - ---- 1&amp;gt;12950411:49:15.796 [t1] INFO thread.TestYield - ---- 1&amp;gt;12950511:49:15.796 [t1] INFO thread.TestYield - ---- 1&amp;gt;12950611:49:15.796 [t1] INFO thread.TestYield - ---- 1&amp;gt;12950711:49:15.796 [t1] INFO thread.TestYield - ---- 1&amp;gt;12950811:49:15.796 [t1] INFO thread.TestYield - ---- 1&amp;gt;12950911:49:15.796 [t1] INFO thread.TestYield - ---- 1&amp;gt;12951011:49:15.796 [t1] INFO thread.TestYield - ---- 1&amp;gt;12951111:49:15.796 [t1] INFO thread.TestYield - ---- 1&amp;gt;12951211:49:15.798 [t2] INFO thread.TestYield - ---- 2&amp;gt;29311:49:15.798 [t1] INFO thread.TestYield - ---- 1&amp;gt;12951311:49:15.798 [t1] INFO thread.TestYield - ---- 1&amp;gt;12951411:49:15.798 [t1] INFO thread.TestYield - ---- 1&amp;gt;12951511:49:15.798 [t1] INFO thread.TestYield - ---- 1&amp;gt;12951611:49:15.798 [t1] INFO thread.TestYield - ---- 1&amp;gt;12951711:49:15.798 [t1] INFO thread.TestYield - ---- 1&amp;gt;129518如上述结果所示，t2线程每次执行时进行了yield()，线程1执行的机会明显比线程2要多。线程的优先级​ 线程内部用1~10的数来调整线程的优先级，默认的线程优先级为NORM_PRIORITY:5​ cpu比较忙时，优先级高的线程获取更多的时间片​ cpu比较闲时，优先级设置基本没用守护线程默认情况下，Java进程需要等待所有线程都运行结束，才会结束，有一种特殊线程叫守护线程，当所有的非守护线程都结束后，即使它没有执行完，也会强制结束。默认的线程都是非守护线程。垃圾回收线程就是典型的守护线程// 方法的定义public final void setDaemon(boolean on) {}Thread thread = new Thread(() -&amp;gt; { while (true) { }});// 具体的api。设为true表示未守护线程，当主线程结束后，守护线程也结束。// 默认是false，当主线程结束后，thread继续运行，程序不停止thread.setDaemon(true);thread.start();log.info(&quot;结束&quot;);线程的阻塞线程的阻塞可以分为好多种，从操作系统层面和Java层面阻塞的定义可能不同，但是广义上使得线程阻塞的方式有下面几种 BIO阻塞，即使用了阻塞式的io流 sleep(long time) 让线程休眠进入阻塞状态 a.join() 调用该方法的线程进入阻塞，等待a线程执行完恢复运行 sychronized或ReentrantLock 造成线程未获得锁进入阻塞状态 (同步锁章节细说) 获得锁之后调用wait()方法 也会让线程进入阻塞状态 (同步锁章节细说) LockSupport.park() 让线程进入阻塞状态 (同步锁章节细说)sleep()使线程休眠，会将运行中的线程进入阻塞状态。当休眠时间结束后，重新争抢cpu的时间片继续运行// 方法的定义 native方法public static native void sleep(long millis) throws InterruptedException; try { // 休眠2秒 // 该方法会抛出 InterruptedException异常 即休眠过程中可被中断，被中断后抛出异常 Thread.sleep(2000); } catch (InterruptedException异常 e) { } try { // 使用TimeUnit的api可替代 Thread.sleep TimeUnit.SECONDS.sleep(1); } catch (InterruptedException e) { }join()​join是指调用该方法的线程进入阻塞状态，等待某线程执行完成后恢复运行// 方法的定义 有重载// 等待线程执行完才恢复运行public final void join() throws InterruptedException {}// 指定join的时间。指定时间内 线程还未执行完 调用方线程不继续等待就恢复运行public final synchronized void join(long millis) throws InterruptedException{}Thread t = new Thread(() -&amp;gt; { try { Thread.sleep(1000); } catch (InterruptedException e) { e.printStackTrace(); } r = 10;});t.start();// 让主线程阻塞 等待t线程执行完才继续执行 // 去除该行，执行结果为0，加上该行 执行结果为10t.join();log.info(&quot;r:{}&quot;, r);运行结果13:09:13.892 [main] INFO thread.TestJoin - r:10线程的打断-interrupt()// 相关方法的定义public void interrupt() {}public boolean isInterrupted() {}public static boolean interrupted() {}打断标记：线程是否被打断，true表示被打断了，false表示没有isInterrupted() 获取线程的打断标记 ,调用后不会修改线程的打断标记interrupt()方法用于中断线程 可以打断sleep,wait,join等显式的抛出InterruptedException方法的线程，但是打断后,线程的打断标记还是false 打断正常线程 ，线程不会真正被中断，但是线程的打断标记为trueinterrupted() 获取线程的打断标记，调用后清空打断标记 即如果获取为true 调用后打断标记为false (不常用)interrupt实例： 有个后台监控线程不停的监控，当外界打断它时，就结束运行。代码如下@Slf4jclass TwoPhaseTerminal{ // 监控线程 private Thread monitor; public void start(){ monitor = new Thread(() -&amp;gt;{ // 不停的监控 while (true){ Thread thread = Thread.currentThread(); // 判断当前线程是否被打断 if (thread.isInterrupted()){ log.info(&quot;当前线程被打断,结束运行&quot;); break; } try { Thread.sleep(1000); // 监控逻辑中被打断后，打断标记为true log.info(&quot;监控&quot;); } catch (InterruptedException e) { // 睡眠时被打断时抛出异常 在该处捕获到 此时打断标记还是false // 在调用一次中断 使得中断标记为true thread.interrupt(); } } }); monitor.start(); } public void stop(){ monitor.interrupt(); }}线程的状态上面说了一些基本的api的使用，调用上面的方法后都会使得线程有对应的状态。线程的状态可从 操作系统层面分为五种状态 从Java api层面分为六种状态。五种状态 初始状态：创建线程对象时的状态 可运行状态(就绪状态)：调用start()方法后进入就绪状态，也就是准备好被cpu调度执行 运行状态：线程获取到cpu的时间片，执行run()方法的逻辑 阻塞状态: 线程被阻塞，放弃cpu的时间片，等待解除阻塞重新回到就绪状态争抢时间片 终止状态: 线程执行完成或抛出异常后的状态六种状态public enum State { NEW, RUNNABLE, BLOCKED, WAITING, TIMED_WAITING, TERMINATED;}六种线程状态和方法的对应关系 NEW 线程对象被创建 Runnable 线程调用了start()方法后进入该状态，该状态包含了三种情况 就绪状态 :等待cpu分配时间片 运行状态:进入Runnable方法执行任务 阻塞状态:BIO 执行阻塞式io流时的状态 Blocked 没获取到锁时的阻塞状态(同步锁章节会细说) WAITING（等待） 调用wait()、join()等方法后的状态 TIMED_WAITING（锁定） 调用 sleep(time)、wait(time)、join(time)等方法后的状态 TERMINATED 线程执行完成或抛出异常后的状态线程的相关方法总结主要总结Thread类中的核心方法 方法名称 是否static 方法说明 start() 否 让线程启动，进入就绪状态,等待cpu分配时间片 run() 否 重写Runnable接口的方法,线程获取到cpu时间片时执行的具体逻辑 yield() 是 线程的礼让，使得获取到cpu时间片的线程进入就绪状态，重新争抢时间片 sleep(time) 是 线程休眠固定时间，进入阻塞状态，休眠时间完成后重新争抢时间片,休眠可被打断 join()/join(time) 否 调用线程对象的join方法，调用者线程进入阻塞,等待线程对象执行完或者到达指定时间才恢复，重新争抢时间片 isInterrupted() 否 获取线程的打断标记，true:被打断，false：没有被打断。调用后不会修改打断标记 interrupt() 否 打断线程，抛出InterruptedException异常的方法均可被打断，但是打断后不会修改打断标记，正常执行的线程被打断后会修改打断标记 interrupted() 否 获取线程的打断标记。调用后会清空打断标记 stop() 否 停止线程运行 不推荐 suspend() 否 挂起线程 不推荐 resume() 否 恢复线程运行 不推荐 currentThread() 是 获取当前线程 Object中与线程相关方法 方法名称 方法说明 wait()/wait(long timeout) 获取到锁的线程进入阻塞状态 notify() 随机唤醒被wait()的一个线程 notifyAll(); 唤醒被wait()的所有线程，重新争抢时间片 同步锁线程安全 一个程序运行多个线程本身是没有问题的 问题有可能出现在多个线程访问共享资源 多个线程都是读共享资源也是没有问题的 当多个线程读写共享资源时,如果发生指令交错，就会出现问题 临界区: 一段代码如果对共享资源的多线程读写操作,这段代码就被称为临界区。注意的是 指令交错指的是 Java代码在解析成字节码文件时，Java代码的一行代码在字节码中可能有多行，在线程上下文切换时就有可能交错。线程安全指的是多线程调用同一个对象的临界区的方法时，对象的属性值一定不会发生错误，这就是保证了线程安全。如下面不安全的代码// 对象的成员变量private static int count = 0;public static void main(String[] args) throws InterruptedException { // t1线程对变量+5000次 Thread t1 = new Thread(() -&amp;gt; { for (int i = 0; i &amp;lt; 5000; i++) { count++; } }); // t2线程对变量-5000次 Thread t2 = new Thread(() -&amp;gt; { for (int i = 0; i &amp;lt; 5000; i++) { count--; } }); t1.start(); t2.start(); // 让t1 t2都执行完 t1.join(); t2.join(); System.out.println(count);}// 运行结果 -1399 上面的代码 两个线程，一个+5000次，一个-5000次，如果线程安全，count的值应该还是0。 但是运行很多次，每次的结果不同，且都不是0，所以是线程不安全的。线程安全的类一定所有的操作都线程安全吗？开发中经常会说到一些线程安全的类，如ConcurrentHashMap，线程安全指的是类里每一个独立的方法是线程安全的，但是方法的组合就不一定是线程安全的。成员变量和静态变量是否线程安全? 如果没有多线程共享，则线程安全 如果存在多线程共享 多线程只有读操作，则线程安全 多线程存在写操作，写操作的代码又是临界区,则线程不安全 局部变量是否线程安全? 局部变量是线程安全的 局部变量引用的对象未必是线程安全的 如果该对象没有逃离该方法的作用范围，则线程安全 如果该对象逃离了该方法的作用范围，比如：方法的返回值,需要考虑线程安全 synchronized同步锁也叫对象锁，是锁在对象上的，不同的对象就是不同的锁。该关键字是用于保证线程安全的，是阻塞式的解决方案。让同一个时刻最多只有一个线程能持有对象锁，其他线程在想获取这个对象锁就会被阻塞，不用担心上下文切换的问题。注意： 不要理解为一个线程加了锁 ，进入 synchronized代码块中就会一直执行下去。如果时间片切换了，也会执行其他线程，再切换回来会紧接着执行，只是不会执行到有竞争锁的资源，因为当前线程还未释放锁。当一个线程执行完synchronized的代码块后 会唤醒正在等待的线程synchronized实际上使用对象锁保证临界区的原子性 临界区的代码是不可分割的 不会因为线程切换所打断基本使用// 加在方法上 实际是对this对象加锁private synchronized void a() {}// 同步代码块,锁对象可以是任意的，加在this上 和a()方法作用相同private void b(){ synchronized (this){ }}// 加在静态方法上 实际是对类对象加锁private synchronized static void c() {}// 同步代码块 实际是对类对象加锁 和c()方法作用相同private void d(){ synchronized (TestSynchronized.class){ }}// 上述b方法对应的字节码源码 其中monitorenter就是加锁的地方aload_0dupastore_1monitorenteraload_1monitorexitgoto 14 (+8)astore_2aload_1monitorexitaload_2athrowreturn线程安全的代码private static int count = 0;private static Object lock = new Object();private static Object lock2 = new Object(); // t1线程和t2对象都是对同一对象加锁。保证了线程安全。此段代码无论执行多少次，结果都是0public static void main(String[] args) throws InterruptedException { Thread t1 = new Thread(() -&amp;gt; { for (int i = 0; i &amp;lt; 5000; i++) { synchronized (lock) { count++; } } }); Thread t2 = new Thread(() -&amp;gt; { for (int i = 0; i &amp;lt; 5000; i++) { synchronized (lock) { count--; } } }); t1.start(); t2.start(); // 让t1 t2都执行完 t1.join(); t2.join(); System.out.println(count);} 重点：加锁是加在对象上，一定要保证是同一对象，加锁才能生效线程通信wait+notify线程间通信可以通过共享变量+wait()¬ify()来实现wait()将线程进入阻塞状态，notify()将线程唤醒当多线程竞争访问对象的同步方法时，锁对象会关联一个底层的Monitor对象(重量级锁的实现)如下图所示 Thread0,1先竞争到锁执行了代码后，2,3,4,5线程同时来执行临界区的代码,开始竞争锁 Thread-0先获取到对象的锁，关联到monitor的owner，同步代码块内调用了锁对象的wait()方法，调用后会进入waitSet等待，Thread-1同样如此，此时Thread-0的状态为Waitting Thread2、3、4、5同时竞争，2获取到锁后，关联了monitor的owner，3、4、5只能进入EntryList中等待，此时2线程状态为 Runnable，3、4、5状态为Blocked 2执行后，唤醒entryList中的线程，3、4、5进行竞争锁，获取到的线程即会关联monitor的owner 3、4、5线程在执行过程中，调用了锁对象的notify()或notifyAll()时，会唤醒waitSet的线程，唤醒的线程进入entryList等待重新竞争锁注意: Blocked状态和Waitting状态都是阻塞状态 Blocked线程会在owner线程释放锁时唤醒 wait和notify使用场景是必须要有同步，且必须获得对象的锁才能调用,使用锁对象去调用,否则会抛异常 wait() 释放锁 进入 waitSet 可传入时间，如果指定时间内未被唤醒 则自动唤醒 notify()随机唤醒一个waitSet里的线程 notifyAll()唤醒waitSet中所有的线程static final Object lock = new Object();new Thread(() -&amp;gt; { synchronized (lock) { log.info(&quot;开始执行&quot;); try { // 同步代码内部才能调用 lock.wait(); } catch (InterruptedException e) { e.printStackTrace(); } log.info(&quot;继续执行核心逻辑&quot;); }}, &quot;t1&quot;).start();new Thread(() -&amp;gt; { synchronized (lock) { log.info(&quot;开始执行&quot;); try { lock.wait(); } catch (InterruptedException e) { e.printStackTrace(); } log.info(&quot;继续执行核心逻辑&quot;); }}, &quot;t2&quot;).start();try { Thread.sleep(2000);} catch (InterruptedException e) { e.printStackTrace();}log.info(&quot;开始唤醒&quot;);synchronized (lock) { // 同步代码内部才能调用 lock.notifyAll();}执行结果14:29:47.138 [t1] INFO TestWaitNotify - 开始执行14:29:47.141 [t2] INFO TestWaitNotify - 开始执行14:29:49.136 [main] INFO TestWaitNotify - 开始唤醒14:29:49.136 [t2] INFO TestWaitNotify - 继续执行核心逻辑14:29:49.136 [t1] INFO TestWaitNotify - 继续执行核心逻辑wait 和 sleep的区别?二者都会让线程进入阻塞状态，有以下区别 wait是Object的方法 sleep是Thread的方法 wait会立即释放锁 sleep不会释放锁 wait后线程的状态是Watting sleep后线程的状态为 Time_Waitingpark&amp;amp;unparkLockSupport是juc下的工具类，提供了park和unpark方法，可以实现线程通信与wait和notity相比的不同点 wait 和notify需要获取对象锁 park unpark不要 unpark 可以指定唤醒线程 notify随机唤醒 park和unpark的顺序可以先unpark wait和notify的顺序不能颠倒生产者消费者模型指的是有生产者来生产数据，消费者来消费数据，生产者生产满了就不生产了，通知消费者取，等消费了再进行生产。消费者消费不到了就不消费了，通知生产者生产，生产到了再继续消费。 public static void main(String[] args) throws InterruptedException { MessageQueue queue = new MessageQueue(2); // 三个生产者向队列里存值 for (int i = 0; i &amp;lt; 3; i++) { int id = i; new Thread(() -&amp;gt; { queue.put(new Message(id, &quot;值&quot; + id)); }, &quot;生产者&quot; + i).start(); } Thread.sleep(1000); // 一个消费者不停的从队列里取值 new Thread(() -&amp;gt; { while (true) { queue.take(); } }, &quot;消费者&quot;).start(); }}// 消息队列被生产者和消费者持有class MessageQueue { private LinkedList&amp;lt;Message&amp;gt; list = new LinkedList&amp;lt;&amp;gt;(); // 容量 private int capacity; public MessageQueue(int capacity) { this.capacity = capacity; } /** * 生产 */ public void put(Message message) { synchronized (list) { while (list.size() == capacity) { log.info(&quot;队列已满，生产者等待&quot;); try { list.wait(); } catch (InterruptedException e) { e.printStackTrace(); } } list.addLast(message); log.info(&quot;生产消息:{}&quot;, message); // 生产后通知消费者 list.notifyAll(); } } public Message take() { synchronized (list) { while (list.isEmpty()) { log.info(&quot;队列已空，消费者等待&quot;); try { list.wait(); } catch (InterruptedException e) { e.printStackTrace(); } } Message message = list.removeFirst(); log.info(&quot;消费消息:{}&quot;, message); // 消费后通知生产者 list.notifyAll(); return message; } }} // 消息class Message { private int id; private Object value;}同步锁案例为了更形象的表达加同步锁的概念，这里举一个生活中的例子，尽量把以上的概念具体化出来。现实中，我们去银行门口的自动取款机取钱，取款机的钱就是共享变量，为了保障安全，不可能两个陌生人同时进入同一个取款机内取钱，所以只能一个人进入取钱，然后锁上取款机的门，其他人只能在取款机门口等待。取款机有多个，里面的钱互不影响，锁也有多个（多个对象锁），取钱人在多个取款机里同时取钱也没有安全问题。假如每个取钱的陌生人都是线程，当取钱人进入取款机锁了门后(线程获得锁)，取到钱后出门(线程释放锁)，下一个人竞争到锁来取钱。假设工作人员也是一个线程,如果取钱人进入后发现取款机钱不足了，这时通知工作人员来向取款机里加钱(调用notifyAll方法)，取钱人暂停取钱，进入银行大堂阻塞等待(调用wait方法)。银行大堂里的工作人员和取钱人都被唤醒，重新竞争锁，进入后如果是取钱人，由于取款机没钱，还得进入银行大堂等待。当工作人员获得取款机的锁进入后，加了钱后会通知大厅里的人来取钱(调用notifyAll方法)。自己暂停加钱，进入银行大堂等待唤醒加钱(调用wait方法)。这时大堂里等待的人都来竞争锁，谁获取到谁进入继续取钱。和现实中不同的就是这里没有排队的概念，谁抢到锁谁进去取。ReentrantLock可重入锁 : 一个线程获取到对象的锁后，执行方法内部在需要获取锁的时候是可以获取到的。如以下代码private static final ReentrantLock LOCK = new ReentrantLock();private static void m() { LOCK.lock(); try { log.info(&quot;begin&quot;); // 调用m1() m1(); } finally { // 注意锁的释放 LOCK.unlock(); }}public static void m1() { LOCK.lock(); try { log.info(&quot;m1&quot;); m2(); } finally { // 注意锁的释放 LOCK.unlock(); }}synchronized 也是可重入锁，ReentrantLock有以下优点 支持获取锁的超时时间 获取锁时可被打断 可设为公平锁 可以有不同的条件变量，即有多个waitSet，可以指定唤醒api// 默认非公平锁，参数传true 表示未公平锁ReentrantLock lock = new ReentrantLock(false);// 尝试获取锁lock()// 释放锁 应放在finally块中 必须执行到unlock()try { // 获取锁时可被打断,阻塞中的线程可被打断 LOCK.lockInterruptibly();} catch (InterruptedException e) { return;}// 尝试获取锁 获取不到就返回falseLOCK.tryLock()// 支持超时时间 一段时间没获取到就返回falsetryLock(long timeout, TimeUnit unit)// 指定条件变量 休息室 一个锁可以创建多个休息室Condition waitSet = ROOM.newCondition();// 释放锁 进入waitSet等待 释放后其他线程可以抢锁yanWaitSet.await()// 唤醒具体休息室的线程 唤醒后 重写竞争锁yanWaitSet.signal()实例：一个线程输出a，一个线程输出b，一个线程输出c，abc按照顺序输出，连续输出5次这个考的就是线程的通信，利用 wait()/notify()和控制变量可以实现，此处使用ReentrantLock即可实现该功能。 public static void main(String[] args) { AwaitSignal awaitSignal = new AwaitSignal(5); // 构建三个条件变量 Condition a = awaitSignal.newCondition(); Condition b = awaitSignal.newCondition(); Condition c = awaitSignal.newCondition(); // 开启三个线程 new Thread(() -&amp;gt; { awaitSignal.print(&quot;a&quot;, a, b); }).start(); new Thread(() -&amp;gt; { awaitSignal.print(&quot;b&quot;, b, c); }).start(); new Thread(() -&amp;gt; { awaitSignal.print(&quot;c&quot;, c, a); }).start(); try { Thread.sleep(1000); } catch (InterruptedException e) { e.printStackTrace(); } awaitSignal.lock(); try { // 先唤醒a a.signal(); } finally { awaitSignal.unlock(); } }}class AwaitSignal extends ReentrantLock { // 循环次数 private int loopNumber; public AwaitSignal(int loopNumber) { this.loopNumber = loopNumber; } /** * @param print 输出的字符 * @param current 当前条件变量 * @param next 下一个条件变量 */ public void print(String print, Condition current, Condition next) { for (int i = 0; i &amp;lt; loopNumber; i++) { lock(); try { try { // 获取锁之后等待 current.await(); System.out.print(print); } catch (InterruptedException e) { } next.signal(); } finally { unlock(); } } }死锁说到死锁,先举个例子，下面是代码实现static Beer beer = new Beer();static Story story = new Story();public static void main(String[] args) { new Thread(() -&amp;gt;{ synchronized (beer){ log.info(&quot;我有酒，给我故事&quot;); try { Thread.sleep(1000); } catch (InterruptedException e) { e.printStackTrace(); } synchronized (story){ log.info(&quot;小王开始喝酒讲故事&quot;); } } },&quot;小王&quot;).start(); new Thread(() -&amp;gt;{ synchronized (story){ log.info(&quot;我有故事，给我酒&quot;); try { Thread.sleep(1000); } catch (InterruptedException e) { e.printStackTrace(); } synchronized (beer){ log.info(&quot;老王开始喝酒讲故事&quot;); } } },&quot;老王&quot;).start();}class Beer {}class Story{}死锁导致程序无法正常运行下去Java内存模型(JMM)JMM 体现在以下三个方面 原子性 保证指令不会受到上下文切换的影响 可见性 保证指令不会受到cpu缓存的影响 有序性 保证指令不会受并行优化的影响可见性停不下来的程序static boolean run = true;public static void main(String[] args) throws InterruptedException { Thread t = new Thread(() -&amp;gt; { while (run) { // .... } }); t.start(); Thread.sleep(1000); // 线程t不会如预想的停下来 run = false; }如上图所示，线程有自己的工作缓存，当主线程修改了变量并同步到主内存时，t线程没有读取到，所以程序停不下来有序性JVM在不影响程序正确性的情况下可能会调整语句的执行顺序，该情况也称为 指令重排序 static int i; static int j;// 在某个线程内执行如下赋值操作 i = ...; j = ...; 有可能将j先赋值原子性原子性大家应该比较熟悉，上述同步锁的synchronized代码块就是保证了原子性，就是一段代码是一个整体，原子性保证了线程安全，不会受到上下文切换的影响。volatile该关键字解决了可见性和有序性，volatile通过内存屏障来实现的 写屏障 会在对象写操作之后加写屏障，会对写屏障的之前的数据都同步到主存，并且保证写屏障的执行顺序在写屏障之前 读屏障 会在对象读操作之前加读屏障，会在读屏障之后的语句都从主存读，并保证读屏障之后的代码执行在读屏障之后 注意： volatile不能解决原子性，即不能通过该关键字实现线程安全。volatile应用场景：一个线程读取变量，另外的线程操作变量，加了该关键字后保证写变量后，读变量的线程可以及时感知。无锁-cascas （compare and swap) 比较并交换为变量赋值时，从内存中读取到的值v，获取到要交换的新值n，执行 compareAndSwap()方法时，比较v和当前内存中的值是否一致，如果一致则将n和v交换，如果不一致，则自旋重试。cas底层是cpu层面的，即不使用同步锁也可以保证操作的原子性。private AtomicInteger balance;// 模拟cas的具体操作@Overridepublic void withdraw(Integer amount) { while (true) { // 获取当前值 int pre = balance.get(); // 进行操作后得到新值 int next = pre - amount; // 比较并设置成功 则中断 否则自旋重试 if (balance.compareAndSet(pre, next)) { break; } }}无锁的效率是要高于之前的锁的，由于无锁不会涉及线程的上下文切换cas是乐观锁的思想，sychronized是悲观锁的思想cas适合很少有线程竞争的场景，如果竞争很强，重试经常发生，反而降低效率juc并发包下包含了实现了cas的原子类 AtomicInteger/AtomicBoolean/AtomicLong AtomicIntegerArray/AtomicLongArray/AtomicReferenceArray AtomicReference/AtomicStampedReference/AtomicMarkableReferenceAtomicIntegernew AtomicInteger(balance)get()compareAndSet(pre, next)// i.incrementAndGet() ++i// i.decrementAndGet() --i// i.getAndIncrement() i++// i.getAndDecrement() ++i i.addAndGet() // 传入函数式接口 修改i int getAndUpdate(IntUnaryOperator updateFunction) // cas 的核心方法 compareAndSet(int expect, int update)ABA问题cas存在ABA问题，即比较并交换时，如果原值为A,有其他线程将其修改为B，在有其他线程将其修改为A。此时实际发生过交换，但是比较和交换由于值没改变可以交换成功解决方式AtomicStampedReference/AtomicMarkableReference上面两个类解决ABA问题，原理就是为对象增加版本号,每次修改时增加版本号，就可以避免ABA问题或者增加个布尔变量标识，修改后调整布尔变量值，也可以避免ABA问题线程池线程池的介绍线程池是Java并发最重要的一个知识点，也是难点，是实际应用最广泛的。线程的资源很宝贵，不可能无限的创建，必须要有管理线程的工具，线程池就是一种管理线程的工具，Java开发中经常有池化的思想，如 数据库连接池、Redis连接池等。预先创建好一些线程，任务提交时直接执行，既可以节约创建线程的时间，又可以控制线程的数量。线程池的好处 降低资源消耗，通过池化思想，减少创建线程和销毁线程的消耗，控制资源 提高响应速度，任务到达时，无需创建线程即可运行 提供更多更强大的功能，可扩展性高线程池的构造方法public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&amp;lt;Runnable&amp;gt; workQueue, ThreadFactory threadFactory, RejectedExecutionHandler handler) { }构造器参数的意义 参数名 参数意义 corePoolSize 核心线程数 maximumPoolSize 最大线程数 keepAliveTime 救急线程的空闲时间 unit 救急线程的空闲时间单位 workQueue 阻塞队列 threadFactory 创建线程的工厂，主要定义线程名 handler 拒绝策略 线程池案例下面 我们通过一个实例来理解线程池的参数以及线程池的接收任务的过程如上图 银行办理业务。 客户到银行时，开启柜台进行办理，柜台相当于线程，客户相当于任务，有两个是常开的柜台，三个是临时柜台。2就是核心线程数，5是最大线程数。即有两个核心线程 当柜台开到第二个后，都还在处理业务。客户再来就到排队大厅排队。排队大厅只有三个座位。 排队大厅坐满时，再来客户就继续开柜台处理，目前最大有三个临时柜台，也就是三个救急线程 此时再来客户，就无法正常为其 提供业务，采用拒绝策略来处理它们 当柜台处理完业务，就会从排队大厅取任务，当柜台隔一段空闲时间都取不到任务时，如果当前线程数大于核心线程数时，就会回收线程。即撤销该柜台。线程池的状态线程池通过一个int变量的高3位来表示线程池的状态，低29位来存储线程池的数量 状态名称 高三位 接收新任务 处理阻塞队列任务 说明 Running 111 Y Y 正常接收任务，正常处理任务 Shutdown 0 N Y 不会接收任务,会执行完正在执行的任务,也会处理阻塞队列里的任务 stop 1 N N 不会接收任务，会中断正在执行的任务,会放弃处理阻塞队列里的任务 Tidying 10 N N 任务全部执行完毕，当前活动线程是0，即将进入终结 Termitted 11 N N 终结状态 // runState is stored in the high-order bitsprivate static final int RUNNING = -1 &amp;lt;&amp;lt; COUNT_BITS;private static final int SHUTDOWN = 0 &amp;lt;&amp;lt; COUNT_BITS;private static final int STOP = 1 &amp;lt;&amp;lt; COUNT_BITS;private static final int TIDYING = 2 &amp;lt;&amp;lt; COUNT_BITS;private static final int TERMINATED = 3 &amp;lt;&amp;lt; COUNT_BITS;线程池的主要流程线程池创建、接收任务、执行任务、回收线程的步骤 创建线程池后，线程池的状态是Running，该状态下才能有下面的步骤 提交任务时，线程池会创建线程去处理任务 当线程池的工作线程数达到corePoolSize时，继续提交任务会进入阻塞队列 当阻塞队列装满时，继续提交任务，会创建救急线程来处理 当线程池中的工作线程数达到maximumPoolSize时，会执行拒绝策略 当线程取任务的时间达到keepAliveTime还没有取到任务，工作线程数大于corePoolSize时，会回收该线程注意： 不是刚创建的线程是核心线程，后面创建的线程是非核心线程，线程是没有核心非核心的概念的，这是我长期以来的误解。拒绝策略 调用者抛出RejectedExecutionException (默认策略) 让调用者运行任务 丢弃此次任务 丢弃阻塞队列中最早的任务，加入该任务提交任务的方法// 执行Runnablepublic void execute(Runnable command) { if (command == null) throw new NullPointerException(); int c = ctl.get(); if (workerCountOf(c) &amp;lt; corePoolSize) { if (addWorker(command, true)) return; c = ctl.get(); } if (isRunning(c) &amp;amp;&amp;amp; workQueue.offer(command)) { int recheck = ctl.get(); if (! isRunning(recheck) &amp;amp;&amp;amp; remove(command)) reject(command); else if (workerCountOf(recheck) == 0) addWorker(null, false); } else if (!addWorker(command, false)) reject(command);}// 提交Callablepublic &amp;lt;T&amp;gt; Future&amp;lt;T&amp;gt; submit(Callable&amp;lt;T&amp;gt; task) { if (task == null) throw new NullPointerException(); // 内部构建FutureTask RunnableFuture&amp;lt;T&amp;gt; ftask = newTaskFor(task); execute(ftask); return ftask;}// 提交Runnable,指定返回值public Future&amp;lt;?&amp;gt; submit(Runnable task) { if (task == null) throw new NullPointerException(); // 内部构建FutureTask RunnableFuture&amp;lt;Void&amp;gt; ftask = newTaskFor(task, null); execute(ftask); return ftask;} // 提交Runnable,指定返回值public &amp;lt;T&amp;gt; Future&amp;lt;T&amp;gt; submit(Runnable task, T result) { if (task == null) throw new NullPointerException(); // 内部构建FutureTask RunnableFuture&amp;lt;T&amp;gt; ftask = newTaskFor(task, result); execute(ftask); return ftask;}protected &amp;lt;T&amp;gt; RunnableFuture&amp;lt;T&amp;gt; newTaskFor(Runnable runnable, T value) { return new FutureTask&amp;lt;T&amp;gt;(runnable, value);}Execetors创建线程池 注意： 下面几种方式都不推荐使用newFixedThreadPoolpublic static ExecutorService newFixedThreadPool(int nThreads) { return new ThreadPoolExecutor(nThreads, nThreads, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&amp;lt;Runnable&amp;gt;());} 核心线程数 = 最大线程数 没有救急线程 阻塞队列无界 可能导致oomnewCachedThreadPoolpublic static ExecutorService newCachedThreadPool() { return new ThreadPoolExecutor(0, Integer.MAX_VALUE, 60L, TimeUnit.SECONDS, new SynchronousQueue&amp;lt;Runnable&amp;gt;());} 核心线程数是0，最大线程数无限制 ，救急线程60秒回收 队列采用 SynchronousQueue 实现 没有容量，即放入队列后没有线程来取就放不进去 可能导致线程数过多，cpu负担太大newSingleThreadExecutorpublic static ExecutorService newSingleThreadExecutor() { return new FinalizableDelegatedExecutorService (new ThreadPoolExecutor(1, 1, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&amp;lt;Runnable&amp;gt;()));} 核心线程数和最大线程数都是1，没有救急线程，无界队列 可以不停的接收任务 将任务串行化 一个个执行， 使用包装类是为了屏蔽修改线程池的一些参数 比如 corePoolSize 如果某线程抛出异常了，会重新创建一个线程继续执行 可能造成oomnewScheduledThreadPoolpublic static ScheduledExecutorService newScheduledThreadPool(int corePoolSize) { return new ScheduledThreadPoolExecutor(corePoolSize);} 任务调度的线程池 可以指定延迟时间调用，可以指定隔一段时间调用线程池的关闭shutdown()会让线程池状态为shutdown，不能接收任务，但是会将工作线程和阻塞队列里的任务执行完 相当于优雅关闭public void shutdown() { final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try { checkShutdownAccess(); advanceRunState(SHUTDOWN); interruptIdleWorkers(); onShutdown(); // hook for ScheduledThreadPoolExecutor } finally { mainLock.unlock(); } tryTerminate();}shutdownNow()会让线程池状态为stop， 不能接收任务，会立即中断执行中的工作线程，并且不会执行阻塞队列里的任务， 会返回阻塞队列的任务列表public List&amp;lt;Runnable&amp;gt; shutdownNow() { List&amp;lt;Runnable&amp;gt; tasks; final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try { checkShutdownAccess(); advanceRunState(STOP); interruptWorkers(); tasks = drainQueue(); } finally { mainLock.unlock(); } tryTerminate(); return tasks;}线程池的正确使用姿势线程池难就难在参数的配置，有一套理论配置参数 cpu密集型 : 指的是程序主要发生cpu的运算 ​核心线程数： CPU核心数+1 IO密集型: 远程调用RPC，操作数据库等，不需要使用cpu进行大量的运算。 大多数应用的场景 ​核心线程数=核数*cpu期望利用率 *总时间/cpu运算时间 但是基于以上理论还是很难去配置，因为cpu运算时间不好估算实际配置大小可参考下表 cpu密集型 io密集型   线程数数量 核数&amp;lt;=x&amp;lt;=核数*2 核心数*50&amp;lt;=x&amp;lt;=核心数*100 队列长度 y&amp;gt;=100 1&amp;lt;=y&amp;lt;=10 1.线程池参数通过分布式配置，修改配置无需重启应用线程池参数是根据线上的请求数变化而变化的，最好的方式是 核心线程数、最大线程数 队列大小都是可配置的主要配置 corePoolSize maxPoolSize queueSizeJava提供了可方法覆盖参数，线程池内部会处理好参数 进行平滑的修改public void setCorePoolSize(int corePoolSize) {}2.增加线程池的监控3.io密集型可调整为先新增任务到最大线程数后再将任务放到阻塞队列代码 主要可重写阻塞队列 加入任务的方法public boolean offer(Runnable runnable) { if (executor == null) { throw new RejectedExecutionException(&quot;The task queue does not have executor!&quot;); } final ReentrantLock lock = this.lock; lock.lock(); try { int currentPoolThreadSize = executor.getPoolSize(); // 如果提交任务数小于当前创建的线程数, 说明还有空闲线程, if (executor.getTaskCount() &amp;lt; currentPoolThreadSize) { // 将任务放入队列中，让线程去处理任务 return super.offer(runnable); } // 核心改动 // 如果当前线程数小于最大线程数，则返回 false ，让线程池去创建新的线程 if (currentPoolThreadSize &amp;lt; executor.getMaximumPoolSize()) { return false; } // 否则，就将任务放入队列中 return super.offer(runnable); } finally { lock.unlock(); }}4.绝策略 建议使用tomcat的拒绝策略(给一次机会)// tomcat的源码@Overridepublic void execute(Runnable command) { if ( executor != null ) { try { executor.execute(command); } catch (RejectedExecutionException rx) { // 捕获到异常后 在从队列获取，相当于重试1取不到任务 在执行拒绝任务 if ( !( (TaskQueue) executor.getQueue()).force(command) ) throw new RejectedExecutionException(&quot;Work queue full.&quot;); } } else throw new IllegalStateException(&quot;StandardThreadPool not started.&quot;);}建议修改从队列取任务的方式： 增加超时时间，超时1分钟取不到在进行返回public boolean offer(E e, long timeout, TimeUnit unit){}" }, { "title": "Java 注解使用", "url": "/posts/java-annotation-usage/", "categories": "Software Development", "tags": "Java", "date": "2020-11-13 14:40:00 +0800", "snippet": "注解概述注解的定义注解，顾名思义，就是对某一事物添加注释说明，其会存放一些信息，这些信息可能对以后某个时段来说是很有用处的。Java注解又叫java标注，java提供了一套机制，使得我们可以对包、类、方法、域、参数、变量等添加标注(即附上某些信息)，且在以后某个时段通过反射将标注的信息提取出来以供使用官网描述如下: Java 注解用于为 Java 代码提供元数据。作为元数据，注解不直接影响你的代码执行，但也有一些类型的注解实际上可以用于这一目的。Java 注解是从 Java5 开始添加到 Java 的。将上面的话再翻译一下，如下： 元数据在开发中的作用就是做数据约束和标准定义，可以将其理解成代码的规范标准（代码的模板）； 代码的模板（元数据）不直接影响代码的执行，它只是帮助我们来更快捷的开发；综上，注解是一种元数据，可以将它理解为注释、解释，它为我们在代码中添加信息提供了一种形式化的方法，它用于帮助我们更快捷的写代码。注解的作用在说注解的用途之前，我们先介绍下XML和注解区别：注解：是一种分散式的元数据，与源代码紧绑定。xml：是一种集中式的元数据，与源代码无绑定这部分多用于Java后台的配置项开发中，我们知道几年前服务器的配置项多存放在一个xml文件中，而spring 2.5 之后开始基于注解配置，从而实现了代替配置文件的功能。注解的用途有很多，上面的只是一个简单的例子，总起起来，注解有如下四大部分作用： 生成文档，通过代码里标识的元数据生成javadoc文档。 编译检查，通过代码里标识的元数据让编译器在编译期间进行检查验证。 编译时动态处理，编译时通过代码里标识的元数据动态处理，例如动态生成代码。 运行时动态处理，运行时通过代码里标识的元数据动态处理，例如使用反射注入实例注解的分类一般常用的注解可以分为三类： Java自带的标准注解包括@Override、@Deprecated、@SuppressWarnings等，使用这些注解后编译器就会进行检查。 元注解元注解是用于定义注解的注解，包括@Retention、@Target、@Inherited、@Documented、@Repeatable 等。元注解也是Java自带的标准注解，只不过用于修饰注解，比较特殊。 自定义注解用户可以根据自己的需求定义注解。 Java自带的标准注解常用的Java注解如下： @Deprecated – 所标注内容不再被建议使用； @Override – 只能标注方法，表示该方法覆盖父类中的方法； @Documented - 所标注内容可以出现在javadoc中； @Inherited – 只能被用来标注“Annotation类型”，它所标注的Annotation具有继承性； @Retention – 只能被用来标注“Annotation类型”，而且它被用来指定Annotation的RetentionPolicy属性； @Target – 只能被用来标注“Annotation类型”，而且它被用来指定Annotation的ElementType属性； @SuppressWarnings – 所标注内容产生的警告，编译器会对这些警告保持静默； @interface – 用于定义一个注解； 其中，4、5、6、8多用于自定义注解，着重记一下。元注解常用的元注解有@Retention、 @Target、 @Document、 @Inherited和@Repeatable五个。@RetentionRetention英文意思有保留、保持的意思，它表示注解存在阶段是保留在源码（编译期），字节码（类加载）或者运行期（JVM中运行）。在@Retention注解中使用枚举RetentionPolicy来表示注解保留时期： @Retention(RetentionPolicy.SOURCE)，注解仅存在于源码中，在class字节码文件中不包含 @Retention(RetentionPolicy.CLASS)， 默认的保留策略，注解会在class字节码文件中存在，但运行时无法获得 @Retention(RetentionPolicy.RUNTIME)， 注解会在class字节码文件中存在，在运行时可以通过反射获取到, 操作方法看AnnotatedElement(所有被注释类的父类)如果我们是自定义注解，则通过前面分析，我们自定义注解如果只存着源码中或者字节码文件中就无法发挥作用，而在运行期间能获取到注解才能实现我们目的，所以自定义注解中肯定是使用 @Retention(RetentionPolicy.RUNTIME)，如下：@Retention(RetentionPolicy.RUNTIME) public @interface MyTestAnnotation {}@TargetTarget的英文意思是目标，这也很容易理解，使用@Target元注解表示我们的注解作用的范围就比较具体了，可以是类，方法，方法参数变量等，同样也是通过枚举类ElementType表达作用类型： @Target(ElementType.TYPE) 作用接口、类、枚举、注解 @Target(ElementType.FIELD) 作用属性字段、枚举的常量 @Target(ElementType.METHOD) 作用方法 @Target(ElementType.PARAMETER) 作用方法参数 @Target(ElementType.CONSTRUCTOR) 作用构造函数 @Target(ElementType.LOCAL_VARIABLE)作用局部变量 @Target(ElementType.ANNOTATION_TYPE)作用于注解（@Retention注解中就使用该属性） @Target(ElementType.PACKAGE) 作用于包 @Target(ElementType.TYPE_PARAMETER) 作用于类型泛型，即泛型方法、泛型类、泛型接口 （jdk1.8加入） @Target(ElementType.TYPE_USE) 类型使用.可以用于标注任意类型除了 class （jdk1.8加入）一般比较常用的是ElementType.TYPE类型，如下： @Retention(RetentionPolicy.RUNTIME) @Target(ElementType.TYPE) public @interface MyTestAnnotation { }ElementType.TYPE_PARAMETER的用法示例class D&amp;lt;@PTest T&amp;gt; { } // 注解@PTest作用于泛型TElementType.TYPE_USE的用法示例//用于父类或者接口 class Test implements @Parent TestP {} //用于构造函数new @Test String(&quot;/usr/data&quot;)//用于强制转换和instanceof检查,注意这些注解中用于外部工具//它们不会对类型转换或者instanceof的检查行为带来任何影响String path=(@Test String)input;if(input instanceof @Test String) //注解不会影响//用于指定异常public Person read() throws @Test IOException.//用于通配符绑定List&amp;lt;@Test ? extends Data&amp;gt;List&amp;lt;? extends @Test Data&amp;gt;@Test String.class //非法，不能标注class@DocumentDocument的英文意思是文档。它的作用是能够将注解中的元素包含到 Javadoc 中去。@InheritedInherited的英文意思是继承，但是这个继承和我们平时理解的继承大同小异，一个被@Inherited注解了的注解修饰了一个父类，如果他的子类没有被其他注解修饰，则它的子类也继承了父类的注解。子类Class&amp;lt;T&amp;gt;通过getAnnotations()可获取父类被@Inherited修饰的注解。而注解本身是不支持继承@Inherited@Retention( value = RetentionPolicy.RUNTIME)@Target(value = ElementType.TYPE)public @interface ATest { }----被ATest注解的父类PTest----@ATestpublic class PTest{ }---Main是PTest的子类----public class Main extends PTest { public static void main(String[] args){ Annotation an = Main.class.getAnnotations()[0]; //Main可以拿到父类的注解ATest，因为ATest被元注解@Inherited修饰 System.out.println(an); }} ---result--@com.ATest() @RepeatableJDK1.8新加入的，表明自定义的注解可以在同一个位置重复使用。在没有该注解前，是无法在同一个类型上使用相同的注解多次Repeatable的英文意思是可重复的。顾名思义说明被这个元注解修饰的注解可以同时作用一个对象多次，但是每次作用注解又可以代表不同的含义。 //Java8前无法重复使用注解 @FilterPath(&quot;/test/v2&quot;) @FilterPath(&quot;/test/v1&quot;) public class Test {}自定义注解在Java中，我们使用@interface注解来自定义一个注解，如下：public @interface MyTestAnnotation {}此时，我们已经定义了一个注解MyTestAnnotation ，接着我们就可以在类或者方法上作用我们刚刚新建的注解：@MyTestAnnotationpublic class Test { @MyTestAnnotation public static void testString(){ }}此时，我们已经自定义了一个注解，不过现在这个注解毫无意义。要如何使注解工作呢？这就需要使用元注解了。这时候就需要使用java内置的四个元注解对自定义注解的功能和范围进行一些限制注解的使用使用Java自带的注解Java 自带的注解，就是 java.lang中定义的一套注解，以Override注解为例，使用方法如下：@Override //在需要注解的方法上面@Override即可protected void onCreate() { }自定义注解使用@interface自定义注解时，自动继承了java.lang.annotation.Annotation接口，由编译程序自动完成其他细节。在定义注解时，不能继承其他的注解或接口。@interface用来声明一个注解，其中的每一个方法实际上是声明了一个配置参数。方法的名称就是参数的名称，返回值类型就是参数的类型（返回值类型只能是基本类型、Class、String、enum）。可以通过default来声明参数的默认值。定义注解格式public @interface 注解名 {定义体}注解参数的可支持数据类型 所有基本数据类型（int,float,boolean,byte,double,char,long,short) String类型 Class类型 enum类型 Annotation类型 以上所有类型的数组下面通过源码来展示自定义注解：首先，我们自定义一个注解：AuthorAnnotation 来标记作者的信息/** * 自定义注解：作者信息注解 */@Target(ElementType.FIELD)@Retention(RetentionPolicy.RUNTIME)@Documentedpublic @interface AuthorAnnotation { // 名字 String name(); // 年龄 int age() default 19; // 性别 String gender() default &quot;男&quot;;}其次，再定义一个注解：BookAnnotation 来标记故事书籍的内容信息/** * 自定义注解：树的信息注解 */@Target({ ElementType.TYPE, ElementType.METHOD })@Retention(RetentionPolicy.RUNTIME)@Documented@Inheritedpublic @interface BookAnnotation { // 书名 String bookName(); // 女主人公 String heroine(); // 书的简介 String briefOfBook(); // 书的销量 int sales() default 10000;}最后，我们定义一种类型的书：LoveStoryBook，类注解标记的是《硅谷之火》，为了区分，方法注解标记的是《think in java》/** * 爱的故事 */@BookAnnotation(bookName = &quot;硅谷之火&quot;, briefOfBook = &quot;本书以一个个生动的故事，介绍了这些计算机业余爱好者以怎样的创新精神和不懈的努力，将计算机技术的力量包装在一个小巧玲珑的机壳里，实现了个人拥有计算机的梦想&quot;, sales = 1000001)public class LoveStoryBook { @AuthorAnnotation(name = &quot;迈克尔.斯韦因&quot;, gender = &quot;男&quot;) private String user; @BookAnnotation(bookName = &quot;think in java&quot;, briefOfBook = &quot;本书详细地阐述了面向对象原理。覆盖了所有基础知识,同时论述了高级特性,适合初学者与专业人员的经典的面向对象叙述方式,为更新的Java SE5/6增加了新的示例和章节&quot;, sales = 100000) public void getBookInfo(){ }}注解解析上面已经将要注解的类和两个注解类实现了，下面定义一个类：ParseAnnotation，来解析我们自定义的注解public class ParseAnnotation { /** * * 解析类注解 * LoveStoryBook * @throws ClassNotFoundException */ public static void parseTypeAnnotation() throws ClassNotFoundException{ @SuppressWarnings(&quot;rawtypes&quot;) Class clazz = Class.forName(&quot;com.akathink.entity.LoveStoryBook&quot;); Annotation[] annotations = clazz.getAnnotations(); for (Annotation annotation : annotations) { BookAnnotation bookAnnotation = (BookAnnotation) annotation; System.out.println(&quot;书名：&quot; + bookAnnotation.bookName() + &quot;\\n&quot; + &quot;书的简介：&quot; + bookAnnotation.briefOfBook() + &quot;\\n&quot;+ &quot;书的销量：&quot; + bookAnnotation .sales() + &quot;\\n&quot;); } } /** * 解析方法注解 * @throws ClassNotFoundException */ public static void parseMethodAnnotation() throws ClassNotFoundException{ Method[] methods = LoveStoryBook.class.getDeclaredMethods(); for (Method method : methods) { /* * 判断方法中是否有指定注解类型的注解 */ boolean hasAnnotation = method.isAnnotationPresent(BookAnnotation.class); if(hasAnnotation){ BookAnnotation bookAnnotation = (BookAnnotation) method.getAnnotation(BookAnnotation.class); System.out.println(&quot;书名：&quot; + bookAnnotation.bookName() + &quot;\\n&quot; + &quot;书的简介：&quot; + bookAnnotation.briefOfBook() + &quot;\\n&quot;+ &quot;书的销量：&quot; + bookAnnotation .sales() + &quot;\\n&quot;); } } } /** * 解析域注解 * @throws ClassNotFoundException */ public static void parseFieldAnnotation() throws ClassNotFoundException{ Field[] fields = LoveStoryBook.class.getDeclaredFields(); for (Field field : fields) { boolean hasAnnotation = field.isAnnotationPresent(AuthorAnnotation.class); if(hasAnnotation){ AuthorAnnotation authorAnnotation = field.getAnnotation(AuthorAnnotation.class); System.out.println(&quot;作者：&quot; +authorAnnotation.name() + &quot;\\n&quot; + &quot;性别：&quot; + authorAnnotation.gender() + &quot;\\n&quot;); } } }}最后的最后就是验证我们自定义的注解是否正确public class AnnotationDemo { public static void main(String[] args) throws ClassNotFoundException { //解析域的注解 System.out.println(&quot;下面是解析域的注解信息：\\n\\n&quot;); ParseAnnotation.parseFieldAnnotation(); //解析方法的注解 System.out.println(&quot;下面是解析方法的注解信息：\\n\\n&quot;); ParseAnnotation.parseMethodAnnotation(); //解析类的注解 System.out.println(&quot;下面是解析类的注解信息:\\n\\n&quot;); ParseAnnotation.parseTypeAnnotation(); }}下面是解析域的注解信息：作者：迈克尔.斯韦因性别：男下面是解析方法的注解信息：书名：think in java书的简介：本书详细地阐述了面向对象原理。覆盖了所有基础知识,同时论述了高级特性,适合初学者与专业人员的经典的面向对象叙述方式,为更新的Java SE5/6增加了新的示例和章节书的销量：100000下面是解析类的注解信息:书名：硅谷之火书的简介：本书以一个个生动的故事，介绍了这些计算机业余爱好者以怎样的创新精神和不懈的努力，将计算机技术的力量包装在一个小巧玲珑的机壳里，实现了个人拥有计算机的梦想书的销量：1000001 注意 对局部变量的注解只能在源码级别上进行处理，class文件并不描述局部变量。因此，所有的局部变量注解在编译完一个类的时候就会被遗弃掉。同样的，对包的注解不能在源码级别之外存在。 一条没有@Target限制的注解可以应用于任何项上。 @Inherited元注解只能应用于对类的注解 通过反射访问注解程序通过反射获取了某个类的对象之后，程序就可以调用该对象的如下四个方法来访问注解信息： 方法1： T getAnnotation(Class annotationClass)：返回该程序元素上存在的、指定类型的注解，如果该类型注解不存在，则返回null 方法2：Annotation[] getAnnotations()：返回该程序元素上存在的所有注解 方法3：boolean is AnnotationPresent(Class&amp;lt;?extends Annotation&amp;gt; annotationClass)：判断该程序元素上是否包含指定类型的注解，存在，则返回true；否则，返回false 方法4：Annotation[] getDeclaredAnnotations()：返回直接存在于此元素上的所有注解。与其他方法不同的是，该方法将忽略继承的注释。如果没有注解直接存在于此元素上，则返回长度为零的一个数组，该方法的调用者可以随意修改返回的数组，可是，这不会对其他调用者返回的数组产生任何影响。" }, { "title": "Java 反射使用方法", "url": "/posts/java-reflection-usage/", "categories": "Software Development", "tags": "Java", "date": "2020-10-23 15:28:00 +0800", "snippet": "反射基础什么是反射反射 (Reflection) 是 Java 的特征之一，它允许运行中的 Java 程序获取自身的信息，并且可以操作类或对象的内部属性。反射之中包含了一个「反」字，所以想要解释反射就必须先从「正」开始解释。一般情况下，我们使用某个类时必定知道它是什么类，是用来做什么的。于是我们直接对这个类进行实例化，之后使用这个类对象进行操作。Apple apple = new Apple(); //直接初始化，「正射」apple.setPrice(4);上面这样子进行类对象的初始化，我们可以理解为「正」。而反射则是一开始并不知道我要初始化的类对象是什么，自然也无法使用 new 关键字来创建对象了。这时候，我们使用 JDK 提供的反射 API 进行反射调用：Class clz = Class.forName(&quot;com.chenshuyi.reflect.Apple&quot;);Method method = clz.getMethod(&quot;setPrice&quot;, int.class);Constructor constructor = clz.getConstructor();Object object = constructor.newInstance();method.invoke(object, 4);上面两段代码的执行结果，其实是完全一样的。但是其思路完全不一样，第一段代码在未运行时就已经确定了要运行的类（Apple），而第二段代码则是在运行时通过字符串值才得知要运行的类（com.chenshuyi.reflect.Apple）。所以说什么是反射？ 反射就是在运行时才知道要操作的类是什么，并且可以在运行时获取类的完整构造，并调用对应的方法。Oracle 官方对反射的解释是： Reflection enables Java code to discover information about the fields, methods and constructors of loaded classes, and to use reflected fields, methods, and constructors to operate on their underlying counterparts, within security restrictions. The API accommodates applications that need access to either the public members of a target object (based on its runtime class) or the members declared by a given class. It also allows programs to suppress default reflective access control.简而言之，通过反射，我们可以在运行时获得程序或程序集中每一个类型的成员和成员的信息。程序中一般的对象的类型都是在编译期就确定下来的，而 Java 反射机制可以动态地创建对象并调用其属性，这样的对象的类型在编译期是未知的。所以我们可以通过反射机制直接创建对象，即使这个对象的类型在编译期是未知的。反射的核心是 JVM 在运行时才动态加载类或调用方法/访问属性，它不需要事先（写代码的时候或编译期）知道运行对象是谁。Java 反射主要提供以下功能： 在运行时判断任意一个对象所属的类； 在运行时构造任意一个类的对象； 在运行时判断任意一个类所具有的成员变量和方法（通过反射甚至可以调用private方法）； 在运行时调用任意一个对象的方法 重点：是运行时而不是编译时反射的主要用途很多人都认为反射在实际的 Java 开发应用中并不广泛，其实不然。当我们在使用 IDE(如 Eclipse，IDEA)时，当我们输入一个对象或类并想调用它的属性或方法时，一按点号，编译器就会自动列出它的属性或方法，这里就会用到反射。反射最重要的用途就是开发各种通用框架。很多框架（比如 Spring）都是配置化的（比如通过 XML 文件配置 Bean），为了保证框架的通用性，它们可能需要根据配置文件加载不同的对象或类，调用不同的方法，这个时候就必须用到反射，运行时动态加载需要加载的对象。举一个例子，在运用 Struts 2 框架的开发中我们一般会在 struts.xml 里去配置 Action，比如：&amp;lt;action name=&quot;login&quot; class=&quot;org.Optimus-Xs.test.action.SimpleLoginAction&quot; method=&quot;execute&quot;&amp;gt; &amp;lt;result&amp;gt;/shop/shop-index.jsp&amp;lt;/result&amp;gt; &amp;lt;result name=&quot;error&quot;&amp;gt;login.jsp&amp;lt;/result&amp;gt;&amp;lt;/action&amp;gt;配置文件与 Action 建立了一种映射关系，当 View 层发出请求时，请求会被 StrutsPrepareAndExecuteFilter 拦截，然后 StrutsPrepareAndExecuteFilter 会去动态地创建 Action 实例。比如我们请求 login.action，那么 StrutsPrepareAndExecuteFilter就会去解析struts.xml文件，检索action中name为login的Action，并根据class属性创建SimpleLoginAction实例，并用invoke方法来调用execute方法，这个过程离不开反射。对与框架开发人员来说，反射虽小但作用非常大，它是各种容器实现的核心。而对于一般的开发者来说，不深入框架开发则用反射用的就会少一点，不过了解一下框架的底层机制有助于丰富自己的编程思想，也是很有益的。Class类RTIT（Run-Time Type Identification）运行时类型识别。在《Thinking in Java》一书第十四章中有提到，其作用是在运行时识别一个对象的类型和类的信息。主要有两种方式：一种是“传统的”RTTI，它假定我们在编译时已经知道了所有的类型；另一种是“反射”机制，它允许我们在运行时发现和使用类的信息。反射就是把java类中的各种成分映射成一个个的Java对象例如：一个类有：成员变量、方法、构造方法、包等等信息，利用反射技术可以对一个类进行解剖，把个个组成部分映射成一个个对象。 这里我们首先需要理解 Class类，以及类的加载机制； 然后基于此我们如何通过反射获取Class类以及类中的成员变量、方法、构造方法等。Class类，Class类也是一个实实在在的类，存在于JDK的java.lang包中。Class类的实例表示java应用运行时的类(class ans enum)或接口(interface and annotation)（每个java类运行时都在JVM里表现为一个class对象，可通过类名.class、类型.getClass()、Class.forName(“类名”)等方法获取class对象）。数组同样也被映射为class 对象的一个类，所有具有相同元素类型和维数的数组都共享该 Class 对象。基本类型boolean，byte，char，short，int，long，float，double和关键字void同样表现为 class 对象。public final class Class&amp;lt;T&amp;gt; implements java.io.Serializable, GenericDeclaration, Type, AnnotatedElement { private static final int ANNOTATION= 0x00002000; private static final int ENUM = 0x00004000; private static final int SYNTHETIC = 0x00001000; private static native void registerNatives(); static { registerNatives(); } /* * Private constructor. Only the Java Virtual Machine creates Class objects. //私有构造器，只有JVM才能调用创建Class对象 * This constructor is not used and prevents the default constructor being * generated. */ private Class(ClassLoader loader) { // Initialize final field for classLoader. The initialization value of non-null // prevents future JIT optimizations from assuming this final field is null. classLoader = loader; }到这我们也就可以得出以下几点信息： Class类也是类的一种，与class关键字是不一样的。 手动编写的类被编译后会产生一个Class对象，其表示的是创建的类的类型信息，而且这个Class对象保存在同名.class的文件中(字节码文件) 每个通过关键字class标识的类，在内存中有且只有一个与之对应的Class对象来描述其类型信息，无论创建多少个实例对象，其依据的都是用一个Class对象。 Class类只存私有构造函数，因此对应Class对象只能有JVM创建和加载 Class类的对象作用是运行时提供或获得某个对象的类型信息，这点对于反射技术很重要(关于反射稍后分析)。反射的API使用在Java中，Class类与java.lang.reflect类库一起对反射技术进行了全力的支持。在反射包中，我们常用的类主要有Constructor类表示的是Class 对象所表示的类的构造方法，利用它可以在运行时动态创建对象、Field表示Class对象所表示的类的成员变量，通过它可以在运行时动态修改成员变量的属性值(包含private)、Method表示Class对象所表示的类的成员方法，通过它可以动态调用对象的方法(包含private)，下面将对这几个重要类进行分别说明。Class类对象的获取在类加载的时候，jvm会创建一个class对象class对象是可以说是反射中最常用的，获取class对象的方式的主要有三种 根据类名：类名.class 根据对象：对象.getClass() 根据全限定类名：Class.forName(全限定类名) @Test public void classTest() throws Exception { // 获取Class对象的三种方式 logger.info(&quot;根据类名: \\t&quot; + User.class); logger.info(&quot;根据对象: \\t&quot; + new User().getClass()); logger.info(&quot;根据全限定类名:\\t&quot; + Class.forName(&quot;com.test.User&quot;)); // 常用的方法 logger.info(&quot;获取全限定类名:\\t&quot; + userClass.getName()); logger.info(&quot;获取类名:\\t&quot; + userClass.getSimpleName()); logger.info(&quot;实例化:\\t&quot; + userClass.newInstance()); } // ... package com.test; public class User { private String name = &quot;init&quot;; private int age; public User() {} public User(String name, int age) { super(); this.name = name; this.age = age; } private String getName() { return name; } private void setName(String name) { this.name = name; } public int getAge() { return age; } public void setAge(int age) { this.age = age; } @Override public String toString() { return &quot;User [name=&quot; + name + &quot;, age=&quot; + age + &quot;]&quot;; } }输出结果：根据类名: class com.test.User根据对象: class com.test.User根据全限定类名: class com.test.User获取全限定类名: com.test.User获取类名: User实例化: User [name=init, age=0]再来看看 Class类的方法 方法名 说明 forName() (1)获取Class对象的一个引用，但引用的类还没有加载(该类的第一个对象没有生成)就加载了这个类。 (2)为了产生Class引用，forName()立即就进行了初始化。 Object-getClass() 获取Class对象的一个引用，返回表示该对象的实际类型的Class引用。 getName() 取全限定的类名(包括包名)，即类的完整名字。 getSimpleName() 获取类名(不包括包名) getCanonicalName() 获取全限定的类名(包括包名) isInterface() 判断Class对象是否是表示一个接口 getInterfaces() 返回Class对象数组，表示Class对象所引用的类所实现的所有接口。 getSupercalss() 返回Class对象，表示Class对象所引用的类所继承的直接基类。应用该方法可在运行时发现一个对象完整的继承结构。 newInstance() 返回一个Oject对象，是实现“虚拟构造器”的一种途径。使用该方法创建的类，必须带有无参的构造器。 getFields() 获得某个类的所有的公共（public）的字段，包括继承自父类的所有公共字段。 类似的还有getMethods和getConstructors。 getDeclaredFields() 获得某个类的自己声明的字段，即包括public、private和proteced，默认但是不包括父类声明的任何字段。类似的还有getDeclaredMethods和getDeclaredConstructors。 简单测试下interface I1 {}interface I2 {}class Cell{ public int mCellPublic;}class Animal extends Cell{ private int mAnimalPrivate; protected int mAnimalProtected; int mAnimalDefault; public int mAnimalPublic; private static int sAnimalPrivate; protected static int sAnimalProtected; static int sAnimalDefault; public static int sAnimalPublic;}class Dog extends Animal implements I1, I2 { private int mDogPrivate; public int mDogPublic; protected int mDogProtected; private int mDogDefault; private static int sDogPrivate; protected static int sDogProtected; static int sDogDefault; public static int sDogPublic;}public class Test { public static void main(String[] args) throws IllegalAccessException, InstantiationException { Class&amp;lt;Dog&amp;gt; dog = Dog.class; //类名打印 System.out.println(dog.getName()); //Optimus-Xs.github.io.Dog System.out.println(dog.getSimpleName()); //Dog System.out.println(dog.getCanonicalName());//Optimus-Xs.github.io.Dog //接口 System.out.println(dog.isInterface()); //false for (Class iI : dog.getInterfaces()) { System.out.println(iI); } /* interface Optimus-Xs.github.io.I1 interface Optimus-Xs.github.io.I2 */ //父类 System.out.println(dog.getSuperclass());//class Optimus-Xs.github.io.Animal //创建对象 Dog d = dog.newInstance(); //字段 for (Field f : dog.getFields()) { System.out.println(f.getName()); } /* mDogPublic sDogPublic mAnimalPublic sAnimalPublic mCellPublic //父类的父类的公共字段也打印出来了 */ System.out.println(&quot;---------&quot;); for (Field f : dog.getDeclaredFields()) { System.out.println(f.getName()); } /** 只有自己类声明的字段 mDogPrivate mDogPublic mDogProtected mDogDefault sDogPrivate sDogProtected sDogDefault sDogPublic */ }}getName、getCanonicalName与getSimpleName的区别： getSimpleName：只获取类名 getName：类的全限定名，jvm中Class的表示，可以用于动态加载Class对象，例如Class.forName。 getCanonicalName：返回更容易理解的表示，主要用于输出（toString）或log打印，大多数情况下和getName一样，但是在内部类、数组等类型的表示形式就不同了。package Optimus-Xs.github.io;public class Test { private class inner{ } public static void main(String[] args) throws ClassNotFoundException { //普通类 System.out.println(Test.class.getSimpleName()); //Test System.out.println(Test.class.getName()); //Optimus-Xs.github.io.Test System.out.println(Test.class.getCanonicalName()); //Optimus-Xs.github.io.Test //内部类 System.out.println(inner.class.getSimpleName()); //inner System.out.println(inner.class.getName()); //Optimus-Xs.github.io.Test$inner System.out.println(inner.class.getCanonicalName()); //Optimus-Xs.github.io.Test.inner //数组 System.out.println(args.getClass().getSimpleName()); //String[] System.out.println(args.getClass().getName()); //[Ljava.lang.String; System.out.println(args.getClass().getCanonicalName()); //java.lang.String[] //我们不能用getCanonicalName去加载类对象，必须用getName //Class.forName(inner.class.getCanonicalName()); 报错 Class.forName(inner.class.getName()); }}Constructor类及其用法 Constructor类存在于反射包(java.lang.reflect)中，反映的是Class 对象所表示的类的构造方法。获取Constructor对象是通过Class类中的方法获取的，Class类与Constructor相关的主要方法如下： 方法返回值 方法名称 方法说明 static Class&amp;lt;?&amp;gt; forName(String className) 返回与带有给定字符串名的类或接口相关联的 Class 对象。 Constructor getConstructor(Class&amp;lt;?&amp;gt;… parameterTypes) 返回指定参数类型、具有public访问权限的构造函数对象 Constructor&amp;lt;?&amp;gt;[] getConstructors() 返回所有具有public访问权限的构造函数的Constructor对象数组 Constructor getDeclaredConstructor(Class&amp;lt;?&amp;gt;… parameterTypes) 返回指定参数类型、所有声明的（包括private）构造函数对象 Constructor&amp;lt;?&amp;gt;[] getDeclaredConstructor() 返回所有声明的（包括private）构造函数对象 T newInstance() 调用无参构造器创建此 Class 对象所表示的类的一个新实例。 下面看一个简单例子来了解Constructor对象的使用：public class ConstructionTest implements Serializable { public static void main(String[] args) throws Exception { Class&amp;lt;?&amp;gt; clazz = null; //获取Class对象的引用 clazz = Class.forName(&quot;com.example.javabase.User&quot;); //第一种方法，实例化默认构造方法，User必须无参构造函数,否则将抛异常 User user = (User) clazz.newInstance(); user.setAge(20); user.setName(&quot;Jack&quot;); System.out.println(user); System.out.println(&quot;--------------------------------------------&quot;); //获取带String参数的public构造函数 Constructor cs1 =clazz.getConstructor(String.class); //创建User User user1= (User) cs1.newInstance(&quot;hiway&quot;); user1.setAge(22); System.out.println(&quot;user1:&quot;+user1.toString()); System.out.println(&quot;--------------------------------------------&quot;); //取得指定带int和String参数构造函数,该方法是私有构造private Constructor cs2=clazz.getDeclaredConstructor(int.class,String.class); //由于是private必须设置可访问 cs2.setAccessible(true); //创建user对象 User user2= (User) cs2.newInstance(25,&quot;hiway2&quot;); System.out.println(&quot;user2:&quot;+user2.toString()); System.out.println(&quot;--------------------------------------------&quot;); //获取所有构造包含private Constructor&amp;lt;?&amp;gt; cons[] = clazz.getDeclaredConstructors(); // 查看每个构造方法需要的参数 for (int i = 0; i &amp;lt; cons.length; i++) { //获取构造函数参数类型 Class&amp;lt;?&amp;gt; clazzs[] = cons[i].getParameterTypes(); System.out.println(&quot;构造函数[&quot;+i+&quot;]:&quot;+cons[i].toString() ); System.out.print(&quot;参数类型[&quot;+i+&quot;]:(&quot;); for (int j = 0; j &amp;lt; clazzs.length; j++) { if (j == clazzs.length - 1) System.out.print(clazzs[j].getName()); else System.out.print(clazzs[j].getName() + &quot;,&quot;); } System.out.println(&quot;)&quot;); } }}class User { private int age; private String name; public User() { super(); } public User(String name) { super(); this.name = name; } /** * 私有构造 * @param age * @param name */ private User(int age, String name) { super(); this.age = age; this.name = name; } public int getAge() { return age; } public void setAge(int age) { this.age = age; } public String getName() { return name; } public void setName(String name) { this.name = name; } @Override public String toString() { return &quot;User{&quot; + &quot;age=&quot; + age + &quot;, name=&#39;&quot; + name + &#39;\\&#39;&#39; + &#39;}&#39;; }}输出结果User{age=20, name=&#39;Jack&#39;}--------------------------------------------user1:User{age=22, name=&#39;hiway&#39;}--------------------------------------------user2:User{age=25, name=&#39;hiway2&#39;}--------------------------------------------构造函数[0]:private com.example.javabase.User(int,java.lang.String)参数类型[0]:(int,java.lang.String)构造函数[1]:public com.example.javabase.User(java.lang.String)参数类型[1]:(java.lang.String)构造函数[2]:public com.example.javabase.User()参数类型[2]:()关于Constructor类本身一些常用方法如下(仅部分，其他可查API) 方法返回值 方法名称 方法说明 Class getDeclaringClass() 返回 Class 对象，该对象表示声明由此 Constructor 对象表示的构造方法的类,其实就是返回真实类型（不包含参数） Type[] getGenericParameterTypes() 按照声明顺序返回一组 Type 对象，返回的就是 Constructor对象构造函数的形参类型。 String getName() 以字符串形式返回此构造方法的名称。 Class&amp;lt;?&amp;gt;[] getParameterTypes() 按照声明顺序返回一组 Class 对象，即返回Constructor 对象所表示构造方法的形参类型 T newInstance(Object… initargs) 使用此 Constructor对象表示的构造函数来创建新实例 String toGenericString() 返回描述此 Constructor 的字符串，其中包括类型参数。 Constructor cs3 = clazz.getDeclaredConstructor(int.class,String.class);System.out.println(&quot;-----getDeclaringClass-----&quot;);Class uclazz=cs3.getDeclaringClass();//Constructor对象表示的构造方法的类System.out.println(&quot;构造方法的类:&quot;+uclazz.getName());System.out.println(&quot;-----getGenericParameterTypes-----&quot;);//对象表示此 Constructor 对象所表示的方法的形参类型Type[] tps=cs3.getGenericParameterTypes();for (Type tp:tps) { System.out.println(&quot;参数名称tp:&quot;+tp);}System.out.println(&quot;-----getParameterTypes-----&quot;);//获取构造函数参数类型Class&amp;lt;?&amp;gt; clazzs[] = cs3.getParameterTypes();for (Class claz:clazzs) { System.out.println(&quot;参数名称:&quot;+claz.getName());}System.out.println(&quot;-----getName-----&quot;);//以字符串形式返回此构造方法的名称System.out.println(&quot;getName:&quot;+cs3.getName());System.out.println(&quot;-----getoGenericString-----&quot;);//返回描述此 Constructor 的字符串，其中包括类型参数。System.out.println(&quot;getoGenericString():&quot;+cs3.toGenericString());输出结果-----getDeclaringClass-----构造方法的类:com.example.javabase.User-----getGenericParameterTypes-----参数名称tp:int参数名称tp:class java.lang.String-----getParameterTypes-----参数名称:int参数名称:java.lang.String-----getName-----getName:com.example.javabase.User-----getoGenericString-----getoGenericString():private com.example.javabase.User(int,java.lang.String)Field类及其用法 Field 提供有关类或接口的单个字段的信息，以及对它的动态访问权限。反射的字段可能是一个类（静态）字段或实例字段。同样的道理，我们可以通过Class类的提供的方法来获取代表字段信息的Field对象，Class类与Field对象相关方法如下： 方法返回值 方法名称 方法说明 Field getDeclaredField(String name) 获取指定name名称的(包含private修饰的) 字段，不包括继承的字段 Field[] getDeclaredFields() 获取Class对象所表示的类或接口的所有(包含private修饰的)字段, 不包括继承的字段 Field getField(String name) 获取指定name名称、具有public修饰的字段，包含继承字段 Field[] getFields() 获取修饰符为public的字段，包含继承字段 下面的代码演示了上述方法的使用过程public class ReflectField { public static void main(String[] args) throws ClassNotFoundException, NoSuchFieldException { Class&amp;lt;?&amp;gt; clazz = Class.forName(&quot;reflect.Student&quot;); //获取指定字段名称的Field类,注意字段修饰符必须为public而且存在该字段, // 否则抛NoSuchFieldException Field field = clazz.getField(&quot;age&quot;); System.out.println(&quot;field:&quot;+field); //获取所有修饰符为public的字段,包含父类字段,注意修饰符为public才会获取 Field fields[] = clazz.getFields(); for (Field f:fields) { System.out.println(&quot;f:&quot;+f.getDeclaringClass()); } System.out.println(&quot;================getDeclaredFields====================&quot;); //获取当前类所字段(包含private字段),注意不包含父类的字段 Field fields2[] = clazz.getDeclaredFields(); for (Field f:fields2) { System.out.println(&quot;f2:&quot;+f.getDeclaringClass()); } //获取指定字段名称的Field类,可以是任意修饰符的自动,注意不包含父类的字段 Field field2 = clazz.getDeclaredField(&quot;desc&quot;); System.out.println(&quot;field2:&quot;+field2); } /** 输出结果: field:public int reflect.Person.age f:public java.lang.String reflect.Student.desc f:public int reflect.Person.age f:public java.lang.String reflect.Person.name ================getDeclaredFields==================== f2:public java.lang.String reflect.Student.desc f2:private int reflect.Student.score field2:public java.lang.String reflect.Student.desc */}class Person{ public int age; public String name; //省略set和get方法}class Student extends Person{ public String desc; private int score; //省略set和get方法}上述方法需要注意的是，如果我们不期望获取其父类的字段，则需使用Class类的getDeclaredField/getDeclaredFields方法来获取字段即可，倘若需要连带获取到父类的字段，那么请使用Class类的getField/getFields，但是也只能获取到public修饰的的字段，无法获取父类的私有字段。下面将通过Field类本身的方法对指定类属性赋值，代码演示如下：//获取Class对象引用Class&amp;lt;?&amp;gt; clazz = Class.forName(&quot;reflect.Student&quot;);Student st= (Student) clazz.newInstance();//获取父类public字段并赋值Field ageField = clazz.getField(&quot;age&quot;);ageField.set(st,18);Field nameField = clazz.getField(&quot;name&quot;);nameField.set(st,&quot;Lily&quot;);//只获取当前类的字段,不获取父类的字段Field descField = clazz.getDeclaredField(&quot;desc&quot;);descField.set(st,&quot;I am student&quot;);Field scoreField = clazz.getDeclaredField(&quot;score&quot;);//设置可访问，score是private的scoreField.setAccessible(true);scoreField.set(st,88);System.out.println(st.toString());//输出结果：Student{age=18, name=&#39;Lily ,desc=&#39;I am student&#39;, score=88} //获取字段值System.out.println(scoreField.get(st));// 88其中的set(Object obj, Object value)方法是Field类本身的方法，用于设置字段的值，而get(Object obj)则是获取字段的值，当然关于Field类还有其他常用的方法如下： 方法返回值 方法名称 方法说明 void set(Object obj, Object value) 将指定对象变量上此 Field 对象表示的字段设置为指定的新值。 Object get(Object obj) 返回指定对象上此 Field 表示的字段的值 Class&amp;lt;?&amp;gt; getType() 返回一个 Class 对象，它标识了此Field 对象所表示字段的声明类型。 boolean isEnumConstant() 如果此字段表示枚举类型的元素则返回 true；否则返回 false String toGenericString() 返回一个描述此 Field（包括其一般类型）的字符串 String getName() 返回此 Field 对象表示的字段的名称 Class&amp;lt;?&amp;gt; getDeclaringClass() 返回表示类或接口的 Class 对象，该类或接口声明由此 Field 对象表示的字段 void setAccessible(boolean flag) 将此对象的 accessible 标志设置为指示的布尔值,即设置其可访问性 上述方法可能是较为常用的，事实上在设置值的方法上，Field类还提供了专门针对基本数据类型的方法，如setInt()/getInt()、setBoolean()/getBoolean、setChar()/getChar()等等方法，这里就不全部列出了，需要时查API文档即可。需要特别注意的是被final关键字修饰的Field字段是安全的，在运行时可以接收任何修改，但最终其实际值是不会发生改变的Method类及其用法 Method 提供关于类或接口上单独某个方法（以及如何访问该方法）的信息，所反映的方法可能是类方法或实例方法（包括抽象方法）。下面是Class类获取Method对象相关的方法： 方法返回值 方法名称 方法说明 Method getDeclaredMethod(String name, Class&amp;lt;?&amp;gt;… parameterTypes) 返回一个指定参数的Method对象，该对象反映此 Class 对象所表示的类或接口的指定已声明方法。 Method[] getDeclaredMethod() 返回 Method 对象的一个数组，这些对象反映此 Class 对象表示的类或接口声明的所有方法，包括公共、保护、默认（包）访问和私有方法，但不包括继承的方法。 Method getMethod(String name, Class&amp;lt;?&amp;gt;… parameterTypes) 返回一个 Method 对象，它反映此 Class 对象所表示的类或接口的指定公共成员方法。 Method[] getMethods() 返回一个包含某些 Method 对象的数组，这些对象反映此 Class 对象所表示的类或接口（包括那些由该类或接口声明的以及从超类和超接口继承的那些的类或接口）的公共 member 方法。 同样通过案例演示上述方法import java.lang.reflect.Method;public class ReflectMethod { public static void main(String[] args) throws ClassNotFoundException, NoSuchMethodException { Class clazz = Class.forName(&quot;reflect.Circle&quot;); //根据参数获取public的Method,包含继承自父类的方法 Method method = clazz.getMethod(&quot;draw&quot;,int.class,String.class); System.out.println(&quot;method:&quot;+method); //获取所有public的方法: Method[] methods =clazz.getMethods(); for (Method m:methods){ System.out.println(&quot;m::&quot;+m); } System.out.println(&quot;=========================================&quot;); //获取当前类的方法包含private,该方法无法获取继承自父类的method Method method1 = clazz.getDeclaredMethod(&quot;drawCircle&quot;); System.out.println(&quot;method1::&quot;+method1); //获取当前类的所有方法包含private,该方法无法获取继承自父类的method Method[] methods1=clazz.getDeclaredMethods(); for (Method m:methods1){ System.out.println(&quot;m1::&quot;+m); } }}class Shape { public void draw(){ System.out.println(&quot;draw&quot;); } public void draw(int count , String name){ System.out.println(&quot;draw &quot;+ name +&quot;,count=&quot;+count); }}class Circle extends Shape{ private void drawCircle(){ System.out.println(&quot;drawCircle&quot;); } public int getAllCount(){ return 100; }}输出结果:method:public void reflect.Shape.draw(int,java.lang.String)m::public int reflect.Circle.getAllCount()m::public void reflect.Shape.draw()m::public void reflect.Shape.draw(int,java.lang.String)m::public final void java.lang.Object.wait(long,int) throws java.lang.InterruptedExceptionm::public final native void java.lang.Object.wait(long) throws java.lang.InterruptedExceptionm::public final void java.lang.Object.wait() throws java.lang.InterruptedExceptionm::public boolean java.lang.Object.equals(java.lang.Object)m::public java.lang.String java.lang.Object.toString()m::public native int java.lang.Object.hashCode()m::public final native java.lang.Class java.lang.Object.getClass()m::public final native void java.lang.Object.notify()m::public final native void java.lang.Object.notifyAll()=========================================method1::private void reflect.Circle.drawCircle()m1::public int reflect.Circle.getAllCount()m1::private void reflect.Circle.drawCircle()在通过getMethods方法获取Method对象时，会把父类的方法也获取到，如上的输出结果，把Object类的方法都打印出来了。而getDeclaredMethod/getDeclaredMethods方法都只能获取当前类的方法。我们在使用时根据情况选择即可。下面将演示通过Method对象调用指定类的方法Class clazz = Class.forName(&quot;reflect.Circle&quot;);//创建对象Circle circle = (Circle) clazz.newInstance();//获取指定参数的方法对象MethodMethod method = clazz.getMethod(&quot;draw&quot;,int.class,String.class);//通过Method对象的invoke(Object obj,Object... args)方法调用method.invoke(circle,15,&quot;圈圈&quot;);//对私有无参方法的操作Method method1 = clazz.getDeclaredMethod(&quot;drawCircle&quot;);//修改私有方法的访问标识method1.setAccessible(true);method1.invoke(circle);//对有返回值得方法操作Method method2 =clazz.getDeclaredMethod(&quot;getAllCount&quot;);Integer count = (Integer) method2.invoke(circle);System.out.println(&quot;count:&quot;+count);输出结果draw 圈圈,count=15drawCirclecount:100在上述代码中调用方法，使用了Method类的invoke(Object obj,Object… args)第一个参数代表调用的对象，第二个参数传递的调用方法的参数。这样就完成了类方法的动态调用。 方法返回值 方法名称 方法说明 bject invoke(Object obj, Object… args) 对带有指定参数的指定对象调用由此 Method 对象表示的底层方法。 lass&amp;lt;?&amp;gt; getReturnType() 返回一个 Class 对象，该对象描述了此 Method 对象所表示的方法的正式返回类型,即方法的返回类型 ype getGenericReturnType() 返回表示由此 Method 对象所表示方法的正式返回类型的 Type 对象，也是方法的返回类型。 lass&amp;lt;?&amp;gt;[] getParameterTypes() 按照声明顺序返回 Class 对象的数组，这些对象描述了此 Method 对象所表示的方法的形参类型。即返回方法的参数类型组成的数组 ype[] getGenericParameterTypes() 按照声明顺序返回 Type 对象的数组，这些对象描述了此 Method 对象所表示的方法的形参类型的，也是返回方法的参数类型 tring getName() 以 String 形式返回此 Method 对象表示的方法名称，即返回方法的名称 oolean isVarArgs() 判断方法是否带可变参数，如果将此方法声明为带有可变数量的参数，则返回 true；否则，返回 false。 tring toGenericString() 返回描述此 Method 的字符串，包括类型参数。 getReturnType方法/getGenericReturnType方法都是获取Method对象表示的方法的返回类型，只不过前者返回的Class类型后者返回的Type(前面已分析过)，Type就是一个接口而已，在Java8中新增一个默认的方法实现，返回的就参数类型信息public interface Type { //1.8新增 default String getTypeName() { return toString(); }}而getParameterTypes/getGenericParameterTypes也是同样的道理，都是获取Method对象所表示的方法的参数类型，其他方法与前面的Field和Constructor是类似的。反射的基本运用示例 由于反射会额外消耗一定的系统资源，因此如果不需要动态地创建一个对象，那么就不需要用反射。另外，反射调用方法时可以忽略权限检查，因此可能会破坏封装性而导致安全问题。获得 Class 对象方法有三种:使用 Class 类的 forName 静态方法:public static Class&amp;lt;?&amp;gt; forName(String className)//比如在 JDBC 开发中常用此方法加载数据库驱动:Class.forName(driver);直接获取某一个对象的 class，比如:Class&amp;lt;?&amp;gt; klass = int.class;Class&amp;lt;?&amp;gt; classInt = Integer.TYPE;调用某个对象的 getClass() 方法，比如:StringBuilder str = new StringBuilder(&quot;123&quot;);Class&amp;lt;?&amp;gt; klass = str.getClass();判断是否为某个类的实例一般地，我们用 instanceof 关键字来判断是否为某个类的实例。同时我们也可以借助反射中 Class 对象的 isInstance() 方法来判断是否为某个类的实例，它是一个 native 方法：public native boolean isInstance(Object obj);创建实例通过反射来生成对象主要有两种方式。使用Class对象的newInstance()方法来创建Class对象对应类的实例Class&amp;lt;?&amp;gt; c = String.class;Object str = c.newInstance();先通过Class对象获取指定的Constructor对象，再调用Constructor对象的newInstance()方法来创建实例。这种方法可以用指定的构造器构造类的实例//获取String所对应的Class对象Class&amp;lt;?&amp;gt; c = String.class;//获取String类带一个String参数的构造器Constructor constructor = c.getConstructor(String.class);//根据构造器创建实例Object obj = constructor.newInstance(&quot;23333&quot;);System.out.println(obj);获取方法获取某个Class对象的方法集合，主要有以下几个方法：getDeclaredMethods 方法返回类或接口声明的所有方法，包括公共、保护、默认（包）访问和私有方法，但不包括继承的方法。public Method[] getDeclaredMethods() throws SecurityExceptiongetMethods 方法返回某个类的所有公用（public）方法，包括其继承类的公用方法。public Method[] getMethods() throws SecurityExceptiongetMethod 方法返回一个特定的方法，其中第一个参数为方法名称，后面的参数为方法的参数对应Class的对象。public Method getMethod(String name, Class&amp;lt;?&amp;gt;... parameterTypes)只是这样描述的话可能难以理解，我们用例子来理解这三个方法：public class test1 { public static void test() throws IllegalAccessException, InstantiationException, NoSuchMethodException, InvocationTargetException { Class&amp;lt;?&amp;gt; c = methodClass.class; Object object = c.newInstance(); Method[] methods = c.getMethods(); Method[] declaredMethods = c.getDeclaredMethods(); //获取methodClass类的add方法 Method method = c.getMethod(&quot;add&quot;, int.class, int.class); //getMethods()方法获取的所有方法 System.out.println(&quot;getMethods获取的方法：&quot;); for(Method m:methods) System.out.println(m); //getDeclaredMethods()方法获取的所有方法 System.out.println(&quot;getDeclaredMethods获取的方法：&quot;); for(Method m:declaredMethods) System.out.println(m); } }class methodClass { public final int fuck = 3; public int add(int a,int b) { return a+b; } public int sub(int a,int b) { return a+b; }}程序运行的结果如下:getMethods获取的方法：public int org.Optimus-Xs.common.methodClass.add(int,int)public int org.Optimus-Xs.common.methodClass.sub(int,int)public final void java.lang.Object.wait() throws java.lang.InterruptedExceptionpublic final void java.lang.Object.wait(long,int) throws java.lang.InterruptedExceptionpublic final native void java.lang.Object.wait(long) throws java.lang.InterruptedExceptionpublic boolean java.lang.Object.equals(java.lang.Object)public java.lang.String java.lang.Object.toString()public native int java.lang.Object.hashCode()public final native java.lang.Class java.lang.Object.getClass()public final native void java.lang.Object.notify()public final native void java.lang.Object.notifyAll()getDeclaredMethods获取的方法：public int org.Optimus-Xs.common.methodClass.add(int,int)public int org.Optimus-Xs.common.methodClass.sub(int,int)可以看到，通过 getMethods() 获取的方法可以获取到父类的方法,比如 java.lang.Object 下定义的各个方法。获取构造器信息获取类构造器的用法与上述获取方法的用法类似。主要是通过Class类的getConstructor方法得到Constructor类的一个实例，而Constructor类有一个newInstance方法可以创建一个对象实例:public T newInstance(Object ... initargs)此方法可以根据传入的参数来调用对应的Constructor创建对象实例获取类的成员变量（字段）信息主要是这几个方法，在此不再赘述： getFiled：访问公有的成员变量 getDeclaredField：所有已声明的成员变量，但不能得到其父类的成员变量getFileds 和 getDeclaredFields 方法用法同上（参照 Method）调用方法当我们从类中获取了一个方法后，我们就可以用 invoke() 方法来调用这个方法。invoke 方法的原型为:public Object invoke(Object obj, Object... args) throws IllegalAccessException, IllegalArgumentException, InvocationTargetException下面是一个实例public class test1 { public static void main(String[] args) throws IllegalAccessException, InstantiationException, NoSuchMethodException, InvocationTargetException { Class&amp;lt;?&amp;gt; klass = methodClass.class; //创建methodClass的实例 Object obj = klass.newInstance(); //获取methodClass类的add方法 Method method = klass.getMethod(&quot;add&quot;,int.class,int.class); //调用method对应的方法 =&amp;gt; add(1,4) Object result = method.invoke(obj,1,4); System.out.println(result); }}class methodClass { public final int fuck = 3; public int add(int a,int b) { return a+b; } public int sub(int a,int b) { return a+b; }}利用反射创建数组数组在Java里是比较特殊的一种类型，它可以赋值给一个Object Reference。下面我们看一看利用反射创建数组的例子：public static void testArray() throws ClassNotFoundException { Class&amp;lt;?&amp;gt; cls = Class.forName(&quot;java.lang.String&quot;); Object array = Array.newInstance(cls,25); //往数组里添加内容 Array.set(array,0,&quot;hello&quot;); Array.set(array,1,&quot;Java&quot;); Array.set(array,2,&quot;fuck&quot;); Array.set(array,3,&quot;Scala&quot;); Array.set(array,4,&quot;Clojure&quot;); //获取某一项的内容 System.out.println(Array.get(array,3));}其中的Array类为java.lang.reflect.Array类。我们通过Array.newInstance()创建数组对象，它的原型是:public static Object newInstance(Class&amp;lt;?&amp;gt; componentType, int length) throws NegativeArraySizeException { return newArray(componentType, length);}而 newArray 方法是一个 native 方法，它在 HotSpot JVM 里的具体实现我们后边再研究，这里先把源码贴出来：private static native Object newArray(Class&amp;lt;?&amp;gt; componentType, int length) throws NegativeArraySizeException;arrayOop Reflection::reflect_new_array(oop element_mirror, jint length, TRAPS) { if (element_mirror == NULL) { THROW_0(vmSymbols::java_lang_NullPointerException()); } if (length &amp;lt; 0) { THROW_0(vmSymbols::java_lang_NegativeArraySizeException()); } if (java_lang_Class::is_primitive(element_mirror)) { Klass* tak = basic_type_mirror_to_arrayklass(element_mirror, CHECK_NULL); return TypeArrayKlass::cast(tak)-&amp;gt;allocate(length, THREAD); } else { Klass* k = java_lang_Class::as_Klass(element_mirror); if (k-&amp;gt;oop_is_array() &amp;amp;&amp;amp; ArrayKlass::cast(k)-&amp;gt;dimension() &amp;gt;= MAX_DIM) { THROW_0(vmSymbols::java_lang_IllegalArgumentException()); } return oopFactory::new_objArray(k, length, THREAD); }} 另外，Array 类的 set 和 get 方法都为 native 方法，在 HotSpot JVM 里分别对应 Reflection::array_set 和 Reflection::array_get 方法反射机制执行的流程先看个例子public class HelloReflect { public static void main(String[] args) { try { // 1. 使用外部配置的实现，进行动态加载类 TempFunctionTest test = (TempFunctionTest)Class.forName(&quot;com.tester.HelloReflect&quot;).newInstance(); test.sayHello(&quot;call directly&quot;); // 2. 根据配置的函数名，进行方法调用（不需要通用的接口抽象） Object t2 = new TempFunctionTest(); Method method = t2.getClass().getDeclaredMethod(&quot;sayHello&quot;, String.class); method.invoke(test, &quot;method invoke&quot;); } catch (ClassNotFoundException e) { e.printStackTrace(); } catch (InstantiationException e) { e.printStackTrace(); } catch (IllegalAccessException e) { e.printStackTrace(); } catch (NoSuchMethodException e ) { e.printStackTrace(); } catch (InvocationTargetException e) { e.printStackTrace(); } } public void sayHello(String word) { System.out.println(&quot;hello,&quot; + word); }}来看执行流程反射获取类实例首先调用了 java.lang.Class 的静态方法，获取类信息。 @CallerSensitive public static Class&amp;lt;?&amp;gt; forName(String className) throws ClassNotFoundException { // 先通过反射，获取调用进来的类信息，从而获取当前的 classLoader Class&amp;lt;?&amp;gt; caller = Reflection.getCallerClass(); // 调用native方法进行获取class信息 return forName0(className, true, ClassLoader.getClassLoader(caller), caller); }forName()反射获取类信息，并没有将实现留给了java,而是交给了jvm去加载。主要是先获取 ClassLoader, 然后调用 native 方法，获取信息，加载类则是回调 java.lang.ClassLoader.最后，jvm又会回调 ClassLoader 进类加载。 // public Class&amp;lt;?&amp;gt; loadClass(String name) throws ClassNotFoundException { return loadClass(name, false); } // sun.misc.Launcher public Class&amp;lt;?&amp;gt; loadClass(String var1, boolean var2) throws ClassNotFoundException { int var3 = var1.lastIndexOf(46); if(var3 != -1) { SecurityManager var4 = System.getSecurityManager(); if(var4 != null) { var4.checkPackageAccess(var1.substring(0, var3)); } } if(this.ucp.knownToNotExist(var1)) { Class var5 = this.findLoadedClass(var1); if(var5 != null) { if(var2) { this.resolveClass(var5); } return var5; } else { throw new ClassNotFoundException(var1); } } else { return super.loadClass(var1, var2); } } // java.lang.ClassLoader protected Class&amp;lt;?&amp;gt; loadClass(String name, boolean resolve) throws ClassNotFoundException { // 先获取锁 synchronized (getClassLoadingLock(name)) { // First, check if the class has already been loaded // 如果已经加载了的话，就不用再加载了 Class&amp;lt;?&amp;gt; c = findLoadedClass(name); if (c == null) { long t0 = System.nanoTime(); try { // 双亲委托加载 if (parent != null) { c = parent.loadClass(name, false); } else { c = findBootstrapClassOrNull(name); } } catch (ClassNotFoundException e) { // ClassNotFoundException thrown if class not found // from the non-null parent class loader } // 父类没有加载到时，再自己加载 if (c == null) { // If still not found, then invoke findClass in order // to find the class. long t1 = System.nanoTime(); c = findClass(name); // this is the defining class loader; record the stats sun.misc.PerfCounter.getParentDelegationTime().addTime(t1 - t0); sun.misc.PerfCounter.getFindClassTime().addElapsedTimeFrom(t1); sun.misc.PerfCounter.getFindClasses().increment(); } } if (resolve) { resolveClass(c); } return c; } } protected Object getClassLoadingLock(String className) { Object lock = this; if (parallelLockMap != null) { // 使用 ConcurrentHashMap来保存锁 Object newLock = new Object(); lock = parallelLockMap.putIfAbsent(className, newLock); if (lock == null) { lock = newLock; } } return lock; } protected final Class&amp;lt;?&amp;gt; findLoadedClass(String name) { if (!checkName(name)) return null; return findLoadedClass0(name); }下面来看一下 newInstance() 的实现方式。 // 首先肯定是 Class.newInstance @CallerSensitive public T newInstance() throws InstantiationException, IllegalAccessException { if (System.getSecurityManager() != null) { checkMemberAccess(Member.PUBLIC, Reflection.getCallerClass(), false); } // NOTE: the following code may not be strictly correct under // the current Java memory model. // Constructor lookup // newInstance() 其实相当于调用类的无参构造函数，所以，首先要找到其无参构造器 if (cachedConstructor == null) { if (this == Class.class) { // 不允许调用 Class 的 newInstance() 方法 throw new IllegalAccessException( &quot;Can not call newInstance() on the Class for java.lang.Class&quot; ); } try { // 获取无参构造器 Class&amp;lt;?&amp;gt;[] empty = {}; final Constructor&amp;lt;T&amp;gt; c = getConstructor0(empty, Member.DECLARED); // Disable accessibility checks on the constructor // since we have to do the security check here anyway // (the stack depth is wrong for the Constructor&#39;s // security check to work) java.security.AccessController.doPrivileged( new java.security.PrivilegedAction&amp;lt;Void&amp;gt;() { public Void run() { c.setAccessible(true); return null; } }); cachedConstructor = c; } catch (NoSuchMethodException e) { throw (InstantiationException) new InstantiationException(getName()).initCause(e); } } Constructor&amp;lt;T&amp;gt; tmpConstructor = cachedConstructor; // Security check (same as in java.lang.reflect.Constructor) int modifiers = tmpConstructor.getModifiers(); if (!Reflection.quickCheckMemberAccess(this, modifiers)) { Class&amp;lt;?&amp;gt; caller = Reflection.getCallerClass(); if (newInstanceCallerCache != caller) { Reflection.ensureMemberAccess(caller, this, null, modifiers); newInstanceCallerCache = caller; } } // Run constructor try { // 调用无参构造器 return tmpConstructor.newInstance((Object[])null); } catch (InvocationTargetException e) { Unsafe.getUnsafe().throwException(e.getTargetException()); // Not reached return null; } }newInstance() 主要做了三件事： 权限检测，如果不通过直接抛出异常； 查找无参构造器，并将其缓存起来； 调用具体方法的无参构造方法，生成实例并返回；下面是获取构造器的过程：private Constructor&amp;lt;T&amp;gt; getConstructor0(Class&amp;lt;?&amp;gt;[] parameterTypes, int which) throws NoSuchMethodException{ // 获取所有构造器 Constructor&amp;lt;T&amp;gt;[] constructors = privateGetDeclaredConstructors((which == Member.PUBLIC)); for (Constructor&amp;lt;T&amp;gt; constructor : constructors) { if (arrayContentsEq(parameterTypes, constructor.getParameterTypes())) { return getReflectionFactory().copyConstructor(constructor); } } throw new NoSuchMethodException(getName() + &quot;.&amp;lt;init&amp;gt;&quot; + argumentTypesToString(parameterTypes));}getConstructor0() 为获取匹配的构造方器；分三步： 先获取所有的constructors, 然后通过进行参数类型比较； 找到匹配后，通过 ReflectionFactory copy一份constructor返回； 否则抛出 NoSuchMethodException; // 获取当前类所有的构造方法，通过jvm或者缓存 // Returns an array of &quot;root&quot; constructors. These Constructor // objects must NOT be propagated to the outside world, but must // instead be copied via ReflectionFactory.copyConstructor. private Constructor&amp;lt;T&amp;gt;[] privateGetDeclaredConstructors(boolean publicOnly) { checkInitted(); Constructor&amp;lt;T&amp;gt;[] res; // 调用 reflectionData(), 获取保存的信息，使用软引用保存，从而使内存不够可以回收 ReflectionData&amp;lt;T&amp;gt; rd = reflectionData(); if (rd != null) { res = publicOnly ? rd.publicConstructors : rd.declaredConstructors; // 存在缓存，则直接返回 if (res != null) return res; } // No cached value available; request value from VM if (isInterface()) { @SuppressWarnings(&quot;unchecked&quot;) Constructor&amp;lt;T&amp;gt;[] temporaryRes = (Constructor&amp;lt;T&amp;gt;[]) new Constructor&amp;lt;?&amp;gt;[0]; res = temporaryRes; } else { // 使用native方法从jvm获取构造器 res = getDeclaredConstructors0(publicOnly); } if (rd != null) { // 最后，将从jvm中读取的内容，存入缓存 if (publicOnly) { rd.publicConstructors = res; } else { rd.declaredConstructors = res; } } return res; } // Lazily create and cache ReflectionData private ReflectionData&amp;lt;T&amp;gt; reflectionData() { SoftReference&amp;lt;ReflectionData&amp;lt;T&amp;gt;&amp;gt; reflectionData = this.reflectionData; int classRedefinedCount = this.classRedefinedCount; ReflectionData&amp;lt;T&amp;gt; rd; if (useCaches &amp;amp;&amp;amp; reflectionData != null &amp;amp;&amp;amp; (rd = reflectionData.get()) != null &amp;amp;&amp;amp; rd.redefinedCount == classRedefinedCount) { return rd; } // else no SoftReference or cleared SoftReference or stale ReflectionData // -&amp;gt; create and replace new instance return newReflectionData(reflectionData, classRedefinedCount); } // 新创建缓存，保存反射信息 private ReflectionData&amp;lt;T&amp;gt; newReflectionData(SoftReference&amp;lt;ReflectionData&amp;lt;T&amp;gt;&amp;gt; oldReflectionData, int classRedefinedCount) { if (!useCaches) return null; // 使用cas保证更新的线程安全性，所以反射是保证线程安全的 while (true) { ReflectionData&amp;lt;T&amp;gt; rd = new ReflectionData&amp;lt;&amp;gt;(classRedefinedCount); // try to CAS it... if (Atomic.casReflectionData(this, oldReflectionData, new SoftReference&amp;lt;&amp;gt;(rd))) { return rd; } // 先使用CAS更新，如果更新成功，则立即返回，否则测查当前已被其他线程更新的情况，如果和自己想要更新的状态一致，则也算是成功了 oldReflectionData = this.reflectionData; classRedefinedCount = this.classRedefinedCount; if (oldReflectionData != null &amp;amp;&amp;amp; (rd = oldReflectionData.get()) != null &amp;amp;&amp;amp; rd.redefinedCount == classRedefinedCount) { return rd; } } }如上，privateGetDeclaredConstructors(), 获取所有的构造器主要步骤； 先尝试从缓存中获取； 如果缓存没有，则从jvm中重新获取，并存入缓存，缓存使用软引用进行保存，保证内存可用；另外，使用 relactionData() 进行缓存保存；ReflectionData 的数据结构如下。// reflection data that might get invalidated when JVM TI RedefineClasses() is calledprivate static class ReflectionData&amp;lt;T&amp;gt; { volatile Field[] declaredFields; volatile Field[] publicFields; volatile Method[] declaredMethods; volatile Method[] publicMethods; volatile Constructor&amp;lt;T&amp;gt;[] declaredConstructors; volatile Constructor&amp;lt;T&amp;gt;[] publicConstructors; // Intermediate results for getFields and getMethods volatile Field[] declaredPublicFields; volatile Method[] declaredPublicMethods; volatile Class&amp;lt;?&amp;gt;[] interfaces; // Value of classRedefinedCount when we created this ReflectionData instance final int redefinedCount; ReflectionData(int redefinedCount) { this.redefinedCount = redefinedCount; }}其中，还有一个点，就是如何比较构造是否是要查找构造器，其实就是比较类型完成相等就完了，有一个不相等则返回false。private static boolean arrayContentsEq(Object[] a1, Object[] a2) { if (a1 == null) { return a2 == null || a2.length == 0; } if (a2 == null) { return a1.length == 0; } if (a1.length != a2.length) { return false; } for (int i = 0; i &amp;lt; a1.length; i++) { if (a1[i] != a2[i]) { return false; } } return true;}// sun.reflect.ReflectionFactory/** Makes a copy of the passed constructor. The returned constructor is a &quot;child&quot; of the passed one; see the comments in Constructor.java for details. */public &amp;lt;T&amp;gt; Constructor&amp;lt;T&amp;gt; copyConstructor(Constructor&amp;lt;T&amp;gt; arg) { return langReflectAccess().copyConstructor(arg);}// java.lang.reflect.Constructor, copy 其实就是新new一个 Constructor 出来Constructor&amp;lt;T&amp;gt; copy() { // This routine enables sharing of ConstructorAccessor objects // among Constructor objects which refer to the same underlying // method in the VM. (All of this contortion is only necessary // because of the &quot;accessibility&quot; bit in AccessibleObject, // which implicitly requires that new java.lang.reflect // objects be fabricated for each reflective call on Class // objects.) if (this.root != null) throw new IllegalArgumentException(&quot;Can not copy a non-root Constructor&quot;); Constructor&amp;lt;T&amp;gt; res = new Constructor&amp;lt;&amp;gt;(clazz, parameterTypes, exceptionTypes, modifiers, slot, signature, annotations, parameterAnnotations); // root 指向当前 constructor res.root = this; // Might as well eagerly propagate this if already present res.constructorAccessor = constructorAccessor; return res;}通过上面，获取到 Constructor 了。接下来就只需调用其相应构造器的 newInstance()，即返回实例了。// return tmpConstructor.newInstance((Object[])null); // java.lang.reflect.Constructor@CallerSensitivepublic T newInstance(Object ... initargs) throws InstantiationException, IllegalAccessException, IllegalArgumentException, InvocationTargetException{ if (!override) { if (!Reflection.quickCheckMemberAccess(clazz, modifiers)) { Class&amp;lt;?&amp;gt; caller = Reflection.getCallerClass(); checkAccess(caller, clazz, null, modifiers); } } if ((clazz.getModifiers() &amp;amp; Modifier.ENUM) != 0) throw new IllegalArgumentException(&quot;Cannot reflectively create enum objects&quot;); ConstructorAccessor ca = constructorAccessor; // read volatile if (ca == null) { ca = acquireConstructorAccessor(); } @SuppressWarnings(&quot;unchecked&quot;) T inst = (T) ca.newInstance(initargs); return inst;}// sun.reflect.DelegatingConstructorAccessorImplpublic Object newInstance(Object[] args) throws InstantiationException, IllegalArgumentException, InvocationTargetException{ return delegate.newInstance(args);}// sun.reflect.NativeConstructorAccessorImplpublic Object newInstance(Object[] args) throws InstantiationException, IllegalArgumentException, InvocationTargetException{ // We can&#39;t inflate a constructor belonging to a vm-anonymous class // because that kind of class can&#39;t be referred to by name, hence can&#39;t // be found from the generated bytecode. if (++numInvocations &amp;gt; ReflectionFactory.inflationThreshold() &amp;amp;&amp;amp; !ReflectUtil.isVMAnonymousClass(c.getDeclaringClass())) { ConstructorAccessorImpl acc = (ConstructorAccessorImpl) new MethodAccessorGenerator(). generateConstructor(c.getDeclaringClass(), c.getParameterTypes(), c.getExceptionTypes(), c.getModifiers()); parent.setDelegate(acc); } // 调用native方法，进行调用 constructor return newInstance0(c, args);}返回构造器的实例后，可以根据外部进行进行类型转换，从而使用接口或方法进行调用实例功能了反射获取方法第一步，先获取 Method; // java.lang.Class @CallerSensitive public Method getDeclaredMethod(String name, Class&amp;lt;?&amp;gt;... parameterTypes) throws NoSuchMethodException, SecurityException { checkMemberAccess(Member.DECLARED, Reflection.getCallerClass(), true); Method method = searchMethods(privateGetDeclaredMethods(false), name, parameterTypes); if (method == null) { throw new NoSuchMethodException(getName() + &quot;.&quot; + name + argumentTypesToString(parameterTypes)); } return method; }忽略第一个检查权限，剩下就只有两个动作了。 获取所有方法列表； 根据方法名称和方法列表，选出符合要求的方法； 如果没有找到相应方法，抛出异常，否则返回对应方法；所以，先看一下怎样获取类声明的所有方法？ // Returns an array of &quot;root&quot; methods. These Method objects must NOT // be propagated to the outside world, but must instead be copied // via ReflectionFactory.copyMethod. private Method[] privateGetDeclaredMethods(boolean publicOnly) { checkInitted(); Method[] res; ReflectionData&amp;lt;T&amp;gt; rd = reflectionData(); if (rd != null) { res = publicOnly ? rd.declaredPublicMethods : rd.declaredMethods; if (res != null) return res; } // No cached value available; request value from VM res = Reflection.filterMethods(this, getDeclaredMethods0(publicOnly)); if (rd != null) { if (publicOnly) { rd.declaredPublicMethods = res; } else { rd.declaredMethods = res; } } return res; }很相似，和获取所有构造器的方法很相似，都是先从缓存中获取方法，如果没有，则从jvm中获取。不同的是，方法列表需要进行过滤 Reflection.filterMethods;当然后面看来，这个方法我们一般不会派上用场 // sun.misc.Reflection public static Method[] filterMethods(Class&amp;lt;?&amp;gt; containingClass, Method[] methods) { if (methodFilterMap == null) { // Bootstrapping return methods; } return (Method[])filter(methods, methodFilterMap.get(containingClass)); } // 可以过滤指定的方法，一般为空，如果要指定过滤，可以调用 registerMethodsToFilter(), 或者... private static Member[] filter(Member[] members, String[] filteredNames) { if ((filteredNames == null) || (members.length == 0)) { return members; } int numNewMembers = 0; for (Member member : members) { boolean shouldSkip = false; for (String filteredName : filteredNames) { if (member.getName() == filteredName) { shouldSkip = true; break; } } if (!shouldSkip) { ++numNewMembers; } } Member[] newMembers = (Member[])Array.newInstance(members[0].getClass(), numNewMembers); int destIdx = 0; for (Member member : members) { boolean shouldSkip = false; for (String filteredName : filteredNames) { if (member.getName() == filteredName) { shouldSkip = true; break; } } if (!shouldSkip) { newMembers[destIdx++] = member; } } return newMembers; }第二步，根据方法名和参数类型过滤指定方法返回： private static Method searchMethods(Method[] methods, String name, Class&amp;lt;?&amp;gt;[] parameterTypes) { Method res = null; // 使用常量池，避免重复创建String String internedName = name.intern(); for (int i = 0; i &amp;lt; methods.length; i++) { Method m = methods[i]; if (m.getName() == internedName &amp;amp;&amp;amp; arrayContentsEq(parameterTypes, m.getParameterTypes()) &amp;amp;&amp;amp; (res == null || res.getReturnType().isAssignableFrom(m.getReturnType()))) res = m; } return (res == null ? res : getReflectionFactory().copyMethod(res)); }大概意思看得明白，就是匹配到方法名，然后参数类型匹配，才可以。 但是可以看到，匹配到一个方法，并没有退出for循环，而是继续进行匹配。 这里是匹配最精确的子类进行返回（最优匹配） 最后，还是通过 ReflectionFactory, copy 方法后返回调用 method.invoke() 方法 @CallerSensitive public Object invoke(Object obj, Object... args) throws IllegalAccessException, IllegalArgumentException, InvocationTargetException { if (!override) { if (!Reflection.quickCheckMemberAccess(clazz, modifiers)) { Class&amp;lt;?&amp;gt; caller = Reflection.getCallerClass(); checkAccess(caller, clazz, obj, modifiers); } } MethodAccessor ma = methodAccessor; // read volatile if (ma == null) { ma = acquireMethodAccessor(); } return ma.invoke(obj, args); }invoke时，是通过 MethodAccessor 进行调用的，而 MethodAccessor 是个接口，在第一次时调用 acquireMethodAccessor() 进行新创建。 // probably make the implementation more scalable. private MethodAccessor acquireMethodAccessor() { // First check to see if one has been created yet, and take it // if so MethodAccessor tmp = null; if (root != null) tmp = root.getMethodAccessor(); if (tmp != null) { // 存在缓存时，存入 methodAccessor，否则调用 ReflectionFactory 创建新的 MethodAccessor methodAccessor = tmp; } else { // Otherwise fabricate one and propagate it up to the root tmp = reflectionFactory.newMethodAccessor(this); setMethodAccessor(tmp); } return tmp; } // sun.reflect.ReflectionFactory public MethodAccessor newMethodAccessor(Method method) { checkInitted(); if (noInflation &amp;amp;&amp;amp; !ReflectUtil.isVMAnonymousClass(method.getDeclaringClass())) { return new MethodAccessorGenerator(). generateMethod(method.getDeclaringClass(), method.getName(), method.getParameterTypes(), method.getReturnType(), method.getExceptionTypes(), method.getModifiers()); } else { NativeMethodAccessorImpl acc = new NativeMethodAccessorImpl(method); DelegatingMethodAccessorImpl res = new DelegatingMethodAccessorImpl(acc); acc.setParent(res); return res; } }两个Accessor详情：// NativeMethodAccessorImpl / DelegatingMethodAccessorImplclass NativeMethodAccessorImpl extends MethodAccessorImpl { private final Method method; private DelegatingMethodAccessorImpl parent; private int numInvocations; NativeMethodAccessorImpl(Method method) { this.method = method; } public Object invoke(Object obj, Object[] args) throws IllegalArgumentException, InvocationTargetException { // We can&#39;t inflate methods belonging to vm-anonymous classes because // that kind of class can&#39;t be referred to by name, hence can&#39;t be // found from the generated bytecode. if (++numInvocations &amp;gt; ReflectionFactory.inflationThreshold() &amp;amp;&amp;amp; !ReflectUtil.isVMAnonymousClass(method.getDeclaringClass())) { MethodAccessorImpl acc = (MethodAccessorImpl) new MethodAccessorGenerator(). generateMethod(method.getDeclaringClass(), method.getName(), method.getParameterTypes(), method.getReturnType(), method.getExceptionTypes(), method.getModifiers()); parent.setDelegate(acc); } return invoke0(method, obj, args); } void setParent(DelegatingMethodAccessorImpl parent) { this.parent = parent; } private static native Object invoke0(Method m, Object obj, Object[] args);}class DelegatingMethodAccessorImpl extends MethodAccessorImpl { private MethodAccessorImpl delegate; DelegatingMethodAccessorImpl(MethodAccessorImpl delegate) { setDelegate(delegate); } public Object invoke(Object obj, Object[] args) throws IllegalArgumentException, InvocationTargetException { return delegate.invoke(obj, args); } void setDelegate(MethodAccessorImpl delegate) { this.delegate = delegate; }}进行 ma.invoke(obj, args); 调用时，调用 DelegatingMethodAccessorImpl.invoke();最后被委托到 NativeMethodAccessorImpl.invoke(), 即： public Object invoke(Object obj, Object[] args) throws IllegalArgumentException, InvocationTargetException { // We can&#39;t inflate methods belonging to vm-anonymous classes because // that kind of class can&#39;t be referred to by name, hence can&#39;t be // found from the generated bytecode. if (++numInvocations &amp;gt; ReflectionFactory.inflationThreshold() &amp;amp;&amp;amp; !ReflectUtil.isVMAnonymousClass(method.getDeclaringClass())) { MethodAccessorImpl acc = (MethodAccessorImpl) new MethodAccessorGenerator(). generateMethod(method.getDeclaringClass(), method.getName(), method.getParameterTypes(), method.getReturnType(), method.getExceptionTypes(), method.getModifiers()); parent.setDelegate(acc); } // invoke0 是个 native 方法，由jvm进行调用业务方法。从而完成反射调用功能。 return invoke0(method, obj, args); }其中， generateMethod() 是生成具体类的方法 /** This routine is not thread-safe */ public MethodAccessor generateMethod(Class&amp;lt;?&amp;gt; declaringClass, String name, Class&amp;lt;?&amp;gt;[] parameterTypes, Class&amp;lt;?&amp;gt; returnType, Class&amp;lt;?&amp;gt;[] checkedExceptions, int modifiers) { return (MethodAccessor) generate(declaringClass, name, parameterTypes, returnType, checkedExceptions, modifiers, false, false, null); }generate() 戳详情 /** This routine is not thread-safe */ private MagicAccessorImpl generate(final Class&amp;lt;?&amp;gt; declaringClass, String name, Class&amp;lt;?&amp;gt;[] parameterTypes, Class&amp;lt;?&amp;gt; returnType, Class&amp;lt;?&amp;gt;[] checkedExceptions, int modifiers, boolean isConstructor, boolean forSerialization, Class&amp;lt;?&amp;gt; serializationTargetClass) { ByteVector vec = ByteVectorFactory.create(); asm = new ClassFileAssembler(vec); this.declaringClass = declaringClass; this.parameterTypes = parameterTypes; this.returnType = returnType; this.modifiers = modifiers; this.isConstructor = isConstructor; this.forSerialization = forSerialization; asm.emitMagicAndVersion(); // Constant pool entries: // ( * = Boxing information: optional) // (+ = Shared entries provided by AccessorGenerator) // (^ = Only present if generating SerializationConstructorAccessor) // [UTF-8] [This class&#39;s name] // [CONSTANT_Class_info] for above // [UTF-8] &quot;sun/reflect/{MethodAccessorImpl,ConstructorAccessorImpl,SerializationConstructorAccessorImpl}&quot; // [CONSTANT_Class_info] for above // [UTF-8] [Target class&#39;s name] // [CONSTANT_Class_info] for above // ^ [UTF-8] [Serialization: Class&#39;s name in which to invoke constructor] // ^ [CONSTANT_Class_info] for above // [UTF-8] target method or constructor name // [UTF-8] target method or constructor signature // [CONSTANT_NameAndType_info] for above // [CONSTANT_Methodref_info or CONSTANT_InterfaceMethodref_info] for target method // [UTF-8] &quot;invoke&quot; or &quot;newInstance&quot; // [UTF-8] invoke or newInstance descriptor // [UTF-8] descriptor for type of non-primitive parameter 1 // [CONSTANT_Class_info] for type of non-primitive parameter 1 // ... // [UTF-8] descriptor for type of non-primitive parameter n // [CONSTANT_Class_info] for type of non-primitive parameter n // + [UTF-8] &quot;java/lang/Exception&quot; // + [CONSTANT_Class_info] for above // + [UTF-8] &quot;java/lang/ClassCastException&quot; // + [CONSTANT_Class_info] for above // + [UTF-8] &quot;java/lang/NullPointerException&quot; // + [CONSTANT_Class_info] for above // + [UTF-8] &quot;java/lang/IllegalArgumentException&quot; // + [CONSTANT_Class_info] for above // + [UTF-8] &quot;java/lang/InvocationTargetException&quot; // + [CONSTANT_Class_info] for above // + [UTF-8] &quot;&amp;lt;init&amp;gt;&quot; // + [UTF-8] &quot;()V&quot; // + [CONSTANT_NameAndType_info] for above // + [CONSTANT_Methodref_info] for NullPointerException&#39;s constructor // + [CONSTANT_Methodref_info] for IllegalArgumentException&#39;s constructor // + [UTF-8] &quot;(Ljava/lang/String;)V&quot; // + [CONSTANT_NameAndType_info] for &quot;&amp;lt;init&amp;gt;(Ljava/lang/String;)V&quot; // + [CONSTANT_Methodref_info] for IllegalArgumentException&#39;s constructor taking a String // + [UTF-8] &quot;(Ljava/lang/Throwable;)V&quot; // + [CONSTANT_NameAndType_info] for &quot;&amp;lt;init&amp;gt;(Ljava/lang/Throwable;)V&quot; // + [CONSTANT_Methodref_info] for InvocationTargetException&#39;s constructor // + [CONSTANT_Methodref_info] for &quot;super()&quot; // + [UTF-8] &quot;java/lang/Object&quot; // + [CONSTANT_Class_info] for above // + [UTF-8] &quot;toString&quot; // + [UTF-8] &quot;()Ljava/lang/String;&quot; // + [CONSTANT_NameAndType_info] for &quot;toString()Ljava/lang/String;&quot; // + [CONSTANT_Methodref_info] for Object&#39;s toString method // + [UTF-8] &quot;Code&quot; // + [UTF-8] &quot;Exceptions&quot; // * [UTF-8] &quot;java/lang/Boolean&quot; // * [CONSTANT_Class_info] for above // * [UTF-8] &quot;(Z)V&quot; // * [CONSTANT_NameAndType_info] for above // * [CONSTANT_Methodref_info] for above // * [UTF-8] &quot;booleanValue&quot; // * [UTF-8] &quot;()Z&quot; // * [CONSTANT_NameAndType_info] for above // * [CONSTANT_Methodref_info] for above // * [UTF-8] &quot;java/lang/Byte&quot; // * [CONSTANT_Class_info] for above // * [UTF-8] &quot;(B)V&quot; // * [CONSTANT_NameAndType_info] for above // * [CONSTANT_Methodref_info] for above // * [UTF-8] &quot;byteValue&quot; // * [UTF-8] &quot;()B&quot; // * [CONSTANT_NameAndType_info] for above // * [CONSTANT_Methodref_info] for above // * [UTF-8] &quot;java/lang/Character&quot; // * [CONSTANT_Class_info] for above // * [UTF-8] &quot;(C)V&quot; // * [CONSTANT_NameAndType_info] for above // * [CONSTANT_Methodref_info] for above // * [UTF-8] &quot;charValue&quot; // * [UTF-8] &quot;()C&quot; // * [CONSTANT_NameAndType_info] for above // * [CONSTANT_Methodref_info] for above // * [UTF-8] &quot;java/lang/Double&quot; // * [CONSTANT_Class_info] for above // * [UTF-8] &quot;(D)V&quot; // * [CONSTANT_NameAndType_info] for above // * [CONSTANT_Methodref_info] for above // * [UTF-8] &quot;doubleValue&quot; // * [UTF-8] &quot;()D&quot; // * [CONSTANT_NameAndType_info] for above // * [CONSTANT_Methodref_info] for above // * [UTF-8] &quot;java/lang/Float&quot; // * [CONSTANT_Class_info] for above // * [UTF-8] &quot;(F)V&quot; // * [CONSTANT_NameAndType_info] for above // * [CONSTANT_Methodref_info] for above // * [UTF-8] &quot;floatValue&quot; // * [UTF-8] &quot;()F&quot; // * [CONSTANT_NameAndType_info] for above // * [CONSTANT_Methodref_info] for above // * [UTF-8] &quot;java/lang/Integer&quot; // * [CONSTANT_Class_info] for above // * [UTF-8] &quot;(I)V&quot; // * [CONSTANT_NameAndType_info] for above // * [CONSTANT_Methodref_info] for above // * [UTF-8] &quot;intValue&quot; // * [UTF-8] &quot;()I&quot; // * [CONSTANT_NameAndType_info] for above // * [CONSTANT_Methodref_info] for above // * [UTF-8] &quot;java/lang/Long&quot; // * [CONSTANT_Class_info] for above // * [UTF-8] &quot;(J)V&quot; // * [CONSTANT_NameAndType_info] for above // * [CONSTANT_Methodref_info] for above // * [UTF-8] &quot;longValue&quot; // * [UTF-8] &quot;()J&quot; // * [CONSTANT_NameAndType_info] for above // * [CONSTANT_Methodref_info] for above // * [UTF-8] &quot;java/lang/Short&quot; // * [CONSTANT_Class_info] for above // * [UTF-8] &quot;(S)V&quot; // * [CONSTANT_NameAndType_info] for above // * [CONSTANT_Methodref_info] for above // * [UTF-8] &quot;shortValue&quot; // * [UTF-8] &quot;()S&quot; // * [CONSTANT_NameAndType_info] for above // * [CONSTANT_Methodref_info] for above short numCPEntries = NUM_BASE_CPOOL_ENTRIES + NUM_COMMON_CPOOL_ENTRIES; boolean usesPrimitives = usesPrimitiveTypes(); if (usesPrimitives) { numCPEntries += NUM_BOXING_CPOOL_ENTRIES; } if (forSerialization) { numCPEntries += NUM_SERIALIZATION_CPOOL_ENTRIES; } // Add in variable-length number of entries to be able to describe // non-primitive parameter types and checked exceptions. numCPEntries += (short) (2 * numNonPrimitiveParameterTypes()); asm.emitShort(add(numCPEntries, S1)); final String generatedName = generateName(isConstructor, forSerialization); asm.emitConstantPoolUTF8(generatedName); asm.emitConstantPoolClass(asm.cpi()); thisClass = asm.cpi(); if (isConstructor) { if (forSerialization) { asm.emitConstantPoolUTF8 (&quot;sun/reflect/SerializationConstructorAccessorImpl&quot;); } else { asm.emitConstantPoolUTF8(&quot;sun/reflect/ConstructorAccessorImpl&quot;); } } else { asm.emitConstantPoolUTF8(&quot;sun/reflect/MethodAccessorImpl&quot;); } asm.emitConstantPoolClass(asm.cpi()); superClass = asm.cpi(); asm.emitConstantPoolUTF8(getClassName(declaringClass, false)); asm.emitConstantPoolClass(asm.cpi()); targetClass = asm.cpi(); short serializationTargetClassIdx = (short) 0; if (forSerialization) { asm.emitConstantPoolUTF8(getClassName(serializationTargetClass, false)); asm.emitConstantPoolClass(asm.cpi()); serializationTargetClassIdx = asm.cpi(); } asm.emitConstantPoolUTF8(name); asm.emitConstantPoolUTF8(buildInternalSignature()); asm.emitConstantPoolNameAndType(sub(asm.cpi(), S1), asm.cpi()); if (isInterface()) { asm.emitConstantPoolInterfaceMethodref(targetClass, asm.cpi()); } else { if (forSerialization) { asm.emitConstantPoolMethodref(serializationTargetClassIdx, asm.cpi()); } else { asm.emitConstantPoolMethodref(targetClass, asm.cpi()); } } targetMethodRef = asm.cpi(); if (isConstructor) { asm.emitConstantPoolUTF8(&quot;newInstance&quot;); } else { asm.emitConstantPoolUTF8(&quot;invoke&quot;); } invokeIdx = asm.cpi(); if (isConstructor) { asm.emitConstantPoolUTF8(&quot;([Ljava/lang/Object;)Ljava/lang/Object;&quot;); } else { asm.emitConstantPoolUTF8 (&quot;(Ljava/lang/Object;[Ljava/lang/Object;)Ljava/lang/Object;&quot;); } invokeDescriptorIdx = asm.cpi(); // Output class information for non-primitive parameter types nonPrimitiveParametersBaseIdx = add(asm.cpi(), S2); for (int i = 0; i &amp;lt; parameterTypes.length; i++) { Class&amp;lt;?&amp;gt; c = parameterTypes[i]; if (!isPrimitive(c)) { asm.emitConstantPoolUTF8(getClassName(c, false)); asm.emitConstantPoolClass(asm.cpi()); } } // Entries common to FieldAccessor, MethodAccessor and ConstructorAccessor emitCommonConstantPoolEntries(); // Boxing entries if (usesPrimitives) { emitBoxingContantPoolEntries(); } if (asm.cpi() != numCPEntries) { throw new InternalError(&quot;Adjust this code (cpi = &quot; + asm.cpi() + &quot;, numCPEntries = &quot; + numCPEntries + &quot;)&quot;); } // Access flags asm.emitShort(ACC_PUBLIC); // This class asm.emitShort(thisClass); // Superclass asm.emitShort(superClass); // Interfaces count and interfaces asm.emitShort(S0); // Fields count and fields asm.emitShort(S0); // Methods count and methods asm.emitShort(NUM_METHODS); emitConstructor(); emitInvoke(); // Additional attributes (none) asm.emitShort(S0); // Load class vec.trim(); final byte[] bytes = vec.getData(); // Note: the class loader is the only thing that really matters // here -- it&#39;s important to get the generated code into the // same namespace as the target class. Since the generated code // is privileged anyway, the protection domain probably doesn&#39;t // matter. return AccessController.doPrivileged( new PrivilegedAction&amp;lt;MagicAccessorImpl&amp;gt;() { public MagicAccessorImpl run() { try { return (MagicAccessorImpl) ClassDefiner.defineClass (generatedName, bytes, 0, bytes.length, declaringClass.getClassLoader()).newInstance(); } catch (InstantiationException | IllegalAccessException e) { throw new InternalError(e); } } }); }主要看这一句：ClassDefiner.defineClass(xx, declaringClass.getClassLoader()).newInstance();在ClassDefiner.defineClass方法实现中，每被调用一次都会生成一个DelegatingClassLoader类加载器对象 ，这里每次都生成新的类加载器，是为了性能考虑，在某些情况下可以卸载这些生成的类，因为类的卸载是只有在类加载器可以被回收的情况下才会被回收的，如果用了原来的类加载器，那可能导致这些新创建的类一直无法被卸载。而反射生成的类，有时候可能用了就可以卸载了，所以使用其独立的类加载器，从而使得更容易控制反射类的生命周期反射调用流程小结最后，用几句话总结反射的实现原理： 反射类及反射方法的获取，都是通过从列表中搜寻查找匹配的方法，所以查找性能会随类的大小方法多少而变化； 每个类都会有一个与之对应的Class实例，从而每个类都可以获取method反射方法，并作用到其他实例身上； 反射也是考虑了线程安全的，放心使用； 反射使用软引用relectionData缓存class信息，避免每次重新从jvm获取带来的开销； 反射调用多次生成新代理Accessor, 而通过字节码生存的则考虑了卸载功能，所以会使用独立的类加载器； 当找到需要的方法，都会copy一份出来，而不是使用原来的实例，从而保证数据隔离； 调度反射方法，最终是由jvm执行invoke0()执行" }, { "title": "Java 泛型使用方法", "url": "/posts/java-generics-usage/", "categories": "Software Development", "tags": "Java", "date": "2020-10-14 15:28:00 +0800", "snippet": "概述泛型在java中有很重要的地位，在面向对象编程及各种设计模式中有非常广泛的应用。什么是泛型？为什么要使用泛型？泛型，即“参数化类型”。一提到参数，最熟悉的就是定义方法时有形参，然后调用此方法时传递实参。那么参数化类型怎么理解呢？顾名思义，就是将类型由原来的具体的类型参数化，类似于方法中的变量参数，此时类型也定义成参数形式（可以称之为类型形参），然后在使用/调用时传入具体的类型（类型实参）。泛型的本质是为了参数化类型（在不创建新的类型的情况下，通过泛型指定的不同类型来控制形参具体限制的类型）。也就是说在泛型使用过程中，操作的数据类型被指定为一个参数，这种参数类型可以用在类、接口和方法中，分别被称为泛型类、泛型接口、泛型方法。一个栗子List arrayList = new ArrayList();arrayList.add(&quot;aaaa&quot;);arrayList.add(100);for(int i = 0; i&amp;lt; arrayList.size();i++){ String item = (String)arrayList.get(i); Log.d(&quot;泛型测试&quot;,&quot;item = &quot; + item);}毫无疑问，程序的运行结果会以崩溃结束：java.lang.ClassCastException: java.lang.Integer cannot be cast to java.lang.StringArrayList可以存放任意类型，例子中添加了一个String类型，添加了一个Integer类型，再使用时都以String的方式使用，因此程序崩溃了。为了解决类似这样的问题（在编译阶段就可以解决），泛型应运而生。我们将第一行声明初始化list的代码更改一下，编译器会在编译阶段就能够帮我们发现类似这样的问题。List&amp;lt;String&amp;gt; arrayList = new ArrayList&amp;lt;String&amp;gt;();...//arrayList.add(100); 在编译阶段，编译器就会报错特性泛型只在编译阶段有效。看下面的代码：List&amp;lt;String&amp;gt; stringArrayList = new ArrayList&amp;lt;String&amp;gt;();List&amp;lt;Integer&amp;gt; integerArrayList = new ArrayList&amp;lt;Integer&amp;gt;();Class classStringArrayList = stringArrayList.getClass();Class classIntegerArrayList = integerArrayList.getClass();if(classStringArrayList.equals(classIntegerArrayList)){ Log.d(&quot;泛型测试&quot;,&quot;类型相同&quot;);}输出结果：D/泛型测试: 类型相同。通过上面的例子可以证明，在编译之后程序会采取去泛型化的措施。也就是说Java中的泛型，只在编译阶段有效。在编译过程中，正确检验泛型结果后，会将泛型的相关信息擦出，并且在对象进入和离开方法的边界处添加类型检查和类型转换的方法。也就是说，泛型信息不会进入到运行时阶段。对此总结成一句话：泛型类型在逻辑上看以看成是多个不同的类型，实际上都是相同的基本类型。泛型的使用泛型有三种使用方式，分别为：泛型类、泛型接口、泛型方法泛型类泛型类型用于类的定义中，被称为泛型类。通过泛型可以完成对一组类的操作对外开放相同的接口。最典型的就是各种容器类，如：List、Set、Map。泛型类的最基本写法（这么看可能会有点晕，会在下面的例子中详解）：class 类名称 &amp;lt;泛型标识：可以随便写任意标识号，标识指定的泛型的类型&amp;gt;{ private 泛型标识 /*（成员变量类型）*/ var; ..... }}一个最普通的泛型类：//此处T可以随便写为任意标识，常见的如T、E、K、V等形式的参数常用于表示泛型//在实例化泛型类时，必须指定T的具体类型public class Generic&amp;lt;T&amp;gt;{ //key这个成员变量的类型为T,T的类型由外部指定 private T key; public Generic(T key) { //泛型构造方法形参key的类型也为T，T的类型由外部指定 this.key = key; } public T getKey(){ //泛型方法getKey的返回值类型为T，T的类型由外部指定 return key; }}//泛型的类型参数只能是类类型（包括自定义类），不能是简单类型//传入的实参类型需与泛型的类型参数类型相同，即为Integer.Generic&amp;lt;Integer&amp;gt; genericInteger = new Generic&amp;lt;Integer&amp;gt;(123456);//传入的实参类型需与泛型的类型参数类型相同，即为String.Generic&amp;lt;String&amp;gt; genericString = new Generic&amp;lt;String&amp;gt;(&quot;key_vlaue&quot;);Log.d(&quot;泛型测试&quot;,&quot;key is &quot; + genericInteger.getKey());Log.d(&quot;泛型测试&quot;,&quot;key is &quot; + genericString.getKey());12-27 09:20:04.432 13063-13063/? D/泛型测试: key is 12345612-27 09:20:04.432 13063-13063/? D/泛型测试: key is key_vlaue定义的泛型类，就一定要传入泛型类型实参么？并不是这样，在使用泛型的时候如果传入泛型实参，则会根据传入的泛型实参做相应的限制，此时泛型才会起到本应起到的限制作用。如果不传入泛型类型实参的话，在泛型类中使用泛型的方法或成员变量定义的类型可以为任何的类型。看一个例子：Generic generic = new Generic(&quot;111111&quot;);Generic generic1 = new Generic(4444);Generic generic2 = new Generic(55.55);Generic generic3 = new Generic(false);Log.d(&quot;泛型测试&quot;,&quot;key is &quot; + generic.getKey());Log.d(&quot;泛型测试&quot;,&quot;key is &quot; + generic1.getKey());Log.d(&quot;泛型测试&quot;,&quot;key is &quot; + generic2.getKey());Log.d(&quot;泛型测试&quot;,&quot;key is &quot; + generic3.getKey());D/泛型测试: key is 111111D/泛型测试: key is 4444D/泛型测试: key is 55.55D/泛型测试: key is false 注意： 泛型的类型参数只能是类类型，不能是简单类型。 不能对确切的泛型类型使用instanceof操作。如下面的操作是非法的，编译时会出错。if(ex_num instanceof Generic&amp;lt;Number&amp;gt;){ } 泛型接口泛型接口与泛型类的定义及使用基本相同。泛型接口常被用在各种类的生产器中，可以看一个例子：//定义一个泛型接口public interface Generator&amp;lt;T&amp;gt; { public T next();}当实现泛型接口的类，未传入泛型实参时：/** * 未传入泛型实参时，与泛型类的定义相同，在声明类的时候，需将泛型的声明也一起加到类中 * 即：class FruitGenerator&amp;lt;T&amp;gt; implements Generator&amp;lt;T&amp;gt;{ * 如果不声明泛型，如：class FruitGenerator implements Generator&amp;lt;T&amp;gt;，编译器会报错：&quot;Unknown class&quot; */class FruitGenerator&amp;lt;T&amp;gt; implements Generator&amp;lt;T&amp;gt;{ @Override public T next() { return null; }}当实现泛型接口的类，传入泛型实参时：/** * 传入泛型实参时： * 定义一个生产器实现这个接口,虽然我们只创建了一个泛型接口Generator&amp;lt;T&amp;gt; * 但是我们可以为T传入无数个实参，形成无数种类型的Generator接口。 * 在实现类实现泛型接口时，如已将泛型类型传入实参类型，则所有使用泛型的地方都要替换成传入的实参类型 * 即：Generator&amp;lt;T&amp;gt;，public T next();中的的T都要替换成传入的String类型。 */public class FruitGenerator implements Generator&amp;lt;String&amp;gt; { private String[] fruits = new String[]{&quot;Apple&quot;, &quot;Banana&quot;, &quot;Pear&quot;}; @Override public String next() { Random rand = new Random(); return fruits[rand.nextInt(3)]; }}泛型通配符我们知道Ingeter是Number的一个子类，同时在特性章节中我们也验证过Generic与Generic实际上是相同的一种基本类型。那么问题来了，在使用Generic作为形参的方法中，能否使用Generic的实例传入呢？在逻辑上类似于Generic和Generic是否可以看成具有父子关系的泛型类型呢？为了弄清楚这个问题，我们使用Generic这个泛型类继续看下面的例子：public void showKeyValue1(Generic&amp;lt;Number&amp;gt; obj){ Log.d(&quot;泛型测试&quot;,&quot;key value is &quot; + obj.getKey());}Generic&amp;lt;Integer&amp;gt; gInteger = new Generic&amp;lt;Integer&amp;gt;(123);Generic&amp;lt;Number&amp;gt; gNumber = new Generic&amp;lt;Number&amp;gt;(456);showKeyValue(gNumber);// showKeyValue这个方法编译器会为我们报错：Generic&amp;lt;java.lang.Integer&amp;gt; // cannot be applied to Generic&amp;lt;java.lang.Number&amp;gt;// showKeyValue(gInteger);通过提示信息我们可以看到Generic不能被看作为`Generic的子类。由此可以看出:同一种泛型可以对应多个版本（因为参数类型是不确定的），不同版本的泛型类实例是不兼容的。回到上面的例子，如何解决上面的问题？总不能为了定义一个新的方法来处理Generic类型的类，这显然与java中的多台理念相违背。因此我们需要一个在逻辑上可以表示同时是Generic和Generic父类的引用类型。由此类型通配符应运而生。我们可以将上面的方法改一下：public void showKeyValue1(Generic&amp;lt;?&amp;gt; obj){ Log.d(&quot;泛型测试&quot;,&quot;key value is &quot; + obj.getKey());} 类型通配符一般是使用？代替具体的类型实参，注意了，此处’？’是类型实参，而不是类型形参 。再直白点的意思就是，此处的？和Number、String、Integer一样都是一种实际的类型，可以把？看成所有类型的父类。是一种真实的类型。可以解决当具体类型不确定的时候，这个通配符就是 ? ；当操作类型时，不需要使用类型的具体功能时，只使用Object类中的功能。那么可以用 ? 通配符来表未知类型。泛型方法在java中,泛型类的定义非常简单，但是泛型方法就比较复杂了。尤其是我们见到的大多数泛型类中的成员方法也都使用了泛型，有的甚至泛型类中也包含着泛型方法，这样在初学者中非常容易将泛型方法理解错了。泛型类，是在实例化类的时候指明泛型的具体类型；泛型方法，是在调用方法的时候指明泛型的具体类型 。/** * 泛型方法的基本介绍 * @param tClass 传入的泛型实参 * @return T 返回值为T类型 * 说明： * 1）public 与 返回值中间&amp;lt;T&amp;gt;非常重要，可以理解为声明此方法为泛型方法。 * 2）只有声明了&amp;lt;T&amp;gt;的方法才是泛型方法，泛型类中的使用了泛型的成员方法并不是泛型方法。 * 3）&amp;lt;T&amp;gt;表明该方法将使用泛型类型T，此时才可以在方法中使用泛型类型T。 * 4）与泛型类的定义一样，此处T可以随便写为任意标识，常见的如T、E、K、V等形式的参数常用于表示泛型。 */public &amp;lt;T&amp;gt; T genericMethod(Class&amp;lt;T&amp;gt; tClass)throws InstantiationException , IllegalAccessException{ T instance = tClass.newInstance(); return instance;}Object obj = genericMethod(Class.forName(&quot;com.test.test&quot;));泛型方法的基本用法public class GenericTest { //这个类是个泛型类，在上面已经介绍过 public class Generic&amp;lt;T&amp;gt;{ private T key; public Generic(T key) { this.key = key; } //我想说的其实是这个，虽然在方法中使用了泛型，但是这并不是一个泛型方法。 //这只是类中一个普通的成员方法，只不过他的返回值是在声明泛型类已经声明过的泛型。 //所以在这个方法中才可以继续使用 T 这个泛型。 public T getKey(){ return key; } /** * 这个方法显然是有问题的，在编译器会给我们提示这样的错误信息&quot;cannot reslove symbol E&quot; * 因为在类的声明中并未声明泛型E，所以在使用E做形参和返回值类型时，编译器会无法识别。 public E setKey(E key){ this.key = keu } */ } /** * 这才是一个真正的泛型方法。 * 首先在public与返回值之间的&amp;lt;T&amp;gt;必不可少，这表明这是一个泛型方法，并且声明了一个泛型T * 这个T可以出现在这个泛型方法的任意位置. * 泛型的数量也可以为任意多个 * 如：public &amp;lt;T,K&amp;gt; K showKeyName(Generic&amp;lt;T&amp;gt; container){ * ... * } */ public &amp;lt;T&amp;gt; T showKeyName(Generic&amp;lt;T&amp;gt; container){ System.out.println(&quot;container key :&quot; + container.getKey()); //当然这个例子举的不太合适，只是为了说明泛型方法的特性。 T test = container.getKey(); return test; } //这也不是一个泛型方法，这就是一个普通的方法，只是使用了Generic&amp;lt;Number&amp;gt;这个泛型类做形参而已。 public void showKeyValue1(Generic&amp;lt;Number&amp;gt; obj){ Log.d(&quot;泛型测试&quot;,&quot;key value is &quot; + obj.getKey()); } //这也不是一个泛型方法，这也是一个普通的方法，只不过使用了泛型通配符? //同时这也印证了泛型通配符章节所描述的，?是一种类型实参，可以看做为Number等所有类的父类 public void showKeyValue2(Generic&amp;lt;?&amp;gt; obj){ Log.d(&quot;泛型测试&quot;,&quot;key value is &quot; + obj.getKey()); } /** * 这个方法是有问题的，编译器会为我们提示错误信息：&quot;UnKnown class &#39;E&#39; &quot; * 虽然我们声明了&amp;lt;T&amp;gt;,也表明了这是一个可以处理泛型的类型的泛型方法。 * 但是只声明了泛型类型T，并未声明泛型类型E，因此编译器并不知道该如何处理E这个类型。 public &amp;lt;T&amp;gt; T showKeyName(Generic&amp;lt;E&amp;gt; container){ ... } */ /** * 这个方法也是有问题的，编译器会为我们提示错误信息：&quot;UnKnown class &#39;T&#39; &quot; * 对于编译器来说T这个类型并未项目中声明过，因此编译也不知道该如何编译这个类。 * 所以这也不是一个正确的泛型方法声明。 public void showkey(T genericObj){ } */ public static void main(String[] args) { }}类中的泛型方法当然这并不是泛型方法的全部，泛型方法可以出现杂任何地方和任何场景中使用。但是有一种情况是非常特殊的，当泛型方法出现在泛型类中时，我们再通过一个例子看一下public class GenericFruit { class Fruit{ @Override public String toString() { return &quot;fruit&quot;; } } class Apple extends Fruit{ @Override public String toString() { return &quot;apple&quot;; } } class Person{ @Override public String toString() { return &quot;Person&quot;; } } class GenerateTest&amp;lt;T&amp;gt;{ public void show_1(T t){ System.out.println(t.toString()); } //在泛型类中声明了一个泛型方法，使用泛型E，这种泛型E可以为任意类型。可以类型与T相同，也可以不同。 //由于泛型方法在声明的时候会声明泛型&amp;lt;E&amp;gt;，因此即使在泛型类中并未声明泛型，编译器也能够正确识别泛型方法中识别的泛型。 public &amp;lt;E&amp;gt; void show_3(E t){ System.out.println(t.toString()); } //在泛型类中声明了一个泛型方法，使用泛型T，注意这个T是一种全新的类型，可以与泛型类中声明的T不是同一种类型。 public &amp;lt;T&amp;gt; void show_2(T t){ System.out.println(t.toString()); } } public static void main(String[] args) { Apple apple = new Apple(); Person person = new Person(); GenerateTest&amp;lt;Fruit&amp;gt; generateTest = new GenerateTest&amp;lt;Fruit&amp;gt;(); //apple是Fruit的子类，所以这里可以 generateTest.show_1(apple); //编译器会报错，因为泛型类型实参指定的是Fruit，而传入的实参类是Person //generateTest.show_1(person); //使用这两个方法都可以成功 generateTest.show_2(apple); generateTest.show_2(person); //使用这两个方法也都可以成功 generateTest.show_3(apple); generateTest.show_3(person); }}泛型方法与可变参数再看一个泛型方法和可变参数的例子：public &amp;lt;T&amp;gt; void printMsg( T... args){ for(T t : args){ Log.d(&quot;泛型测试&quot;,&quot;t is &quot; + t); }}printMsg(&quot;111&quot;,222,&quot;aaaa&quot;,&quot;2323.4&quot;,55.55);静态方法与泛型静态方法有一种情况需要注意一下，那就是在类中的静态方法使用泛型：静态方法无法访问类上定义的泛型；如果静态方法操作的引用数据类型不确定的时候，必须要将泛型定义在方法上。即：如果静态方法要使用泛型的话，必须将静态方法也定义成泛型方法 。public class StaticGenerator&amp;lt;T&amp;gt; { .... .... /** * 如果在类中定义使用泛型的静态方法，需要添加额外的泛型声明（将这个方法定义成泛型方法） * 即使静态方法要使用泛型类中已经声明过的泛型也不可以。 * 如：public static void show(T t){..},此时编译器会提示错误信息： &quot;StaticGenerator cannot be refrenced from static context&quot; */ public static &amp;lt;T&amp;gt; void show(T t){ }}泛型方法总结泛型方法能使方法独立于类而产生变化，以下是一个基本的指导原则： 无论何时，如果你能做到，你就该尽量使用泛型方法。也就是说，如果使用泛型方法将整个类泛型化，那么就应该使用泛型方法。另外对于一个static的方法而已，无法访问泛型类型的参数。所以如果static方法要使用泛型能力，就必须使其成为泛型方法。泛型上下边界在使用泛型的时候，我们还可以为传入的泛型类型实参进行上下边界的限制，如：类型实参只准传入某种类型的父类或某种类型的子类。为泛型添加上边界，即传入的类型实参必须是指定类型的子类型public void showKeyValue1(Generic&amp;lt;? extends Number&amp;gt; obj){ Log.d(&quot;泛型测试&quot;,&quot;key value is &quot; + obj.getKey());}Generic&amp;lt;String&amp;gt; generic1 = new Generic&amp;lt;String&amp;gt;(&quot;11111&quot;);Generic&amp;lt;Integer&amp;gt; generic2 = new Generic&amp;lt;Integer&amp;gt;(2222);Generic&amp;lt;Float&amp;gt; generic3 = new Generic&amp;lt;Float&amp;gt;(2.4f);Generic&amp;lt;Double&amp;gt; generic4 = new Generic&amp;lt;Double&amp;gt;(2.56);//这一行代码编译器会提示错误，因为String类型并不是Number类型的子类//showKeyValue1(generic1);showKeyValue1(generic2);showKeyValue1(generic3);showKeyValue1(generic4);如果我们把泛型类的定义也改一下:public class Generic&amp;lt;T extends Number&amp;gt;{ private T key; public Generic(T key) { this.key = key; } public T getKey(){ return key; }}//这一行代码也会报错，因为String不是Number的子类Generic&amp;lt;String&amp;gt; generic1 = new Generic&amp;lt;String&amp;gt;(&quot;11111&quot;);再来一个泛型方法的例子：//在泛型方法中添加上下边界限制的时候，必须在权限声明与返回值之间的&amp;lt;T&amp;gt;上添加上下边界，即在泛型声明的时候添加//public &amp;lt;T&amp;gt; T showKeyName(Generic&amp;lt;T extends Number&amp;gt; container)，编译器会报错：&quot;Unexpected bound&quot;public &amp;lt;T extends Number&amp;gt; T showKeyName(Generic&amp;lt;T&amp;gt; container){ System.out.println(&quot;container key :&quot; + container.getKey()); T test = container.getKey(); return test;} 通过上面的两个例子可以看出：泛型的上下边界添加，必须与泛型的声明在一起 。泛型数组看到了很多文章中都会提起泛型数组，经过查看sun的说明文档，在java中是”不能创建一个确切的泛型类型的数组”的。也就是说下面的这个例子是不可以的：List&amp;lt;String&amp;gt;[] ls = new ArrayList&amp;lt;String&amp;gt;[10]; 而使用通配符创建泛型数组是可以的，如下面这个例子：List&amp;lt;?&amp;gt;[] ls = new ArrayList&amp;lt;?&amp;gt;[10]; 这样也是可以的：List&amp;lt;String&amp;gt;[] ls = new ArrayList[10];下面使用Sun的一篇文档的一个例子来说明这个问题：List&amp;lt;String&amp;gt;[] lsa = new List&amp;lt;String&amp;gt;[10]; // Not really allowed. Object o = lsa; Object[] oa = (Object[]) o; List&amp;lt;Integer&amp;gt; li = new ArrayList&amp;lt;Integer&amp;gt;(); li.add(new Integer(3)); oa[1] = li; // Unsound, but passes run time store check String s = lsa[1].get(0); // Run-time error: ClassCastException.这种情况下，由于JVM泛型的擦除机制，在运行时JVM是不知道泛型信息的，所以可以给oa[1]赋上一个ArrayList而不会出现异常，但是在取出数据的时候却要做一次类型转换，所以就会出现ClassCastException，如果可以进行泛型数组的声明，上面说的这种情况在编译期将不会出现任何的警告和错误，只有在运行时才会出错。而对泛型数组的声明进行限制，对于这样的情况，可以在编译期提示代码有类型安全问题，比没有任何提示要强很多。下面采用通配符的方式是被允许的:数组的类型不可以是类型变量，除非是采用通配符的方式，因为对于通配符的方式，最后取出数据是要做显式的类型转换的。List&amp;lt;?&amp;gt;[] lsa = new List&amp;lt;?&amp;gt;[10]; // OK, array of unbounded wildcard type. Object o = lsa; Object[] oa = (Object[]) o; List&amp;lt;Integer&amp;gt; li = new ArrayList&amp;lt;Integer&amp;gt;(); li.add(new Integer(3)); oa[1] = li; // Correct. Integer i = (Integer) lsa[1].get(0); // OK " }, { "title": "为什么使用 @Autowired 提示不推荐", "url": "/posts/why-autowired-not-recommended/", "categories": "Software Development", "tags": "Java, Spring, DevDairy", "date": "2020-10-09 13:09:00 +0800", "snippet": "@Autowired注解相信每个Spring开发者都不陌生了！但是当我们使用IDEA写代码的时候，经常会发现@Autowired注解下面是有小黄线的，我们把小鼠标悬停在上面，可以看到这个如下图所示的警告信息：那么为什么IDEA会给出Field injection is not recommended这样的警告呢？下面带着这样的问题，一起来全面的了解下Spring中的三种注入方式以及他们之间在各方面的优劣。Spring中的三种依赖注入方式Field Injection@Autowired注解的一大使用场景就是Field Injection。具体形式如下：@Controllerpublic class UserController { @Autowired private UserService userService;}这种注入方式通过Java的反射机制实现，所以private的成员也可以被注入具体的对象。Constructor InjectionConstructor Injection是构造器注入，是我们日常最为推荐的一种使用方式。具体形式如下：@Controllerpublic class UserController { private final UserService userService; public UserController(UserService userService){ this.userService = userService; }}这种注入方式很直接，通过对象构建的时候建立关系，所以这种方式对对象创建的顺序会有要求，当然Spring会为你搞定这样的先后顺序，除非你出现循环依赖，然后就会抛出异常。Setter InjectionSetter Injection也会用到@Autowired注解，但使用方式与Field Injection有所不同，Field Injection是用在成员变量上，而Setter Injection的时候，是用在成员变量的Setter函数上。具体形式如下：@Controllerpublic class UserController { private UserService userService; @Autowired public void setUserService(UserService userService){ this.userService = userService; }}这种注入方式也很好理解，就是通过调用成员变量的set方法来注入想要使用的依赖对象。三种依赖注入的对比在知道了Spring提供的三种依赖注入方式之后，我们继续回到本文开头说到的问题：IDEA为什么不推荐使用Field Injection呢？我们可以从多个开发测试的考察角度来对比一下它们之间的优劣：可靠性从对象构建过程和使用过程，看对象在各阶段的使用是否可靠来评判： Field Injection：不可靠 Constructor Injection：可靠 Setter Injection：不可靠由于构造函数有严格的构建顺序和不可变性，一旦构建就可用，且不会被更改。可维护性主要从更容易阅读、分析依赖关系的角度来评判： Field Injection：差 Constructor Injection：好 Setter Injection：差还是由于依赖关键的明确，从构造函数中可以显现的分析出依赖关系，对于我们如何去读懂关系和维护关系更友好。可测试性当在复杂依赖关系的情况下，考察程序是否更容易编写单元测试来评判 Field Injection：差 Constructor Injection：好 Setter Injection：好Constructor Injection和Setter Injection的方式更容易Mock和注入对象，所以更容易实现单元测试。灵活性主要根据开发实现时候的编码灵活性来判断： Field Injection：很灵活 Constructor Injection：不灵活 Setter Injection：很灵活由于Constructor Injection对Bean的依赖关系设计有严格的顺序要求，所以这种注入方式不太灵活。相反Field Injection和Setter Injection就非常灵活，但也因为灵活带来了局面的混乱，也是一把双刃剑。循环关系的检测对于Bean之间是否存在循环依赖关系的检测能力： Field Injection：不检测 Constructor Injection：自动检测 Setter Injection：不检测性能表现不同的注入方式，对性能的影响 Field Injection：启动快 Constructor Injection：启动慢 Setter Injection：启动快主要影响就是启动时间，由于Constructor Injection有严格的顺序要求，所以会拉长启动时间。总结所以，综合上面各方面的比较，可以获得如下表格： 注入方式 可靠性 可维护性 可测试性 灵活性 循环关系的检测 性能影响 Field Injection 不可靠 低 差 很灵活 不检测 启动快 Constructor Injection 可靠 高 好 不灵活 自动检测 启动慢 Setter Injection 不可靠 低 好 很灵活 不检测 启动快 结果一目了然，Constructor Injection在很多方面都是优于其他两种方式的，所以Constructor Injection通常都是首选方案！而Setter Injection比起Field Injection来说，大部分都一样，但因为可测试性更好，所以当你要用@Autowired的时候，推荐使用Setter Injection的方式，这样IDEA也不会给出警告了。同时，也侧面也反映了，可测试性的重要地位啊最后，关于@Autowired注入，我们给出两个结论: 依赖注入的使用上，Constructor Injection是首选。 使用@Autowired注解的时候，要使用Setter Injection方式，这样代码更容易编写单元测试。" }, { "title": "Java 集合类概览", "url": "/posts/java-collection-overview/", "categories": "Software Development", "tags": "Java", "date": "2020-10-03 15:28:00 +0800", "snippet": "Java集合框架集合是java中存放对象的容器，存放于java.util包中。下图是java集合类的继承与实现关系：框架图说明 所有集合类都位于java.util包下。Java的集合类主要由两个接口派生而出：Collection和Map，Collection和Map是Java集合框架的根接口，这两个接口又包含了一些子接口或实现类。 集合接口：6个接口（短虚线表示），表示不同集合类型，是集合框架的基础。 抽象类：5个抽象类（长虚线表示），对集合接口的部分实现。可扩展为自定义集合类。 实现类：8个实现类（实线表示），对接口的具体实现。 Collection 接口是一组允许重复的对象。 Set 接口继承 Collection，集合元素不重复。 List 接口继承 Collection，允许重复，维护元素插入顺序。 Map接口是键－值对象，与Collection接口没有什么关系。 Set、List和Map可以看做集合的三大类： List集合是有序集合，集合中的元素可以重复，访问集合中的元素可以根据元素的索引来访问。 Set集合是无序集合，集合中的元素不可以重复，访问集合中的元素只能根据元素本身来访问（也是集合里元素不允许重复的原因）。 Map集合中保存Key-value对形式的元素，访问时只能根据每项元素的key来访问其value。 框架图分析看上面的框架图，先抓住它的主干，即Collection和Map。 Collection是一个接口，是高度抽象出来的集合，它包含了集合的基本操作和属性。Collection包含了List和Set两大分支。List是一个有序的队列，每一个元素都有它的索引。第一个元素的索引值是0。List的实现类有LinkedList, ArrayList, Vector, Stack。Set是一个不允许有重复元素的集合。Set的实现类有HastSet和TreeSet。HashSet依赖于HashMap，它实际上是通过HashMap实现的；TreeSet依赖于TreeMap，它实际上是通过TreeMap实现的。 Map是一个映射接口，即key-value键值对。Map中的每一个元素包含“一个key”和“key对应的value”。AbstractMap是个抽象类，它实现了Map接口中的大部分API。而HashMap，TreeMap，WeakHashMap都是继承于AbstractMap。Hashtable虽然继承于Dictionary，但它实现了Map接口。 接下来，再看Iterator。它是遍历集合的工具，即我们通常通过Iterator迭代器来遍历集合。我们说Collection依赖于Iterator，是因为Collection的实现类都要实现iterator()函数，返回一个Iterator对象。ListIterator是专门为遍历List而存在的。 再看Enumeration，它是JDK 1.0引入的抽象类。作用和Iterator一样，也是遍历集合；但是Enumeration的功能要比Iterator少。在上面的框图中，Enumeration只能在Hashtable, Vector, Stack中使用。 最后，看Arrays和Collections。它们是操作数组、集合的两个工具类。有了上面的整体框架之后，我们接下来对每个类分别进行分析。Collection接口Collection接口是处理对象集合的根接口，其中定义了很多对元素进行操作的方法。Collection接口有两个主要的子接口List和Set 注意Map不是Collection的子接口，这个要牢记。Collection接口中的方法如下: 方法名称 说明 boolean add(E e) 向集合中添加一个元素，E 是元素的数据类型 boolean addAll(Collection c) 向集合中添加集合 c 中的所有元素 void clear() 删除集合中的所有元素 boolean contains(Object o) 判断集合中是否存在指定元素 boolean containsAll(Collection c) 判断集合中是否包含集合 c 中的所有元素 boolean isEmpty() 判断集合是否为空 Iteratoriterator() 返回一个 Iterator 对象，用于遍历集合中的元素 boolean remove(Object o) 从集合中删除一个指定元素 boolean removeAll(Collection c) 从集合中删除所有在集合 c 中出现的元素 boolean retainAll(Collection c) 仅仅保留集合中所有在集合 c 中出现的元素 int size() 返回集合中元素的个数 Object[] toArray() 返回包含此集合中所有元素的数组 List接口List集合代表一个有序集合，集合中每个元素都有其对应的顺序索引。List集合允许使用重复元素，可以通过索引来访问指定位置的集合元素。List接口继承于Collection接口，它可以定义一个允许重复的有序集合。因为List中的元素是有序的，所以我们可以通过使用索引（元素在List中的位置，类似于数组下标）来访问List中的元素，这类似于Java的数组。List接口为Collection直接接口。List所代表的是有序的Collection，即它用某种特定的插入顺序来维护元素顺序。用户可以对列表中每个元素的插入位置进行精确地控制，同时可以根据元素的整数索引（在列表中的位置）访问元素，并搜索列表中的元素。实现List接口的集合主要有：ArrayList、LinkedList、Vector、Stack。ArrayListArrayList是一个动态数组，也是我们最常用的集合。它允许任何符合规则的元素插入甚至包括null。每一个ArrayList都有一个初始容量（10），该容量代表了数组的大小。随着容器中的元素不断增加，容器的大小也会随着增加。在每次向容器中增加元素的同时都会进行容量检查，当快溢出时，就会进行扩容操作。所以如果我们明确所插入元素的多少，最好指定一个初始容量值，避免过多的进行扩容操作而浪费时间、效率。size、isEmpty、get、set、iterator和 listIterator 操作都以固定时间运行。add 操作以分摊的固定时间运行，也就是说，添加 n 个元素需要 O(n) 时间（由于要考虑到扩容，所以这不只是添加元素会带来分摊固定时间开销那样简单）。ArrayList擅长于随机访问。同时ArrayList是非同步的LinkedList同样实现List接口的LinkedList与ArrayList不同，ArrayList是一个动态数组，而LinkedList是一个双向链表。所以它除了有ArrayList的基本操作方法外还额外提供了get，remove，insert方法在LinkedList的首部或尾部。由于实现的方式不同，LinkedList不能随机访问，它所有的操作都是要按照双重链表的需要执行。在列表中索引的操作将从开头或结尾遍历列表（从靠近指定索引的一端）。这样做的好处就是可以通过较低的代价在List中进行插入和删除操作。与ArrayList一样，LinkedList也是非同步的。如果多个线程同时访问一个List，则必须自己实现访问同步。一种解决方法是在创建List时构造一个同步的List：List list = Collections.synchronizedList(new LinkedList(...));Vector与ArrayList相似，但是Vector是同步的。所以说Vector是线程安全的动态数组。它的操作与ArrayList几乎一样。 已被ArrayList替代StackStack继承自Vector，实现一个后进先出的堆栈。Stack提供5个额外的方法使得Vector得以被当作堆栈使用。基本的push和pop 方法，还有peek方法得到栈顶的元素，empty方法测试堆栈是否为空，search方法检测一个元素在堆栈中的位置。Stack刚创建后是空栈。Set接口Set是一种不包括重复元素的Collection。它维持它自己的内部排序，所以随机访问没有任何意义。与List一样，它同样允许null的存在但是仅有一个。由于Set接口的特殊性，所有传入Set集合中的元素都必须不同，同时要注意任何可变对象，如果在对集合中元素进行操作时，导致e1.equals(e2)==true，则必定会产生某些问题。Set接口有三个具体实现类，分别是散列集HashSet、链式散列集LinkedHashSet和树形集TreeSet。Set是一种不包含重复的元素的Collection，无序，即任意的两个元素e1和e2都有e1.equals(e2)=false，Set最多有一个null元素。需要注意的是：虽然Set中元素没有顺序，但是元素在set中的位置是由该元素的HashCode决定的，其具体位置其实是固定的。 此外需要说明一点，在set接口中的不重复是有特殊要求的。举一个例子：对象A和对象B，本来是不同的两个对象，正常情况下它们是能够放入到Set里面的，但是如果对象A和B的都重写了hashcode和equals方法，并且重写后的hashcode和equals方法是相同的话。那么A和B是不能同时放入到Set集合中去的，也就是Set集合中的去重和hashcode与equals方法直接相关。为了更好地理解，请看下面的例子：public class Test{ public static void main(String[] args) { Set&amp;lt;String&amp;gt; set=new HashSet&amp;lt;String&amp;gt;(); set.add(&quot;Hello&quot;); set.add(&quot;world&quot;); set.add(&quot;Hello&quot;); System.out.println(&quot;集合的尺寸为:&quot;+set.size()); System.out.println(&quot;集合中的元素为:&quot;+set.toString()); } }运行结果：集合的尺寸为:2集合中的元素为:[world, Hello]分析：由于String类中重写了hashcode和equals方法，用来比较指向的字符串对象所存储的字符串是否相等。所以这里的第二个Hello是加不进去的。再看一个例子：public class TestSet { public static void main(String[] args){ Set&amp;lt;String&amp;gt; books = new HashSet&amp;lt;String&amp;gt;(); //添加一个字符串对象 books.add(new String(&quot;Struts2权威指南&quot;)); //再次添加一个字符串对象， //因为两个字符串对象通过equals方法比较相等，所以添加失败，返回false boolean result = books.add(new String(&quot;Struts2权威指南&quot;)); System.out.println(result); //下面输出看到集合只有一个元素 System.out.println(books); }}运行结果：false[Struts2权威指南]说明：程序中，book集合两次添加的字符串对象明显不是一个对象（程序通过new关键字来创建字符串对象），当使用==运算符判断返回false，使用equals方法比较返回true，所以不能添加到Set集合中，最后只能输出一个元素HashSetHashSet 是一个没有重复元素的集合。它是由HashMap实现的，不保证元素的顺序(这里所说的没有顺序是指：元素插入的顺序与输出的顺序不一致)，而且HashSet允许使用null 元素。HashSet是非同步的，如果多个线程同时访问一个哈希set，而其中至少一个线程修改了该set，那么它必须保持外部同步。 HashSet按Hash算法来存储集合的元素，因此具有很好的存取和查找性能。HashSet的实现方式大致如下，通过一个HashMap存储元素，元素是存放在HashMap的Key中，而Value统一使用一个Object对象。HashSet使用和理解中容易出现的误区: HashSet中存放null值。HashSet中是允许存入null值的，但是在HashSet中仅仅能够存入一个null值。 HashSet中存储元素的位置是固定的。HashSet中存储的元素的是无序的，这个没什么好说的，但是由于HashSet底层是基于Hash算法实现的，使用了hashcode，所以HashSet中相应的元素的位置是固定的。 必须小心操作可变对象（Mutable Object）。如果一个Set中的可变元素改变了自身状态导致Object.equals(Object)=true将导致一些问题LinkedHashSetLinkedHashSet继承自HashSet，其底层是基于LinkedHashMap来实现的，有序，非同步。LinkedHashSet集合同样是根据元素的hashCode值来决定元素的存储位置，但是它同时使用链表维护元素的次序。这样使得元素看起来像是以插入顺序保存的，也就是说，当遍历该集合时候，LinkedHashSet将会以元素的添加顺序访问集合的元素TreeSetreeSet是一个有序集合，其底层是基于TreeMap实现的，非线程安全。TreeSet可以确保集合元素处于排序状态。TreeSet支持两种排序方式，自然排序和定制排序，其中自然排序为默认的排序方式。当我们构造TreeSet时，若使用不带参数的构造函数，则TreeSet的使用自然比较器；若用户需要使用自定义的比较器，则需要使用带比较器的参数。 注意：TreeSet集合不是通过hashcode和equals函数来比较元素的.它是通过compare或者comparaeTo函数来判断元素是否相等.compare函数通过判断两个对象的id，相同的id判断为重复元素，不会被加入到集合中。Queue接口Queue接口相对于List接口来说，Queue接口中支持的方法相对就比较少了，接口代码如下：public interface Queue&amp;lt;E&amp;gt; extends Collection&amp;lt;E&amp;gt; { boolean add(E e); // 往队尾添加一个元素，失败抛出异常 boolean offer(E e); // 往队尾添加一个元素，失败返回false E remove(); // 检索到队头元素并删除，返回该队头，失败抛出异常 E poll(); // 检索到队头元素并删除，返回该队头，失败返回null E element(); // 检索到队头元素，并返回该队头，失败抛出异常 E peek(); // 检索到队头元素，并返回该队头，失败返回null} Queue接口不支持存放null元素。这里有个问题需要关注，原来自己用的时候也没仔细想过，为什么好像有两套功能一样的方法？即add()和offer(),remove()和poll()，element()和peek()的区别是什么？原来，二者区别的就是在操作失败时的处理上，就好比有两套约定，在Collection接口中规定，如果add()操作失败，则抛出相应的异常; 而offer()方法则规定，如果操作失败，返回false。remove()和poll()，element()和peek()的区别类似。 方法 返回值处理 方法 返回值处理 add() 失败抛出异常，有IllegalStateException,ClassCastException和NullPointerException三种异常。 offer() 失败返回false remove() 失败抛出NoSuchElementException异常。 poll() 失败返回null element() 失败抛出NoSuchElementException异常。 peek() 失败返回null Deque接口说完Queue接口，很自然地就会涉及到Deque接口。Deque，即Double End Queue，双端队列，顾名思义，就是可以在队头和队尾进行插入或删除操作，我们看下接口的设计，这里我们也只列举一部分：public interface Deque&amp;lt;E&amp;gt; extends Queue&amp;lt;E&amp;gt; { void addFirst(E e); void addLast(E e); boolean offerFirst(E e); boolean offerLast(E e); E removeFirst(); E removeLast(); E pollFirst(); E pollLast();}Okay，和我们的猜想一模一样，至于为什么也有两套一样的方法嘛，和上面在Queue中的解释完完全全一样。ArrayDeque实现ArrayDeque类是实现了Deque接口的，常见的使用方法如下Deque&amp;lt;String&amp;gt; dq=new ArrayDeque&amp;lt;&amp;gt;();dq.add(&quot;jack&quot;);dq.add(&quot;andy&quot;);dq.add(&quot;rose&quot;);System.out.println(dq.toString()); // 输出 [jack, andy, rose]dq.removeLast();System.out.println(dq.toString()); // 输出 [jack, andy]LinkedList实现QueueLinkedList即可以作为朴素队列Queue接口的实现类来使用，也可以作为双端队列Deque接口的实现类来使用LinkedList作为朴素队列来使用的代码如下：Queue&amp;lt;String&amp;gt; q=new LinkedList&amp;lt;&amp;gt;();q.add(&quot;jack&quot;);q.add(&quot;andy&quot;);q.add(&quot;rose&quot;);System.out.println(q.toString()); // 输出 [jack, andy, rose]q.remove();System.out.println(q.toString()); // 输出 [andy, rose]Map接口Map与List、Set接口不同，它是由一系列键值对组成的集合，提供了key到Value的映射。同时它也没有继承Collection。在Map中它保证了key与value之间的一一对应关系。也就是说一个key对应一个value，所以它不能存在相同的key值，当然value值可以相同。HashMap以哈希表数据结构实现，查找对象时通过哈希函数计算其位置，它是为快速查询而设计的，其内部定义了一个hash表数组（Entry[] table），元素会通过哈希转换函数将元素的哈希地址转换成数组中存放的索引，如果有冲突，则使用散列链表的形式将所有相同哈希地址的元素串起来，可能通过查看HashMap.Entry的源码它是一个单链表结构LinkedHashMapLinkedHashMap是HashMap的一个子类，它保留插入的顺序，如果需要输出的顺序和输入时的相同，那么就选用LinkedHashMapLinkedHashMap是Map接口的哈希表和链接列表实现，具有可预知的迭代顺序。此实现提供所有可选的映射操作，并允许使用null值和null键。此类不保证映射的顺序，特别是它不保证该顺序恒久不变。LinkedHashMap实现与HashMap的不同之处在于，后者维护着一个运行于所有条目的双重链接列表。此链接列表定义了迭代顺序，该迭代顺序可以是插入顺序或者是访问顺序。根据链表中元素的顺序可以分为：按插入顺序的链表，和按访问顺序(调用get方法)的链表。默认是按插入顺序排序，如果指定按访问顺序排序，那么调用get方法后，会将这次访问的元素移至链表尾部，不断访问可以形成按访问顺序排序的链表。 注意，此实现不是同步的。如果多个线程同时访问链接的哈希映射，而其中至少一个线程从结构上修改了该映射，则它必须保持外部同步。由于LinkedHashMap需要维护元素的插入顺序，因此性能略低于HashMap的性能，但在迭代访问Map里的全部元素时将有很好的性能，因为它以链表来维护内部顺序。TreeMapTreeMap 是一个有序的key-value集合，非同步，基于红黑树（Red-Black tree）实现，每一个key-value节点作为红黑树的一个节点。TreeMap存储时会进行排序的，会根据key来对key-value键值对进行排序，其中排序方式也是分为两种，一种是自然排序，一种是定制排序，具体取决于使用的构造方法。自然排序：TreeMap中所有的key必须实现Comparable接口，并且所有的key都应该是同一个类的对象，否则会报ClassCastException异常。定制排序：定义TreeMap时，创建一个comparator对象，该对象对所有的treeMap中所有的key值进行排序，采用定制排序的时候不需要TreeMap中所有的key必须实现Comparable接口。TreeMap判断两个元素相等的标准：两个key通过compareTo()方法返回0，则认为这两个key相等。如果使用自定义的类来作为TreeMap中的key值，且想让TreeMap能够良好的工作，则必须重写自定义类中的equals()方法，TreeMap中判断相等的标准是：两个key通过equals()方法返回为true，并且通过compareTo()方法比较应该返回为0。Iterator 与 ListIterator详解IteratorIterator的定义如下：public interface Iterator&amp;lt;E&amp;gt; {}Iterator是一个接口，它是集合的迭代器。集合可以通过Iterator去遍历集合中的元素。Iterator提供的API接口如下：boolean hasNext()：判断集合里是否存在下一个元素。如果有，hasNext()方法返回 true。Object next()：返回集合里下一个元素。void remove()：删除集合里上一次next方法返回的元素。使用示例public class IteratorExample { public static void main(String[] args) { ArrayList&amp;lt;String&amp;gt; a = new ArrayList&amp;lt;String&amp;gt;(); a.add(&quot;aaa&quot;); a.add(&quot;bbb&quot;); a.add(&quot;ccc&quot;); System.out.println(&quot;Before iterate : &quot; + a); Iterator&amp;lt;String&amp;gt; it = a.iterator(); while (it.hasNext()) { String t = it.next(); if (&quot;bbb&quot;.equals(t)) { it.remove(); } } System.out.println(&quot;After iterate : &quot; + a); }}输出结果如下：Before iterate : [aaa, bbb, ccc]After iterate : [aaa, ccc] 注意： Iterator只能单向移动。 Iterator.remove()是唯一安全的方式来在迭代过程中修改集合；如果在迭代过程中以任何其它的方式修改了基本集合将会产生未知的行为。而且每调用一次next()方法，remove()方法只能被调用一次，如果违反这个规则将抛出一个异常 ListIteratorListIterator是一个功能更加强大的迭代器, 它继承于Iterator接口，只能用于各种List类型的访问。可以通过调用listIterator()方法产生一个指向List开始处的ListIterator, 还可以调用listIterator(n)方法创建一个一开始就指向列表索引为n的元素处的ListIterator。ListIterator接口定义如下:public interface ListIterator&amp;lt;E&amp;gt; extends Iterator&amp;lt;E&amp;gt; { boolean hasNext(); E next(); boolean hasPrevious(); E previous(); int nextIndex(); int previousIndex(); void remove(); void set(E e); void add(E e);}由以上定义我们可以推出ListIterator可以: 双向移动（向前/向后遍历）. 产生相对于迭代器在列表中指向的当前位置的前一个和后一个元素的索引. 可以使用set()方法替换它访问过的最后一个元素. 可以使用add()方法在next()方法返回的元素之前或previous()方法返回的元素之后插入一个元素.使用示例：public class ListIteratorExample { public static void main(String[] args) { ArrayList&amp;lt;String&amp;gt; a = new ArrayList&amp;lt;String&amp;gt;(); a.add(&quot;aaa&quot;); a.add(&quot;bbb&quot;); a.add(&quot;ccc&quot;); System.out.println(&quot;Before iterate : &quot; + a); ListIterator&amp;lt;String&amp;gt; it = a.listIterator(); while (it.hasNext()) { System.out.println(it.next() + &quot;, &quot; + it.previousIndex() + &quot;, &quot; + it.nextIndex()); } while (it.hasPrevious()) { System.out.print(it.previous() + &quot; &quot;); } System.out.println(); it = a.listIterator(1); while (it.hasNext()) { String t = it.next(); System.out.println(t); if (&quot;ccc&quot;.equals(t)) { it.set(&quot;nnn&quot;); } else { it.add(&quot;kkk&quot;); } } System.out.println(&quot;After iterate : &quot; + a); }}输出结果如下：Before iterate : [aaa, bbb, ccc]aaa, 0, 1bbb, 1, 2ccc, 2, 3ccc bbb aaa bbbcccAfter iterate : [aaa, bbb, kkk, nnn]常见相似集合类差异点ArrayList和LinkedList ArrayList是实现了基于动态数组的数据结构，LinkedList基于链表的数据结构。 对于随机访问get和set，ArrayList绝对优于LinkedList，因为LinkedList要移动指针。 对于新增和删除操作add和remove，LinedList比较占优势，因为ArrayList要移动数据。这一点要看实际情况的。若只对单条数据插入或删除，ArrayList的速度反而优于LinkedList。但若是批量随机的插入删除数据，LinkedList的速度大大优于ArrayList. 因为ArrayList每插入一条数据，要移动插入点及之后的所有数据。HashTable与HashMap相同点：都实现了Map、Cloneable、java.io.Serializable接口。都是存储”键值对(key-value)”的散列表，而且都是采用拉链法实现的。不同点： 历史原因：HashTable是基于陈旧的Dictionary类的，HashMap是Java 1.2引进的Map接口的一个实现 。 同步性：HashTable是线程安全的，也就是说是同步的，而HashMap是线程序不安全的，不是同步的 。 对null值的处理：HashMap的key、value都可为null，HashTable的key、value都不可为null 。 基类不同：HashMap继承于AbstractMap，而Hashtable继承于Dictionary。 Dictionary是一个抽象类，它直接继承于Object类，没有实现任何接口。Dictionary类是JDK 1.0的引入的。虽然Dictionary也支持“添加key-value键值对”、“获取value”、“获取大小”等基本操作，但它的API函数比Map少；而且Dictionary一般是通过Enumeration(枚举类)去遍历，Map则是通过Iterator(迭代M器)去遍历。然而由于Hashtable也实现了Map接口，所以，它即支持Enumeration遍历，也支持Iterator遍历。 AbstractMap是一个抽象类，它实现了Map接口的绝大部分API函数；为Map的具体实现类提供了极大的便利。它是JDK 1.2新增的类。 支持的遍历种类不同：HashMap只支持Iterator(迭代器)遍历。而Hashtable支持Iterator(迭代器)和Enumeration(枚举器)两种方式遍历。HashMap、Hashtable、LinkedHashMap和TreeMap比较Hashmap 是一个最常用的Map，它根据键的HashCode 值存储数据，根据键可以直接获取它的值，具有很快的访问速度。遍历时，取得数据的顺序是完全随机的。HashMap最多只允许一条记录的键为Null；允许多条记录的值为Null；HashMap不支持线程的同步，即任一时刻可以有多个线程同时写HashMap；可能会导致数据的不一致。如果需要同步，可以用Collections的synchronizedMap方法使HashMap具有同步的能力。Hashtable 与 HashMap类似，不同的是：它不允许记录的键或者值为空；它支持线程的同步，即任一时刻只有一个线程能写Hashtable，因此也导致了Hashtale在写入时会比较慢。LinkedHashMap保存了记录的插入顺序，在用Iterator遍历LinkedHashMap时，先得到的记录肯定是先插入的，也可以在构造时用带参数，按照应用次数排序。在遍历的时候会比HashMap慢，不过有种情况例外，当HashMap容量很大，实际数据较少时，遍历起来可能会比LinkedHashMap慢，因为LinkedHashMap的遍历速度只和实际数据有关，和容量无关，而HashMap的遍历速度和他的容量有关。如果需要输出的顺序和输入的相同，那么用LinkedHashMap可以实现，它还可以按读取顺序来排列，像连接池中可以应用。LinkedHashMap实现与HashMap的不同之处在于，后者维护着一个运行于所有条目的双重链表。此链接列表定义了迭代顺序，该迭代顺序可以是插入顺序或者是访问顺序。对于LinkedHashMap而言，它继承与HashMap、底层使用哈希表与双向链表来保存所有元素。其基本操作与父类HashMap相似，它通过重写父类相关的方法，来实现自己的链接列表特性。TreeMap实现SortMap接口，内部实现是红黑树。能够把它保存的记录根据键排序，默认是按键值的升序排序，也可以指定排序的比较器，当用Iterator 遍历TreeMap时，得到的记录是排过序的。TreeMap不允许key的值为null。非同步的。一般情况下，我们用的最多的是HashMap，HashMap里面存入的键值对在取出的时候是随机的，它根据键的HashCode值存储数据，根据键可以直接获取它的值，具有很快的访问速度。在Map 中插入、删除和定位元素，HashMap 是最好的选择。TreeMap取出来的是排序后的键值对。但如果您要按自然顺序或自定义顺序遍历键，那么TreeMap会更好。LinkedHashMap 是HashMap的一个子类，如果需要输出的顺序和输入的相同，那么用LinkedHashMap可以实现，它还可以按读取顺序来排列，像连接池中可以应用。public class MapTest { public static void main(String[] args) { //HashMap HashMap&amp;lt;String,String&amp;gt; hashMap = new HashMap(); hashMap.put(&quot;4&quot;, &quot;d&quot;); hashMap.put(&quot;3&quot;, &quot;c&quot;); hashMap.put(&quot;2&quot;, &quot;b&quot;); hashMap.put(&quot;1&quot;, &quot;a&quot;); Iterator&amp;lt;String&amp;gt; iteratorHashMap = hashMap.keySet().iterator(); System.out.println(&quot;HashMap--&amp;gt;&quot;); while (iteratorHashMap.hasNext()){ Object key1 = iteratorHashMap.next(); System.out.println(key1 + &quot;--&quot; + hashMap.get(key1)); } //LinkedHashMap LinkedHashMap&amp;lt;String,String&amp;gt; linkedHashMap = new LinkedHashMap(); linkedHashMap.put(&quot;4&quot;, &quot;d&quot;); linkedHashMap.put(&quot;3&quot;, &quot;c&quot;); linkedHashMap.put(&quot;2&quot;, &quot;b&quot;); linkedHashMap.put(&quot;1&quot;, &quot;a&quot;); Iterator&amp;lt;String&amp;gt; iteratorLinkedHashMap = linkedHashMap.keySet().iterator(); System.out.println(&quot;LinkedHashMap--&amp;gt;&quot;); while (iteratorLinkedHashMap.hasNext()){ Object key2 = iteratorLinkedHashMap.next(); System.out.println(key2 + &quot;--&quot; + linkedHashMap.get(key2)); } //TreeMap TreeMap&amp;lt;String,String&amp;gt; treeMap = new TreeMap(); treeMap.put(&quot;4&quot;, &quot;d&quot;); treeMap.put(&quot;3&quot;, &quot;c&quot;); treeMap.put(&quot;2&quot;, &quot;b&quot;); treeMap.put(&quot;1&quot;, &quot;a&quot;); Iterator&amp;lt;String&amp;gt; iteratorTreeMap = treeMap.keySet().iterator(); System.out.println(&quot;TreeMap--&amp;gt;&quot;); while (iteratorTreeMap.hasNext()){ Object key3 = iteratorTreeMap.next(); System.out.println(key3 + &quot;--&quot; + treeMap.get(key3)); } }}输出结果：HashMap--&amp;gt;3--c2--b1--a4--dLinkedHashMap--&amp;gt;4--d3--c2--b1--aTreeMap--&amp;gt;1--a2--b3--c4--dHashSet、LinkedHashSet、TreeSet比较Set接口Set不允许包含相同的元素，如果试图把两个相同元素加入同一个集合中，add方法返回false。Set判断两个对象相同不是使用==运算符，而是根据equals方法。也就是说，只要两个对象用equals方法比较返回true，Set就不会接受这两个对象。HashSetHashSet有以下特点： 不能保证元素的排列顺序，顺序有可能发生变化。 不是同步的。 集合元素可以是null，但只能放入一个null。当向HashSet结合中存入一个元素时，HashSet会调用该对象的hashCode()方法来得到该对象的hashCode值，然后根据 hashCode值来决定该对象在HashSet中存储位置。简单的说，HashSet集合判断两个元素相等的标准是两个对象通过equals方法比较相等，并且两个对象的hashCode()方法返回值也相等。 注意，如果要把一个对象放入HashSet中，重写该对象对应类的equals方法，也应该重写其hashCode()方法。其规则是如果两个对象通过equals方法比较返回true时，其hashCode也应该相同。另外，对象中用作equals比较标准的属性，都应该用来计算 hashCode的值。LinkedHashSetLinkedHashSet集合同样是根据元素的hashCode值来决定元素的存储位置，但是它同时使用链表维护元素的次序。这样使得元素看起来像是以插入顺序保存的，也就是说，当遍历该集合时候，LinkedHashSet将会以元素的添加顺序访问集合的元素。LinkedHashSet在迭代访问Set中的全部元素时，性能比HashSet好，但是插入时性能稍微逊色于HashSet。TreeSet类TreeSet是SortedSet接口的唯一实现类，TreeSet可以确保集合元素处于排序状态。TreeSet支持两种排序方式，自然排序和定制排序，其中自然排序为默认的排序方式。向TreeSet中加入的应该是同一个类的对象。TreeSet判断两个对象不相等的方式是两个对象通过equals方法返回false，或者通过CompareTo方法比较没有返回0。自然排序自然排序使用要排序元素的CompareTo（Object obj）方法来比较元素之间大小关系，然后将元素按照升序排列。Java提供了一个Comparable接口，该接口里定义了一个compareTo(Object obj)方法，该方法返回一个整数值，实现了该接口的对象就可以比较大小。obj1.compareTo(obj2)方法如果返回0，则说明被比较的两个对象相等，如果返回一个正数，则表明obj1大于obj2，如果是负数，则表明obj1小于obj2。如果我们将两个对象的equals方法总是返回true，则这两个对象的compareTo方法返回应该返回0。定制排序自然排序是根据集合元素的大小，以升序排列，如果要定制排序，应该使用Comparator接口，实现 int compare(T o1,T o2)方法。package com.test; import java.util.HashSet; import java.util.LinkedHashSet; import java.util.TreeSet; /** * @description 几个set的比较 * HashSet：哈希表是通过使用称为散列法的机制来存储信息的，元素并没有以某种特定顺序来存放； * LinkedHashSet：以元素插入的顺序来维护集合的链接表，允许以插入的顺序在集合中迭代； * TreeSet：提供一个使用树结构存储Set接口的实现，对象以升序顺序存储，访问和遍历的时间很快。 */ public class SetDemo { public static void main(String[] args) { HashSet&amp;lt;String&amp;gt; hs = new HashSet&amp;lt;String&amp;gt;(); hs.add(&quot;B&quot;); hs.add(&quot;A&quot;); hs.add(&quot;D&quot;); hs.add(&quot;E&quot;); hs.add(&quot;C&quot;); hs.add(&quot;F&quot;); System.out.println(&quot;HashSet 顺序:\\n&quot;+hs); LinkedHashSet&amp;lt;String&amp;gt; lhs = new LinkedHashSet&amp;lt;String&amp;gt;(); lhs.add(&quot;B&quot;); lhs.add(&quot;A&quot;); lhs.add(&quot;D&quot;); lhs.add(&quot;E&quot;); lhs.add(&quot;C&quot;); lhs.add(&quot;F&quot;); System.out.println(&quot;LinkedHashSet 顺序:\\n&quot;+lhs); TreeSet&amp;lt;String&amp;gt; ts = new TreeSet&amp;lt;String&amp;gt;(); ts.add(&quot;B&quot;); ts.add(&quot;A&quot;); ts.add(&quot;D&quot;); ts.add(&quot;E&quot;); ts.add(&quot;C&quot;); ts.add(&quot;F&quot;); System.out.println(&quot;TreeSet 顺序:\\n&quot;+ts); } }输出结果：HashSet 顺序:[D, E, F, A, B, C]LinkedHashSet 顺序:[B, A, D, E, C, F]TreeSet 顺序:[A, B, C, D, E, F]Iterator和ListIterator区别我们在使用List，Set的时候，为了实现对其数据的遍历，我们经常使用到了Iterator(迭代器)。使用迭代器，你不需要干涉其遍历的过程，只需要每次取出一个你想要的数据进行处理就可以了。但是在使用的时候也是有不同的。List和Set都有iterator()来取得其迭代器。对List来说，你也可以通过listIterator()取得其迭代器，两种迭代器在有些时候是不能通用的，Iterator和ListIterator主要区别在以下方面： ListIterator有add()方法，可以向List中添加对象，而Iterator不能 ListIterator和Iterator都有hasNext()和next()方法，可以实现顺序向后遍历，但是ListIterator有hasPrevious()和previous()方法，可以实现逆向（顺序向前）遍历。Iterator就不可以。 ListIterator可以定位当前的索引位置，nextIndex()和previousIndex()可以实现。Iterator没有此功能。 都可实现删除对象，但是ListIterator可以实现对象的修改，set()方法可以实现。Iierator仅能遍历，不能修改。因为ListIterator的这些功能，可以实现对LinkedList等List数据结构的操作。其实，数组对象也可以用迭代器来实现。Collection 和 Collections区别java.util.Collection 是一个集合接口（集合类的一个顶级接口）。它提供了对集合对象进行基本操作的通用接口方法。Collection接口在Java 类库中有很多具体的实现。Collection接口的意义是为各种具体的集合提供了最大化的统一操作方式，其直接继承接口有List与Set。 Collection ├List │├LinkedList │├ArrayList │└Vector │　└Stack └Set java.util.Collections 是一个包装类（工具类/帮助类）。它包含有各种有关集合操作的静态多态方法。此类不能实例化，就像一个工具类，用于对集合中元素进行排序、搜索以及线程安全等各种操作，服务于Java的Collection框架。代码示例：public class TestCollections { public static void main(String args[]) { //注意List是实现Collection接口的 List list = new ArrayList(); double array[] = { 112, 111, 23, 456, 231 }; for (int i = 0; i &amp;lt; array.length; i++) { list.add(new Double(array[i])); } Collections.sort(list); for (int i = 0; i &amp;lt; array.length; i++) { System.out.println(list.get(i)); } // 结果：23.0 111.0 112.0 231.0 456.0 } }" }, { "title": "Init Test", "url": "/posts/init-test/", "categories": "", "tags": "", "date": "1970-01-01 08:00:00 +0800", "snippet": "Hello WorldThis is the very first article of my blog for testing, content down below is the first web page on this planet World Wide Web The WorldWideWeb (W3) is a wide-area hypermedia information retrieval initiative aiming to give universal access to a large universe of documents. Everything there is online about W3 is linked directly or indirectly to this document, including an executive summary of the project, Mailing lists , Policy , November’s W3 news , Frequently Asked Questions . What’s out there? Pointers to the world’s online information, subjects , W3 servers, etc. Help on the browser you are using Software Products A list of W3 project components and their current state. (e.g. Line Mode ,X11 Viola , NeXTStep , Servers , Tools , Mail robot , Library ) Technical Details of protocols, formats, program internals etc Bibliography Paper documentation on W3 and references. People A list of some people involved in the project. History A summary of the history of the project. How can I help ? If you would like to support the web.. Getting code Getting the code by anonymous FTP , etc. " } ]
